AggregateFunction (class, org.jooq)
An aggregate function. An aggregate function is a special field that is usually used in a GROUP BY
context. It is also the base for window function construction. Example: // Assuming import static
org.jooq.impl.DSL.*; using(configuration) .select(ACTOR.LAST_NAME, count()) .from(ACTOR)
.groupBy(ACTOR.LAST_NAME) .orderBy(count().desc()) .fetch(); Instances can be created using various
DSL methods and their overloads, such as DSL.count() or DSL.countDistinct(Field).
Methods:
- $filterWhere: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

AlterTableFinalStep (class, org.jooq)
The final step in the ALTER TABLE DSL. Referencing XYZ*Step types directly from client code It is
usually not recommended to reference any XYZ*Step types directly from client code, or assign them to
local variables. When writing dynamic SQL, creating a statement's components dynamically, and
passing them to the DSL API statically is usually a better choice. See the manual's section about
dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks
of referencing the XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ
3.x) They're less composable and not easy to get right when dynamic SQL gets complex They're less
readable They might have binary incompatible changes between minor releases

AlterTableStep (class, org.jooq)
The step in the ALTER TABLE statement where the action can be decided. Referencing XYZ*Step types
directly from client code It is usually not recommended to reference any XYZ*Step types directly
from client code, or assign them to local variables. When writing dynamic SQL, creating a
statement's components dynamically, and passing them to the DSL API statically is usually a better
choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- comment SQLDialect#COCKROACHDB: Specify a comment for a table using MySQL's syntax.
- comment: Specify a comment for a table using MySQL's syntax.
- renameTo: Add a RENAME TO clause to the ALTER TABLE statement.
- renameColumn: Add a RENAME COLUMN clause to the ALTER TABLE statement.
- renameIndex: Add a RENAME INDEX clause to the ALTER TABLE statement.
- renameConstraint: Add a RENAME CONSTRAINT clause to the ALTER TABLE statement.
- alter: Add an ALTER CONSTRAINT clause to the ALTER TABLE statement. This is an alias for
  alterConstraint(Constraint).
- alterColumn: Add an ALTER COLUMN clause to the ALTER TABLE statement.
- alterConstraint: Add an ALTER CONSTRAINT clause to the ALTER TABLE statement.
- add: Add an ADD COLUMN clause to the ALTER TABLE statement. This is an alias for addColumn(Field).
- addIfNotExists: Add an ADD COLUMN IF NOT EXISTS clause to the ALTER TABLE statement. This is an
  alias for addColumnIfNotExists(Field).
- addColumn: Add an ADD COLUMN clause to the ALTER TABLE statement.
- addColumnIfNotExists: Add an ADD COLUMN IF NOT EXISTS clause to the ALTER TABLE statement.
- drop: Add an DROP COLUMN clause to the ALTER TABLE statement. This is an alias for
  dropColumn(Field).
- dropIfExists: Add an DROP COLUMN IF EXISTS clause to the ALTER TABLE statement. This is an alias
  for dropColumnIfExists(Field).
- dropColumn: Add an DROP COLUMN clause to the ALTER TABLE statement.
- dropColumnIfExists: Add an DROP COLUMN IF EXISTS clause to the ALTER TABLE statement.
- dropColumns: Add an DROP COLUMN clause to the ALTER TABLE statement.
- dropConstraint: Add a DROP CONSTRAINT clause to the ALTER TABLE statement.
- dropConstraintIfExists: Add a DROP CONSTRAINT IF EXISTS clause to the ALTER TABLE statement.
- dropPrimaryKey: Add a DROP PRIMARY KEY clause to the ALTER TABLE statement.
- dropUnique SQLDialect#COCKROACHDB: Add a DROP UNIQUE clause to the ALTER TABLE statement. Some
  dialects (e.g. Ungültige Referenz SQLDialect#COCKROACHDB ) may not be able to drop constraints by
  name. If users specify the constraint type and the name, however, then the syntax can be emulated,
  e.g. using DROP INDEX … CASCADE.
- dropForeignKey: Add a DROP FOREIGN KEY clause to the ALTER TABLE statement.

Batch (class, org.jooq)
A wrapper for a JDBC batch operation. It has two modes: Execute several queries without bind values
create.batch(query1, query2, query3) .execute(); Execute one query several times with bind values
create.batch(query) .bind(valueA1, valueA2) .bind(valueB1, valueB2) .execute();
Methods:
- execute: Execute the batch operation.
- executeAsync: Execute the batch operation in a new CompletionStage. The result is asynchronously
  completed by a task running in an Executor provided by the underlying
  Configuration.executorProvider().
- size: Get the number of executed queries in this batch operation

BatchBindStep (class, org.jooq)
This type is used for the Batch's DSL API. Use it to add bind values to a single operation in the
batch statement.
Methods:
- bind: Set indexed bind values onto the batch statement. The argument array of bindValues will be
  set onto the indexed bind values of the batch statement: :1 -> bindValues[0] :2 -> bindValues[1]
  ... :N -> bindValues[N - 1] "Unmatched" bind values will be left unmodified: :N+1 -> unmodified
  :N+2 -> unmodified Bind index order The 1-based parameter index describes a parameter in rendering
  order, not in input order. For example, if a query contains a DSL.log(Field, Field) call, where
  the first argument is the value and the second argument is the base, this may produce different
  dialect specific renderings: Db2: ln(value) / ln(base) Oracle: log(base, value) SQL Server:
  log(value, base) Some bind values may even be repeated by a dialect specific emulation, leading to
  duplication and index-shifting. As such, it is usually better to supply bind values directly with
  the input of an expression, e.g.: Directly with the DSL method, such as DSL.log(Field, Field), for
  example. With the plain SQL template constructor, e.g. DSL.field(String, Object...) With the
  parser method, e.g. Parser.parseField(String, Object...)

Binding (class, org.jooq)
An SPI (Service Provider Interface) that exposes all low-level interactions with JDBC bind
variables. This SPI is used by jOOQ users to implement support for custom data types that would
otherwise not be supported by jOOQ and/or JDBC. All of jOOQ's internal support for bind variable
types is implemented in DefaultBinding. When Binding is invoked A Binding is invoked whenever jOOQ
interacts with JDBC's various types, including: get(BindingGetResultSetContext): To read from a JDBC
ResultSet get(BindingGetStatementContext): To read from a JDBC CallableStatement (OUT parameters).
register(BindingRegisterContext) may be needed to declare OUT parameters beforehand.
get(BindingGetSQLInputContext): To read from a JDBC SQLInput (UDT attributes)
set(BindingSetStatementContext): To write to a JDBC PreparedStatement (sql(BindingSQLContext) may be
needed to specify the bind value syntax) set(BindingSetSQLOutputContext): To read from a JDBC
SQLOutput (UDT attributes) Unlike a Converter, a Binding applies only to JDBC interactions. It does
not influence how nested data structures (such as DSL.multiset(TableLike) or
DSL.row(SelectField...)) are mapped to Java objects, for example. Creating user defined DataTypes
jOOQ provides built in data types through SQLDataType. Users can define their own data types
programmatically by calling DataType.asConvertedDataType(Converter) or
DataType.asConvertedDataType(Binding), for example. Custom data types can also be defined on
generated code using the <forcedType/> configuration, see the manual for more details. Ad-hoc
converters allow for attaching a converter directly to a SQL expression in order to keep related
logic close together, see the Converter Javadoc for more details.
Methods:
- converter: A converter that can convert between the database type and the custom type. While the
  Converter property of a binding is not optional (Converter.fromType() and Converter.toType() are
  needed by jOOQ's internals), the conversion implementation (i.e. Converter.from(Object) and
  Converter.to(Object)) isn't strictly required if implementations don't rely on it. If these
  conversion implementations are non-functional, it is advised to hint at this fact in
  Converter.fromSupported() and Converter.toSupported().
- sql: Generate SQL code for the bind variable. Implementations should generate SQL code onto
  BindingSQLContext.render(), given the context's bind variable located at
  BindingSQLContext.value(). Examples of such SQL code are: "?": Default implementations can simply
  generate a question mark. "123": Implementations may choose to inline bind variables to influence
  execution plan generation. Context.paramType() contains information whether inlined bind variables
  are expected in the current context. "CAST(? AS DATE)": Cast a database to a more specific type.
  This can be useful in databases like Oracle, which map both DATE and TIMESTAMP SQL types to
  Timestamp. Context.castMode() may contain some hints about whether casting is suggested in the
  current context. "?::json": Vendor-specific bind variables can be supported, e.g.
  SQLDialect.POSTGRES's JSON data type. Implementations must provide consistent behaviour between
  sql(BindingSQLContext) and set(BindingSetStatementContext), i.e. when bind variables are inlined,
  then they must not be bound to the PreparedStatement in set(BindingSetStatementContext)
- register: Register a CallableStatement's OUT parameter.
- set: Set a PreparedStatement's IN parameter.
- get: Get a ResultSet's OUT value. Implementations are expected to produce a value by calling
  BindingGetResultSetContext.value(Object), passing the resulting value to the method.
- of: Construct a binding from functions.

Case (class, org.jooq)
The SQL case statement. This construct can be used to create expressions of the type CASE x WHEN 1
THEN 'one' WHEN 2 THEN 'two' ELSE 'three' END or of the type CASE WHEN x < 1 THEN 'one' WHEN x >= 2
THEN 'two' ELSE 'three' END Instances of Case are created through the DSL.decode() method
Methods:
- value CASE value WHEN 1 THEN 'one' WHEN 2 THEN 'two' ELSE 'three' END: This construct can be used
  to create expressions of the type CASE value WHEN 1 THEN 'one' WHEN 2 THEN 'two' ELSE 'three' END
- when CASE WHEN x < 1 THEN 'one' WHEN x >= 2 THEN 'two' ELSE 'three' END: This construct can be
  used to create expressions of the type CASE WHEN x < 1 THEN 'one' WHEN x >= 2 THEN 'two' ELSE
  'three' END

Catalog (class, org.jooq)
A catalog. Standard SQL object identifiers come in 3 parts: [catalog].[schema].[object]. The catalog
is an object that groups a set of Schema instances, which again group a set of objects, where
objects can be Table, Sequence, Routine and many other types of objects. If your RDBMS supports
catalogs, and jOOQ supports using catalogs with your RDBMS, then generated catalog references can be
used to fully qualify objects Example: // Assuming import static org.jooq.impl.DSL.*;
using(configuration) .select(CATALOG.SCHEMA.ACTOR.FIRST_NAME, CATALOG.SCHEMA.ACTOR.LAST_NAME)
.from(CATALOG.SCHEMA.ACTOR) .fetch(); Compatibility: jOOQ supports catalogs in Ungültige Referenz
SQLDialect#SQLSERVER and related dialects, such as Ungültige Referenz SQLDialect#SQLDATAWAREHOUSE .
Database products like SQLDialect.MYSQL and related dialects, such as SQLDialect.MARIADB use
catalogs ("databases") instead of schemas, and lack schema support. For historic reasons, jOOQ
treats MySQL catalogs as schemas and does not support any catalog qualifier in MySQL. Instances can
be created using DSL.catalog(Name) and overloads.
Methods:
- getSchemas: List all schemas contained in this catalog.
- getSchema: Get a schema by its name (case-sensitive) in this catalog, or null if no such schema
  exists.
- schemaStream: Stream all schemas contained in this catalog.

Comment (class, org.jooq)
A comment. Most RDBMS support commenting (i.e. documenting) stored objects, such as Schema, Table,
Field, and other objects. Such comments can be modelled in DDL statements as well as retrieved from
meta data through the Comment type. Example: // Assuming import static org.jooq.impl.DSL.*;
using(configuration) .commentOnTable(TABLE) .is(comment("My Comment")) .execute(); Instances can be
created using DSL.comment(String) and overloads.
Methods:
- getComment: Get the comment.
- $comment: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

CommonTableExpression (class, org.jooq)
A common table expression. A common table expression is a table that can be supplied to WITH
clauses. It may or may not be defined recursively. Example: // Assuming import static
org.jooq.impl.DSL.*; Table<?> t = name("t").fields("v").as(select(one())); using(configuration)
.select() .from(t) .fetch(); Instances can be created using Name.as(ResultQuery).
Methods:
- $derivedColumnList: Experimental query object model accessor method, see also QOM. Subject to
  change in future jOOQ versions, use at your own risk.
- $query: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $materialized: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

Condition (class, org.jooq)
A condition or predicate. Conditions can be used in a variety of SQL clauses. They're mainly used in
a Select statement's WHERE clause, but can also appear in (non-exhaustive list): SELECT … WHERE,
e.g. via SelectWhereStep.where(Condition) SELECT … HAVING, e.g. via
SelectHavingStep.having(Condition) In a CASE expression, e.g. via DSL.case_() and
Case.when(Condition, Field) As an ordinary column expression, e.g. via DSL.field(Condition) In
filtered aggregate functions, e.g. via AggregateFilterStep.filterWhere(Condition) ... and many more
Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration) .select() .from(ACTOR)
.where(ACTOR.ACTOR_ID.eq(1)) // The eq operator produces a Condition from two Fields .fetch();
Instances can be created using DSL.condition(Field) and overloads, or by calling a comparison
operator method on Field, such as Field.eq(Field).
Methods:
- and: Combine this condition with another one using the Operator.AND operator.
- andNot: Combine this condition with a negated other one using the Operator.AND operator.
- andExists: Combine this condition with an EXISTS clause using the Operator.AND operator.
- andNotExists: Combine this condition with a NOT EXIST clause using the Operator.AND operator.
- or: Combine this condition with another one using the Operator.OR operator.
- orNot: Combine this condition with a negated other one using the Operator.OR operator.
- orExists: Combine this condition with an EXISTS clause using the Operator.OR operator.
- orNotExists: Combine this condition with a NOT EXIST clause using the Operator.OR operator.
- xor: Combine this condition with another one using the Operator.XOR operator.
- xorNot: Combine this condition with a negated other one using the Operator.XOR operator.
- xorExists: Combine this condition with an EXISTS clause using the Operator.XOR operator.
- xorNotExists: Combine this condition with a NOT EXIST clause using the Operator.XOR operator.
- not: The NOT operator.

Configuration (class, org.jooq)
A Configuration configures a DSLContext, providing it with information for query rendering and
execution. A Configuration wraps all information elements that are needed... by a RenderContext to
render Query objects and QueryParts by a BindContext to bind values to Query objects and QueryParts
by a Query or Routine object to execute themselves A Configuration is composed of types composing
its state and of SPIs: Types composing its state: dialect(): The SQLDialect that defines the
underlying database's behaviour when generating SQL syntax, or bind variables, or when executing the
query settings(): The Settings that define general jOOQ behaviour data(): A Map containing user-
defined data for the Scope of this configuration. SPIs: connectionProvider(): The ConnectionProvider
that defines the semantics of ConnectionProvider.acquire() and
ConnectionProvider.release(Connection) for all queries executed in the context of this
Configuration. jOOQ-provided default implementations include: DefaultConnectionProvider: a non-
thread-safe implementation that wraps a single JDBC Connection. Ideal for batch processing.
DataSourceConnectionProvider: a possibly thread-safe implementation that wraps a JDBC DataSource.
Ideal for use with connection pools, Java EE, or Spring. executeListenerProviders(): A set of
ExecuteListenerProvider that implement Query execution lifecycle management. jOOQ-provided example
implementations include: LoggerListener: generating default query execution log output (active by
default) StopWatchListener: generating default query execution speed log output (inactive by
default) executorProvider(): A provider for an Executor, which is used by default, in the absence of
an explicit executor, to execute asynchronous logic throughout the jOOQ API, such as for example
ResultQuery.fetchAsync(). metaProvider(): A provider for the DSLContext.meta() object which is used
to look up database meta data from various jOOQ APIs, such as for example the DSLContext.parser().
migrationListenerProviders(): A set of MigrationListenerProvider that allow for listening to the
database migration lifecycle. recordListenerProviders(): A set of RecordListenerProvider that
implement Record fetching and storing lifecycle management, specifically for use with
UpdatableRecord. jOOQ does not provide any implementations. recordMapperProvider(): The
RecordMapperProvider that defines and implements the behaviour of Record.into(Class),
ResultQuery.fetchInto(Class), Cursor.fetchInto(Class), and various related methods. jOOQ-provided
default implementations include: DefaultRecordMapperProvider: an implementation delegating to the
DefaultRecordMapper, which implements the most common mapping use-cases. recordUnmapperProvider():
The inverse of the recordMapperProvider() that allows to implement the behaviour of
Record.from(Object), and various related methods. transactionProvider(): The TransactionProvider
that defines and implements the behaviour of the DSLContext.transaction(TransactionalRunnable) and
DSLContext.transactionResult(TransactionalCallable) methods. jOOQ-provided default implementations
include: DefaultTransactionProvider: an implementation backed by JDBC directly, via
Connection.commit(), Connection.rollback(), and Connection.rollback(Savepoint) for nested
transactions. unwrapperProvider(): An UnwrapperProvider that allows for injecting custom JDBC
Wrapper.unwrap(Class) behaviour. visitListenerProviders(): A set of VisitListenerProvider that
implement Query rendering and variable binding lifecycle management, and that are allowed to
implement query transformation - e.g. to implement row-level security, or multi-tenancy. jOOQ does
not provide any implementations. Thread safety The simplest usage of a Configuration instance is to
use it exactly for a single Query execution, disposing it immediately. This will make it very simple
to implement thread-safe behaviour, but reflection caches will not be used optimally, e.g. when
using DefaultRecordMapper. At the same time, jOOQ does not require Configuration instances to be
that short-lived. Thread-safety will then be delegated to component objects, such as the
ConnectionProvider, the ExecuteListener list, etc. For a Configuration to be used in a thread safe
way, all set() methods must be avoided post initialisation, and settings() must not be modified
either. If you wish to create a derived configuration for local usage, with some configuration parts
changed, use the various derive() methods, instead.
Methods:
- dsl: Wrap this Configuration in a DSLContext, providing access to the configuration-contextual DSL
  to construct executable queries. In the DefaultConfiguration implementation, this is just
  convenience for DSL.using(Configuration). There's no functional difference between the two
  methods.
- data: Get all custom data from this Configuration. This is custom data that was previously set to
  the configuration using data(Object, Object). Use custom data if you want to pass data to your
  custom QueryPart or ExecuteListener objects to be made available at render, bind, execution, fetch
  time. See ExecuteListener for more details.
- clock: Get this configuration's Clock, which is used for optimistic locking, transaction time, and
  other time-depending features.
- connectionProvider: Get this configuration's underlying connection provider.
- connectionFactory: Get this configuration's underlying R2DBC connection factory.
- interpreterConnectionProvider: Get this configuration's underlying interpreter connection
  provider, which provides connections for DDL interpretation.
- systemConnectionProvider: Get this configuration's underlying system connection provider, which
  provides connections for system tasks. System tasks may include the generation of auxiliary data
  types or stored procedures, which users may want to generate using a different data source or
  transaction. By default, this connection provider is the same as connectionProvider().
- metaProvider: Get this configuration's underlying meta provider.
- commitProvider: Get this configuration's underlying commit provider.
- executorProvider: Get this configuration's underlying executor provider. Asynchronous operations
  will call back to this SPI to obtain an executor. This applies, for example, to
  ResultQuery.fetchAsync(). The following logic is applied when resolving the appropriate executor:
  If executorProvider() does not return null, then ExecutorProvider.provide() is called to obtain an
  Executor for the asynchronous task. In the jOOQ Java 8 distribution, ForkJoinPool.commonPool() is
  used if ForkJoinPool.getCommonPoolParallelism() > 1 A new "one thread per call" Executor is used
  in any other case. The SPI will not be called if an asynchronous operation explicitly overrides
  the Executor, e.g. as is the case for ResultQuery.fetchAsync(Executor).
- cacheProvider: Get this configuration's underlying cache provider. Cached operations will call
  this SPI to obtain a thread safe cache implementation to cache various things internally. This SPI
  allows for replacing the default cache implementation, which is mostly a ConcurrentHashMap, by a
  more specialised one, e.g. a LRU cache, e.g. from Guava.
- transactionProvider: Get this configuration's underlying transaction provider. If no explicit
  transaction provider was specified, and if connectionProvider() is a DefaultConnectionProvider,
  then this will return a DefaultTransactionProvider.
- transactionListenerProviders: Get the configured TransactionListenerProviders from this
  configuration.
- diagnosticsListenerProviders: Get the configured DiagnosticsListenerProviders from this
  configuration.
- unwrapperProvider: Get the configured UnwrapperProvider from this configuration.
- charsetProvider: Get the configured CharsetProvider from this configuration.
- annotatedPojoMemberProvider: Get this configuration's underlying annotated POJO member provider.
- constructorPropertiesProvider: Get this configuration's underlying constructor properties
  provider.
- recordMapperProvider: Get this configuration's underlying record mapper provider.
- recordUnmapperProvider: Get this configuration's underlying record unmapper provider.
- recordListenerProviders: Get the configured RecordListenerProviders from this configuration. This
  method allows for retrieving the configured RecordListenerProvider from this configuration. The
  providers will provide jOOQ with RecordListener instances. These instances receive record
  manipulation notification events every time jOOQ executes queries. jOOQ makes no assumptions about
  the internal state of these listeners, i.e. listener instances may share this Configuration's
  lifecycle (i.e. that of a JDBC Connection, or that of a transaction) share the lifecycle of an
  RecordContext (i.e. that of a single record manipulation) follow an entirely different lifecycle.
- executeListenerProviders: Get the configured ExecuteListenerProviders from this configuration.
  This method allows for retrieving the configured ExecuteListenerProvider from this configuration.
  The providers will provide jOOQ with ExecuteListener instances. These instances receive execution
  lifecycle notification events every time jOOQ executes queries. jOOQ makes no assumptions about
  the internal state of these listeners, i.e. listener instances may share this Configuration's
  lifecycle (i.e. that of a JDBC Connection, or that of a transaction) share the lifecycle of an
  ExecuteContext (i.e. that of a single query execution) follow an entirely different lifecycle.
  Note, depending on your Settings.isExecuteLogging(), some additional listeners may be prepended to
  this list, internally. Those listeners will never be exposed through this method, though.
- migrationListenerProviders: Get the configured MigrationListenerProviders from this configuration.
  This method allows for retrieving the configured MigrationListenerProvider from this
  configuration. The providers will provide jOOQ with MigrationListener instances. These instances
  receive migration lifecycle notification events every time jOOQ executes migrations. jOOQ makes no
  assumptions about the internal state of these listeners, i.e. listener instances may share this
  Configuration's lifecycle (i.e. that of a JDBC Connection, or that of a transaction) share the
  lifecycle of an MigrationContext (i.e. that of a single query execution) follow an entirely
  different lifecycle.
- visitListenerProviders: Get the configured VisitListenerProvider instances from this
  configuration. This method allows for retrieving the configured VisitListenerProvider instances
  from this configuration. The providers will provide jOOQ with VisitListener instances. These
  instances receive query rendering lifecycle notification events every time jOOQ renders queries.
  jOOQ makes no assumptions about the internal state of these listeners, i.e. listener instances may
  share this Configuration's lifecycle (i.e. that of a JDBC Connection, or that of a transaction)
  share the lifecycle of an ExecuteContext (i.e. that of a single query execution) follow an
  entirely different lifecycle.
- converterProvider: Get the configured ConverterProvider from this configuration.
- formattingProvider: Get the configured FormattingProvider from this configuration.
- subscriberProvider: Get the configured SubscriberProvider from this configuration.
- schemaMapping: Retrieve the configured schema mapping.
- dialect: Retrieve the configured dialect.
- family: Retrieve the family of the configured dialect.
- settings: Retrieve the runtime configuration settings.
- set: Change this configuration to hold a new Clock. This method is not thread-safe and should not
  be used in globally available Configuration objects.
- setAppending: Change this configuration by appending new record listeners. This will wrap the
  argument RecordListener in a DefaultRecordListenerProvider for convenience. This method is not
  thread-safe and should not be used in globally available Configuration objects.
- derive: Create a derived configuration from this one, without changing any properties.
- deriveAppending: Create a derived configuration from this one, with appended record listeners.
  This will wrap the argument RecordListener in a DefaultRecordListenerProvider for convenience.
- deriveSettings: Create a derived configuration from this one, with new settings constructed from a
  clone of the current settings.
- commercial: Whether this is a commercial edition of jOOQ.
- requireCommercial: Whether this is a commercial edition of jOOQ, throwing an exception with a
  message, if not.

ConnectionProvider (class, org.jooq)
A connection lifecycle handler API. The ConnectionProvider allows for abstracting the handling of
custom Connection lifecycles outside of jOOQ, injecting behaviour into jOOQ's internals. jOOQ will
try to acquire a new JDBC Connection from the connection provider as early as needed, and will
release it as early as possible. TransactionProvider implementations may choose to influence
ConnectionProvider behaviour, e.g. by acquiring connections upon
TransactionProvider.begin(TransactionContext) and by releasing connections only upon
TransactionProvider.commit(TransactionContext), or TransactionProvider.rollback(TransactionContext).
Methods:
- acquire: Acquire a connection from the connection lifecycle handler. This method is called by jOOQ
  exactly once per execution lifecycle, i.e. per ExecuteContext. Implementations may freely chose,
  whether subsequent calls to this method: return the same connection instance return the same
  connection instance for the same thread return the same connection instance for the same
  transaction (e.g. a javax.transaction.UserTransaction) return a fresh connection instance every
  time jOOQ will guarantee that every acquired connection is released through release(Connection)
  exactly once.
- release: Release a connection to the connection lifecycle handler. jOOQ will guarantee that every
  acquired connection is released exactly once.

Constraint (class, org.jooq)
A DDL constraint. Constraint definitions can be used in DDL statements in order to specify the
constraint, or in some DML statements that reference a given constraint. Example: // Assuming import
static org.jooq.impl.DSL.*; using(configuration) .alterTable(ACTOR)
.add(constraint("actor_unique_name") .unique(ACTOR.FIRST_NAME, ACTOR.LAST_NAME)) .execute();
Instances can be created using DSL.constraint(Name) and overloads.

Context (class, org.jooq)
A context type that is used for rendering SQL or for binding. This type implements Scope and thus
has a lifecycle defined by the rendering or binding operation. The Scope.data() map contents are
maintained for the entirety of the rendering or binding operation, and are passed along to child
Scope types, including e.g. GeneratorContext: When computing client side computed column values
BindingSQLContext: When generating the SQL for bind values
Methods:
- visit: Visit a QueryPart in the current Context. This method is called by certain QueryPart
  implementations to recursively visit component QueryParts.
- visitSubquery: Visit a QueryPart as a subquery in the current Context. This method is called by
  certain QueryPart implementations to recursively visit component QueryParts.
- start: TODO [#2667] Properties of these methods: - A clause is always started / ended, even if it
  isn't rendered or if it's empty!
- end:
- data: Set a data value for a key for the scope of a Consumer.
- declareFields: Whether the current context is rendering a SQL field declaration (e.g. a Field in
  the SELECT clause of the query).
- declareTables: Whether the current context is rendering a SQL table declaration (e.g. a Table in
  the FROM or JOIN clause of the query).
- declareAliases: Whether the current context is rendering a SQL alias declarations in
  declareTables() or declareFields() sections.
- declareWindows: Whether the current context is rendering a SQL window declaration (e.g. a
  WindowDefinition in the WINDOW clause of the query).
- declareCTE: Whether the current context is rendering a common table expression (e.g. a
  CommonTableExpression in the WITH clause of the query).
- topLevel: The top level QueryPart that is being rendered.
- topLevelForLanguageContext: The top level QueryPart that is being rendered in the current
  languageContext().
- subquery: Whether the current context is rendering a subquery (nested query).
- derivedTableSubquery: Whether the current context is rendering a derived table subquery.
- setOperationSubquery: Whether the current context is rendering a set operation subquery.
- predicandSubquery: Whether the current context is rendering a predicand subquery, i.e. a subquery
  that is an operand of a predicate.
- subqueryLevel: Which level of subqueries we're currently in, starting with 0 for the top level
  query.
- scopeLevel: Which level of scopes we're currently in, starting with 0 for the top scope.
- scopeStart: Start a new scope.
- scopePart: Return the QueryPart that defines the current scopeStart(QueryPart), if any, or null if
  there is no such QueryPart.
- scopeMarkStart: Mark the beginning of a scoped query part.
- scopeHide: Hide the argument query part from child scopes, if it has been registered previously.
- scopeShow: Show the argument query part in child scopes, if it has been registered previously.
- scopeRegister: Register a "special" query part in the scope, reusing the object from a higher
  scope, if available.
- scopeRegisterAndMark: Combine scopeRegister(QueryPart, boolean), scopeMarkStart(QueryPart) and
  scopeMarkEnd(QueryPart).
- scopeParts: Get all values of a type that are in the current scope or higher.
- currentScopeParts: Get all values of a type that are in the current scope.
- inScope: Check whether a query part is registered in the current scope or higher.
- inCurrentScope: Check whether a query part is registered in the current scope.
- scopeMapping: Retrieve the registered mapping for a query part in the current scope. If no such
  mapping exists, the argument QueryPart itself is returned.
- scopeMarkEnd: Mark the end of a scoped query part.
- scopeEnd: End a previous SELECT scope.
- stringLiteral: whether the current context is rendering a string literal.
- nextIndex: Get the next bind index. This increments an internal counter. This is relevant for two
  use-cases: When binding variables to a PreparedStatement. Client code must assure that calling
  nextIndex() is followed by setting a bind value to statement() When rendering unnamed bind
  variables with paramType() being to NAMED
- peekIndex: Peek the next bind index. This won't increment the internal counter, unlike
  nextIndex().
- skipUpdateCount: Skip an additional update count produced by this query.
- skipUpdateCounts: Skip a number of additional update counts produced by this query.
- statement: Retrieve the context's underlying PreparedStatement if available, or null if this
  traversal does not operate on a PreparedStatement.
- bindValue: Bind a value using a specific type. This will also increment the internal counter.
- peekAlias: Peek the next alias that will be generated by nextAlias().
- nextAlias: Return a new alias that is unique for the scope of one query. These aliases are
  sometimes needed when unaliased projections are defined in subqueries, which can lead to syntax
  errors.
- render: Render the context's underlying SQL statement.
- sql: Append some SQL to the context's contained StringBuilder.
- sqlIndentStart: Append some SQL to the context's contained StringBuilder, followed by the usual
  calls to formatIndentStart() and formatNewLine().
- sqlIndentEnd: Append some SQL to the context's contained StringBuilder preceded by the usual calls
  to formatIndentEnd() and formatNewLine().
- floatFormat: A formatter to produce scientific notation for Float types.
- doubleFormat: A formatter to produce scientific notation for Double types.
- format: Override the value of Settings.isRenderFormatted().
- formatNewLine: Render a new line character (only if Settings.isRenderFormatted() is set to true).
- formatNewLineAfterPrintMargin: Render a new line character (only if Settings.isRenderFormatted()
  is set to true, and the formatPrintMargin(int) has been exceeded).
- formatSeparator: Render a new line character (only if Settings.isRenderFormatted() is set to
  true), or a whitespace separator character otherwise.
- separatorRequired: Specify that a separator will be required before the next visit(QueryPart)
  call, but leave the decision whether to generate a formatSeparator() or just a whitespace to that
  next QueryPart.
- formatIndentStart: Start indenting subsequent SQL by one level (two characters), if
  Settings.isRenderFormatted() is set to true. This is the same as calling formatIndentStart(int)
  with a parameter of 2
- formatIndentLockStart: Start indenting subsequent SQL at the same level as the current line, if
  Settings.isRenderFormatted() is set to true.
- formatIndentEnd: Stop indenting subsequent SQL by one level (two characters), if
  Settings.isRenderFormatted() is set to true. This is the same as calling formatIndentEnd(int) with
  a parameter of 2
- formatIndentLockEnd: Stop indenting subsequent SQL at the same level as the current line, if
  Settings.isRenderFormatted() is set to true.
- formatPrintMargin: Set a print margin that will be applied to formatted SQL, if
  Settings.isRenderFormatted() is set to true. The default print margin is 80. Setting this to zero
  or a negative value means that no print margin will be applied. The print margin is applied to any
  of these QueryParts: Field.in(Field...) and related expressions
- literal: Append some literal to the context's contained StringBuilder.
- quote: Whether Name parts (and literal(String)) should be quoted.
- qualify: Whether query parts should render qualified names or not.
- qualifySchema: Whether query parts should render Schema-qualified names or not.
- qualifyCatalog: Whether query parts should render Catalog-qualified names or not.
- paramType: Specify, how bind values should be rendered. As ParamType.INDEXED parameters: ?, ?, ?
  As ParamType.NAMED parameters: :1, :2, :custom_name As ParamType.INLINED parameters: 1, 'A', null
- paramTypeIf: Set the new context value for paramType(), if a condition is true.
- languageContext: The current language context.
- languageContextIf: Set the new language context for languageContext(), if a condition is true.
- castMode: The currently applied cast mode for bind values.
- castModeIf: Set the new cast mode for castMode(), if a condition is true.

Converter (class, org.jooq)
A Converter for data types. A general data type conversion interface that can be provided to jOOQ at
various places in order to perform custom data type conversion. Conversion is directed, this means
that the Converter is used to load database types converting them to user types "FROM" the database.
Hence, fromType() is the type as defined in the database. Think of "FROM" = "reading". to store user
types converting them to database types "TO" the database. Think of "TO" = "writing". Hence,
toType() is the user-defined type Reciprocity In order to avoid unwanted side-effects, it is highly
recommended (yet not required) for from(Object) and to(Object) to be reciprocal. The two methods are
reciprocal, if for all X and Y, it can be said that if Y.equals(converter.from(X)), then
X.equals(converter.to(Y)). X.equals(converter.from(converter.to(X)))
X.equals(converter.to(converter.from(X))) Furthermore, it is recommended (yet not required) that
converter.from(null) == null converter.to(null) == null Irrespective of the Converter's encoding of
null values above, an implementation must be able to handle null values. When Converter is invoked
Unlike Binding, which is limited to JDBC interactions, a Converter can be invoked also outside of
the context of reading / writing data from / to the JDBC driver. This may include converting nested
data structures, such as DSL.multiset(TableLike) or DSL.row(SelectField...), recursively. These two
particular expression types are special cases. With other nested (but opaque to jOOQ) data
structures, it is not possible to recursively apply a Converter. For example, a
DSL.jsonObject(JSONEntry...), while constructed with jOOQ, produces "opaque" contents and thus
cannot recursively apply Converter. Creating user defined DataTypes jOOQ provides built in data
types through SQLDataType. Users can define their own data types programmatically by calling
DataType.asConvertedDataType(Converter) or DataType.asConvertedDataType(Binding), for example.
Custom data types can also be defined on generated code using the <forcedType/> configuration, see
the manual for more details Ad-hoc converters allow for attaching a converter directly to a SQL
expression in order to keep related logic close together. E.g.: Result<Record1<BookId>> result =
ctx.select(BOOK.ID.convertFrom(BookId::new)) .from(BOOK) .fetch(); In the above example, a one-way
only converter (only implementing from(Object), not to(Object)) is attached to the BOOK.ID Field
expression in order to convert between e.g. Long and BookId. While visually embedded in the query
itself, the Converter is still only applied when reading the Result, and like any other kind of
Converter (including those attached to Field by the code generator) thus has no effect on the
generated SQL or the contents reported by the database.
Methods:
- from Converter<String, Integer> converter = Converter.ofNullable(String.class, Integer.class,
  Integer::parseInt, Object::toString); // No exceptions thrown assertNull(converter.from(null));
  assertNull(converter.to(null));: Read and convert a database object to a user object.
  Implementations that don't support this conversion are expected to override fromSupported() to
  indicate lack of support.
- from: Read and convert a database object to a user object. Implementations that don't support this
  conversion are expected to override fromSupported() to indicate lack of support.
- to: Convert and write a user object to a database object. Implementations that don't support this
  conversion are expected to override toSupported() to indicate lack of support.
- fromType: The database type.
- toType: The user type.
- inverse: Inverse this converter.
- andThen: Chain a converter to this converter.
- forArrays: Turn this converter into a converter for arrays.
- fromSupported: Whether this is a write only converter. A write only converter implements only
  to(Object) but not from(Object).
- toSupported: Whether this is a read only converter. A read only converter implements only
  from(Object) but not to(Object).
- of: Construct a new converter from functions. The resulting Converter is expected to return true
  on both fromSupported() and toSupported().
- ofNullable Converter<String, Integer> converter = Converter.ofNullable(String.class,
  Integer.class, Integer::parseInt, Object::toString); // No exceptions thrown
  assertNull(converter.from(null)); assertNull(converter.to(null));: Construct a new converter from
  functions. This works like of(Class, Class, Function, Function), except that both conversion
  Functions are decorated with a function that always returns null for null inputs. Example:
  Converter<String, Integer> converter = Converter.ofNullable(String.class, Integer.class,
  Integer::parseInt, Object::toString); // No exceptions thrown assertNull(converter.from(null));
  assertNull(converter.to(null)); The resulting Converter is expected to return true on both
  fromSupported() and toSupported().
- fromNullable Converter<String, Integer> converter = Converter.fromNullable(String.class,
  Integer.class, Integer::parseInt); // No exceptions thrown assertNull(converter.from(null));:
  Construct a new read-only converter from a function. This works like from(Class, Class, Function),
  except that the conversion Function is decorated with a function that always returns null for null
  inputs. Example: Converter<String, Integer> converter = Converter.fromNullable(String.class,
  Integer.class, Integer::parseInt); // No exceptions thrown assertNull(converter.from(null)); The
  resulting Converter returns false on toSupported().
- toNullable Converter<String, Integer> converter = Converter.toNullable(String.class,
  Integer.class, Object::toString); // No exceptions thrown assertNull(converter.to(null));:
  Construct a new write-only converter from a function. This works like to(Class, Class, Function),
  except that the conversion Function is decorated with a function that always returns null for null
  inputs. Example: Converter<String, Integer> converter = Converter.toNullable(String.class,
  Integer.class, Object::toString); // No exceptions thrown assertNull(converter.to(null)); The
  resulting Converter returns false on fromSupported().

CreateTableAsStep (class, org.jooq)
A step in the construction of the CREATE TABLE statement. Referencing XYZ*Step types directly from
client code It is usually not recommended to reference any XYZ*Step types directly from client code,
or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases
Methods:
- as: Add the AS clause to the CREATE TABLE statement.

CreateTableFinalStep (class, org.jooq)
A step in the construction of the CREATE TABLE statement. Referencing XYZ*Step types directly from
client code It is usually not recommended to reference any XYZ*Step types directly from client code,
or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases

DAO (class, org.jooq)
A generic DAO interface for a pojo and a primary key type. This type is implemented by generated DAO
classes to provide a common API for common actions on POJOs
Methods:
- configuration: Expose the configuration in whose context this DAO is operating.
- settings: The settings wrapped by this context. This method is a convenient way of accessing
  configuration().settings().
- dialect: The SQLDialect wrapped by this context. This method is a convenient way of accessing
  configuration().dialect().
- family: The SQLDialect.family() wrapped by this context. This method is a convenient way of
  accessing configuration().family().
- mapper: Expose the RecordMapper that is used internally by this DAO to map from records of type R
  to POJOs of type P.
- insert: Performs an INSERT statement for a given POJO. Depending on various settings, like
  Settings.isReturnRecordToPojo(), Settings.isReturnIdentityOnUpdatableRecord(),
  Settings.isReturnAllOnUpdatableRecord(), and others, the argument POJO, if mutable, will receive
  any server side generated values using a Record.into(Object) call.
- update: Performs an UPDATE statement for a given POJO. Depending on various settings, like
  Settings.isReturnRecordToPojo(), Settings.isReturnIdentityOnUpdatableRecord(),
  Settings.isReturnAllOnUpdatableRecord(), and others, the argument POJO, if mutable, will receive
  any server side generated values using a Record.into(Object) call, if UPDATE … RETURNING is
  supported by the dialect.
- merge: Performs an MERGE statement for a given POJO.
- delete: Performs a DELETE statement for a POJO
- deleteById: Performs a DELETE statement for a given set of IDs.
- exists: Checks if a given POJO exists.
- existsById: Checks if a given ID exists.
- count: Count all records of the underlying table.
- findAll: Find all records of the underlying table.
- findById: Find a record of the underlying table by ID.
- findOptionalById: Find a record of the underlying table by ID.
- fetch: Find records by a given field and a set of values.
- fetchRange: Find records by a given field and a range of values.
- fetchOne: Find a unique record by a given field and a value.
- fetchOptional: Find a unique record by a given field and a value.
- getTable: Get the underlying table.
- getType: Get the underlying POJO type.
- getId: Extract the ID value from a POJO.

DSLContext (class, org.jooq)
A contextual DSL providing "attached" implementations to the org.jooq interfaces. Apart from the
DSL, this contextual DSL is the main entry point for client code, to access jOOQ classes and
functionality that are related to Query execution. Unlike objects created through the DSL type,
objects created from a DSLContext will be "attached" to the DSLContext's Scope.configuration(), such
that they can be executed immediately in a fluent style. An example is given here: DSLContext create
= DSL.using(connection, dialect); // Immediately fetch results after constructing a query
create.selectFrom(MY_TABLE).where(MY_TABLE.ID.eq(1)).fetch(); // The above is equivalent to this
"non-fluent" style create.fetch(DSL.selectFrom(MY_TABLE).where(MY_TABLE.ID.eq(1))); The DSL provides
convenient constructors to create a Configuration, which will be shared among all Query objects thus
created. Optionally, you can pass a reusable Configuration to the DSL.using(Configuration)
constructor. Please consider thread-safety concerns documented in Configuration, should you want to
reuse the same Configuration instance in various threads and / or transactions. DSLContext is a
Scope type, mostly for convenience access to its underlying Configuration properties, including the
Scope.data() map, which it shares with the Configuration. It does not have an independent lifecycle.
Methods:
- map String sql = "SET SCHEMA 'abc'";: Map a schema to another one. This will map a schema onto
  another one, depending on configured schema mapping in this DSLContext. If no applicable schema
  mapping can be found, the schema itself is returned.
- map: Map a schema to another one. This will map a schema onto another one, depending on configured
  schema mapping in this DSLContext. If no applicable schema mapping can be found, the schema itself
  is returned.
- parser: Access the parser API.
- parsingConnection: A JDBC connection that runs each statement through the parser() first, prior to
  re-generating and running the SQL. Static statements are translated eagerly upon execution, e.g.
  of Statement.executeQuery(String). Prepared statements are prepared lazily once all bind variables
  are available, because the specific bind value and type may influence the generated SQL. As such,
  a PreparedStatement created from a parsing connection does not yet allocate any server side
  resources until it is executed for the first time. The Configuration.cacheProvider() is called for
  CacheType.CACHE_PARSING_CONNECTION to provide a translation cache to avoid the overhead of re-
  parsing and re-generating the same SQL string all the time. By default, this is an LRU cache. The
  resulting Connection wraps an underlying JDBC connection that has been obtained from
  ConnectionProvider.acquire() and must be released by calling Connection.close(), which calls
  ConnectionProvider.release(Connection).
- parsingDataSource: A JDBC data source that runs each statement through the parser() first, prior
  to re-generating and running the SQL. This simply wraps the parsingConnection() in a DataSource.
- parsingConnectionFactory: An R2DBC ConnectionFactory that runs each statement through the parser()
  first, prior to re-generating and running the SQL.
- diagnosticsConnection: A JDBC connection that proxies the underlying connection to run the jOOQ
  Diagnostics Pack on executed queries.
- diagnosticsDataSource: A JDBC connection that proxies the underlying connection to run the jOOQ
  Diagnostics Pack on executed queries. This simply wraps the diagnosticsConnection() in a
  DataSource.
- migrations: The experimental migrations API. This is EXPERIMENTAL functionality and subject to
  change in future jOOQ versions.
- meta: Access the database meta data. This method returns meta information provided by
  Configuration.metaProvider(), which defaults to a wrapper type that gives access to your JDBC
  connection's DatabaseMetaData as obtained from your ConnectionProvider.
- informationSchema: Convenience method for Meta.informationSchema().
- explain: Run an EXPLAIN statement in the database to estimate the cardinality of the query.
- transactionResult: Run a TransactionalCallable in the context of this DSLContext's underlying
  Scope.configuration()'s Configuration.transactionProvider(), and return the transactional's
  outcome. The argument transactional code should not capture any scope but derive its Configuration
  from the TransactionalCallable.run(Configuration) argument in order to create new statements.
- transaction: Run a TransactionalRunnable in the context of this DSLContext's underlying
  Scope.configuration()'s Configuration.transactionProvider(). The argument transactional code
  should not capture any scope but derive its Configuration from the
  TransactionalCallable.run(Configuration) argument in order to create new statements.
- transactionResultAsync: Run a TransactionalCallable asynchronously. The TransactionCallable is run
  in the context of this DSLContext's underlying Scope.configuration()'s
  Configuration.transactionProvider(), and returns the transactional's outcome in a new
  CompletionStage that is asynchronously completed by a task run by an Executor provided by the
  underlying Scope.configuration()'s Configuration.executorProvider().
- transactionAsync: Run a TransactionalRunnable asynchronously. The TransactionRunnable is run in
  the context of this DSLContext's underlying Scope.configuration()'s
  Configuration.transactionProvider(), and returns the transactional's outcome in a new
  CompletionStage that is asynchronously completed by a task run by an Executor provided by the
  underlying Scope.configuration()'s Configuration.executorProvider().
- transactionPublisher: Run a TransactionalPublishable reactively.
- connectionResult: Run a ConnectionCallable in the context of this DSLContext's underlying
  Scope.configuration()'s Configuration.connectionProvider().
- connection: Run a ConnectionRunnable in the context of this DSLContext's underlying
  Scope.configuration()'s Configuration.connectionProvider().
- mockResult: Run a MockRunnable in the context of this DSLContext 's underlying
  Scope.configuration()'s, and of a MockDataProvider and return the mockable's outcome.
- mock: Run a MockRunnable in the context of this DSLContext 's underlying Scope.configuration()'s,
  and of a MockDataProvider.
- renderContext: Get a new RenderContext for the context of this DSLContext. This will return an
  initialised render context as such: Context.castMode() == DEFAULT Context.declareFields() == false
  Context.declareTables() == false Context.format() == false Context.paramType() ==
  ParamType.INDEXED Context.qualify() == true Context.subquery() == false
- render: Render a QueryPart in the context of this DSLContext. This is the same as calling
  renderContext().render(part)
- renderNamedParams: Render a QueryPart in the context of this DSLContext, rendering bind variables
  as named parameters. This is the same as calling renderContext().paramType(NAMED).render(part)
- renderNamedOrInlinedParams: Render a QueryPart in the context of this DSLContext, rendering bind
  variables as named parameters, or inlined parameters if they have no name. This is the same as
  calling renderContext().paramType(NAMED_OR_INLINED).render(part)
- renderInlined: Render a QueryPart in the context of this DSLContext, inlining all bind variables.
  This is the same as calling renderContext().inline(true).render(part)
- extractBindValues: Retrieve the bind values that will be bound by a given QueryPart. The returned
  List is immutable. To modify bind values, use extractParams(QueryPart) instead. Unlike
  extractParams(QueryPart), which returns also inlined parameters, this returns only actual bind
  values that will render an actual bind value as a question mark "?"
- extractParams: Get a Map of named parameters. The Map itself is immutable, but the Param elements
  allow for modifying bind values on an existing Query (or any other QueryPart). Bind values created
  with DSL.val(Object) will have their bind index as name.
- extractParam: Get a named parameter from a QueryPart, provided its name. Bind values created with
  DSL.val(Object) will have their bind index as name.
- bindContext: Get a new BindContext for the context of this DSLContext. This will return an
  initialised bind context as such: Context.declareFields() == false Context.declareTables() ==
  false BindContext for JOOQ INTERNAL USE only. Avoid referencing it directly
- attach: Attach this DSLContext's underlying Scope.configuration() to some attachables.
- loadInto: Create a new Loader object to load data from a CSV or XML source.
- queries: Wrap a collection of queries.
- begin: Wrap a collection of statements in an anonymous procedural block.
- query String sql = "SET SCHEMA 'abc'";: Create a new query holding plain SQL. There must not be
  any binding variables contained in the SQL. Example: String sql = "SET SCHEMA 'abc'"; NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses!
- query // The following query query("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will render this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Create a new query holding plain SQL. Unlike query(String, Object...), the SQL passed to
  this method should not contain any bind variables. Instead, you can pass QueryPart objects to the
  method which will be rendered at indexed locations of your SQL string as such: // The following
  query query("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); // Will render this
  SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When inserting plain
  SQL into jOOQ objects, you must guarantee syntax integrity. You may also create the possibility of
  malicious SQL injection. Be sure to properly use bind variables and/or escape literals when
  concatenated into SQL clauses! One way to escape literals is to use DSL.name(String...) and
  similar methods
- fetch String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain SQL.
  Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite): String
  sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects, you must
  guarantee syntax integrity. You may also create the possibility of malicious SQL injection. Be
  sure to properly use bind variables and/or escape literals when concatenated into SQL clauses!
- fetch // The following query fetch("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetch(String, Object...), the SQL passed to
  this method should not contain any bind variables. Instead, you can pass QueryPart objects to the
  method which will be rendered at indexed locations of your SQL string as such: // The following
  query fetch("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); // Will execute
  this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When inserting
  plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create the
  possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetchLazy String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL and "lazily" return the generated result. The returned Cursor holds a reference to the
  executed PreparedStatement and the associated ResultSet. Data can be fetched (or iterated over)
  lazily, fetching records from the ResultSet one by one. Example (Postgres): String sql = "FETCH
  ALL IN \"<unnamed cursor 1>\""; Example (SQLite): String sql = "pragma table_info('my_table')";
  NOTE: When inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may
  also create the possibility of malicious SQL injection. Be sure to properly use bind variables
  and/or escape literals when concatenated into SQL clauses! Depending on your JDBC driver's default
  behaviour, this may load the whole database result into the driver's memory. In order to indicate
  to the driver that you may not want to fetch all records at once, use ResultQuery.fetchSize(int)
  and run ResultQuery.fetchLazy() instead, or specify Settings.setFetchSize(Integer) prior to
  calling this method. Client code is responsible for closing the cursor after use.
- fetchLazy // The following query fetchLazy("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL and "lazily" return the generated result. The
  returned Cursor holds a reference to the executed PreparedStatement and the associated ResultSet.
  Data can be fetched (or iterated over) lazily, fetching records from the ResultSet one by one.
  Unlike fetchLazy(String, Object...), the SQL passed to this method should not contain any bind
  variables. Instead, you can pass QueryPart objects to the method which will be rendered at indexed
  locations of your SQL string as such: // The following query fetchLazy("select {0}, {1} from {2}",
  val(1), inline("test"), name("DUAL")); // Will execute this SQL by default, using
  SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses! One way to escape literals is to use DSL.name(String...) and similar methods
  Depending on your JDBC driver's default behaviour, this may load the whole database result into
  the driver's memory. In order to indicate to the driver that you may not want to fetch all records
  at once, use ResultQuery.fetchSize(int) and run ResultQuery.fetchLazy() instead, or specify
  Settings.setFetchSize(Integer) prior to calling this method. Client code is responsible for
  closing the cursor after use.
- fetchAsync String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Fetch results in a new
  CompletionStage. The result is asynchronously completed by a task running in an Executor provided
  by the Scope.configuration()'s Configuration.executorProvider(). Example (Postgres): String sql =
  "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite): String sql = "pragma
  table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects, you must guarantee
  syntax integrity. You may also create the possibility of malicious SQL injection. Be sure to
  properly use bind variables and/or escape literals when concatenated into SQL clauses!
- fetchAsync // The following query fetchLazy("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Fetch results in a new CompletionStage. The result is asynchronously completed by a task
  running in an Executor provided by the Scope.configuration()'s Configuration.executorProvider().
  Unlike fetchLazy(String, Object...), the SQL passed to this method should not contain any bind
  variables. Instead, you can pass QueryPart objects to the method which will be rendered at indexed
  locations of your SQL string as such: // The following query fetchLazy("select {0}, {1} from {2}",
  val(1), inline("test"), name("DUAL")); // Will execute this SQL by default, using
  SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses! One way to escape literals is to use DSL.name(String...) and similar methods
- fetchStream String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL and "lazily" return the generated result. The returned Stream holds a reference to the
  executed PreparedStatement and the associated ResultSet. Data can be fetched (or iterated over)
  lazily, fetching records from the ResultSet one by one. Example (Postgres): String sql = "FETCH
  ALL IN \"<unnamed cursor 1>\""; Example (SQLite): String sql = "pragma table_info('my_table')";
  NOTE: When inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may
  also create the possibility of malicious SQL injection. Be sure to properly use bind variables
  and/or escape literals when concatenated into SQL clauses! Depending on your JDBC driver's default
  behaviour, this may load the whole database result into the driver's memory. In order to indicate
  to the driver that you may not want to fetch all records at once, use ResultQuery.fetchSize(int)
  and run ResultQuery.fetchStream() instead, or specify Settings.setFetchSize(Integer) prior to
  calling this method. Client code is responsible for closing the stream after use.
- fetchStream // The following query fetchLazy("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL and "lazily" return the generated result. The
  returned Stream holds a reference to the executed PreparedStatement and the associated ResultSet.
  Data can be fetched (or iterated over) lazily, fetching records from the ResultSet one by one.
  Unlike fetchStream(String, Object...), the SQL passed to this method should not contain any bind
  variables. Instead, you can pass QueryPart objects to the method which will be rendered at indexed
  locations of your SQL string as such: // The following query fetchLazy("select {0}, {1} from {2}",
  val(1), inline("test"), name("DUAL")); // Will execute this SQL by default, using
  SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses! One way to escape literals is to use DSL.name(String...) and similar methods
  Depending on your JDBC driver's default behaviour, this may load the whole database result into
  the driver's memory. In order to indicate to the driver that you may not want to fetch all records
  at once, use ResultQuery.fetchSize(int) and run ResultQuery.fetchStream() instead, or specify
  Settings.setFetchSize(Integer) prior to calling this method. Client code is responsible for
  closing the stream after use.
- fetchMany String sql = "sp_help 'my_table'";: Execute a new query holding plain SQL, possibly
  returning several result sets. Example (Sybase ASE): String sql = "sp_help 'my_table'"; NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses!
- fetchMany // The following query fetchMany("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL, possibly returning several result sets. Unlike
  fetchMany(String, Object...), the SQL passed to this method should not contain any bind variables.
  Instead, you can pass QueryPart objects to the method which will be rendered at indexed locations
  of your SQL string as such: // The following query fetchMany("select {0}, {1} from {2}", val(1),
  inline("test"), name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE:
  select ?, 'test' from "DUAL" NOTE: When inserting plain SQL into jOOQ objects, you must guarantee
  syntax integrity. You may also create the possibility of malicious SQL injection. Be sure to
  properly use bind variables and/or escape literals when concatenated into SQL clauses! One way to
  escape literals is to use DSL.name(String...) and similar methods
- fetchOne String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite):
  String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchOne // The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetchOne(String, Object...), the SQL passed
  to this method should not contain any bind variables. Instead, you can pass QueryPart objects to
  the method which will be rendered at indexed locations of your SQL string as such: // The
  following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); //
  Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetchSingle String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite):
  String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchSingle // The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetchOne(String, Object...), the SQL passed
  to this method should not contain any bind variables. Instead, you can pass QueryPart objects to
  the method which will be rendered at indexed locations of your SQL string as such: // The
  following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); //
  Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetchOptional String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding
  plain SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example
  (SQLite): String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ
  objects, you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchOptional // The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetchOne(String, Object...), the SQL passed
  to this method should not contain any bind variables. Instead, you can pass QueryPart objects to
  the method which will be rendered at indexed locations of your SQL string as such: // The
  following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); //
  Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetchValue String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite):
  String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchValue // The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetchValue(String, Object...), the SQL
  passed to this method should not contain any bind variables. Instead, you can pass QueryPart
  objects to the method which will be rendered at indexed locations of your SQL string as such: //
  The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); //
  Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetchOptionalValue String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query
  holding plain SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example
  (SQLite): String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ
  objects, you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchOptionalValue // The following query fetchOne("select {0}, {1} from {2}", val(1),
  inline("test"), name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE:
  select ?, 'test' from "DUAL": Execute a new query holding plain SQL. Unlike fetchValue(String,
  Object...), the SQL passed to this method should not contain any bind variables. Instead, you can
  pass QueryPart objects to the method which will be rendered at indexed locations of your SQL
  string as such: // The following query fetchOne("select {0}, {1} from {2}", val(1),
  inline("test"), name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE:
  select ?, 'test' from "DUAL" NOTE: When inserting plain SQL into jOOQ objects, you must guarantee
  syntax integrity. You may also create the possibility of malicious SQL injection. Be sure to
  properly use bind variables and/or escape literals when concatenated into SQL clauses! One way to
  escape literals is to use DSL.name(String...) and similar methods
- fetchValues String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Execute a new query holding plain
  SQL. Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example (SQLite):
  String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ objects,
  you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- fetchValues // The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike fetchValue(String, Object...), the SQL
  passed to this method should not contain any bind variables. Instead, you can pass QueryPart
  objects to the method which will be rendered at indexed locations of your SQL string as such: //
  The following query fetchOne("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); //
  Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- execute: Execute a query holding plain SQL. NOTE: When inserting plain SQL into jOOQ objects, you
  must guarantee syntax integrity. You may also create the possibility of malicious SQL injection.
  Be sure to properly use bind variables and/or escape literals when concatenated into SQL clauses!
- execute // The following query execute("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Execute a new query holding plain SQL. Unlike execute(String, Object...), the SQL passed
  to this method should not contain any bind variables. Instead, you can pass QueryPart objects to
  the method which will be rendered at indexed locations of your SQL string as such: // The
  following query execute("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL")); // Will
  execute this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE: When
  inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also create
  the possibility of malicious SQL injection. Be sure to properly use bind variables and/or escape
  literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- resultQuery String sql = "FETCH ALL IN \"<unnamed cursor 1>\"";: Create a new query holding plain
  SQL. There must not be any bind variables contained in the SQL Use this method, when you want to
  take advantage of the many ways to fetch results in jOOQ, using ResultQuery. Some examples:
  ResultQuery.fetchLazy() Open a cursor and fetch records one by one ResultQuery.fetchInto(Class)
  Fetch records into a custom POJO (optionally annotated with JPA annotations)
  ResultQuery.fetchInto(RecordHandler) Fetch records into a custom callback (similar to Spring's
  RowMapper) Example (Postgres): String sql = "FETCH ALL IN \"<unnamed cursor 1>\""; Example
  (SQLite): String sql = "pragma table_info('my_table')"; NOTE: When inserting plain SQL into jOOQ
  objects, you must guarantee syntax integrity. You may also create the possibility of malicious SQL
  injection. Be sure to properly use bind variables and/or escape literals when concatenated into
  SQL clauses!
- resultQuery // The following query resultQuery("select {0}, {1} from {2}", val(1), inline("test"),
  name("DUAL")); // Will render this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from
  "DUAL": Create a new query holding plain SQL. Unlike resultQuery(String, Object...), the SQL
  passed to this method should not contain any bind variables. Instead, you can pass QueryPart
  objects to the method which will be rendered at indexed locations of your SQL string as such: //
  The following query resultQuery("select {0}, {1} from {2}", val(1), inline("test"), name("DUAL"));
  // Will render this SQL by default, using SQLDialect.ORACLE: select ?, 'test' from "DUAL" NOTE:
  When inserting plain SQL into jOOQ objects, you must guarantee syntax integrity. You may also
  create the possibility of malicious SQL injection. Be sure to properly use bind variables and/or
  escape literals when concatenated into SQL clauses! One way to escape literals is to use
  DSL.name(String...) and similar methods
- fetch: Fetch all data from a JDBC ResultSet and transform it to a jOOQ Result. After fetching all
  data, the JDBC ResultSet will be closed. Use fetchLazy(ResultSet), to fetch one Record at a time,
  instead of load the entire ResultSet into a jOOQ Result at once.
- fetchOne: Fetch a record from a JDBC ResultSet and transform it to a jOOQ Record. This will
  internally fetch all records and throw an exception if there was more than one resulting record.
- fetchSingle: Fetch a record from a JDBC ResultSet and transform it to a jOOQ Record. This will
  internally fetch all records and throw an exception if there was more than one resulting record.
- fetchOptional: Fetch a record from a JDBC ResultSet and transform it to a jOOQ Record. This will
  internally fetch all records and throw an exception if there was more than one resulting record.
- fetchValue: Fetch a record from a JDBC ResultSet and return the only contained value. This will
  internally fetch all records and throw an exception if there was more than one resulting record.
- fetchOptionalValue: Fetch a record from a JDBC ResultSet and return the only contained value. This
  will internally fetch all records and throw an exception if there was more than one resulting
  record.
- fetchValues: Fetch a result from a JDBC ResultSet and return the only contained column's values.
- fetchLazy: Wrap a JDBC ResultSet into a jOOQ Cursor. Use fetch(ResultSet), to load the entire
  ResultSet into a jOOQ Result at once.
- fetchAsync: Fetch results in a new CompletionStage. The result is asynchronously completed by a
  task running in an Executor provided by the Scope.configuration()'s
  Configuration.executorProvider().
- fetchStream: Wrap a JDBC ResultSet into a jOOQ Stream. Use fetch(ResultSet), to load the entire
  ResultSet into a jOOQ Result at once.
- fetchFromTXT: Fetch all data from a formatted string. The supplied string is supposed to be
  formatted in a human-readable way. This is the same as calling fetchFromTXT(string, "{null}")
- fetchFromTXT +-----+-----+--------------------------+ |COL1 |COL2 |COL3 containing whitespace|
  +-----+-----+--------------------------+ |val1 |1 |some text | |val2 | 2 | more text |
  +-----+-----+--------------------------+: Fetch all data from a formatted string. This method
  supports parsing results from two types of human-readable formats: The jOOQ Formattable.format()
  This format is recognised by the fact that the first line starts with a "plus" sign:
  +-----+-----+--------------------------+ |COL1 |COL2 |COL3 containing whitespace|
  +-----+-----+--------------------------+ |val1 |1 |some text | |val2 | 2 | more text |
  +-----+-----+--------------------------+ This method will decode the above formatted string
  according to the following rules: The number of columns is defined by the number of dash groups in
  the first line. Groups are separated by exactly one "plus" sign The column types are VARCHAR(N)
  where N = number of dashes per dash group The column names are defined by the trimmed text
  contained in the second row The data is defined by the trimmed text contained in the subsequent
  rows The H2 database test data format The supplied string is supposed to be formatted in the
  following, human-readable way: COL1 COL2 COL3 containing whitespace ----- ----
  -------------------------- val1 1 some text val2 2 more text This method will decode the above
  formatted string according to the following rules: The number of columns is defined by the number
  of dash groups in the second line. Groups are separated by space(s) The column types are
  VARCHAR(N) where N = number of dashes per dash group The column names are defined by the trimmed
  text contained in the first row The data is defined by the trimmed text contained in the
  subsequent rows Both parsing methods Both parsing methods make no assumption about the resulting
  data types. Instead, all data is string-based.
- fetchFromHTML <table> <tr><th>COL1</th><th>COL2</th></tr> <tr><td>1</td><td>a</td></tr>
  <tr><td>2</td><td>b</td></tr> </table>: Convert an HTML table into a jOOQ Result. This is the
  inverse operation of Formattable.formatHTML(). It works according to the following parsing rules:
  The input is expected to be well-formed XML. XHTML conformance is not required - i.e. unknown
  elements / attributes, or elements / attributes not specified here, such as <caption>, <thead>,
  <tbody> are simply ignored. The surrounding <table> element is optional, but it may appear only
  once A single row containing table headings <th> is allowed. Further rows containing table
  headings are ignored. Table headings define field names. In the absence of table headings, field
  names are generated. The first row <tr> specifies the number of columns in the table (regardless
  if it contains table headings or not). Subsequent rows containing less columns will be padded.
  Subsequent rows containing more columns will be truncated. Comments are ignored Nested tables are
  not supported Ideal input looks like this: <table> <tr><th>COL1</th><th>COL2</th></tr>
  <tr><td>1</td><td>a</td></tr> <tr><td>2</td><td>b</td></tr> </table>
- fetchFromCSV: Fetch all data from a CSV string. This is the same as calling fetchFromCSV(string,
  ',') and the inverse of calling Formattable.formatCSV(). The first row of the CSV data is required
  to hold field name information. Subsequent rows may contain data, which is interpreted as String.
  Use the various conversion methods to retrieve other data types from the Result:
  Result.getValues(Field, Class) Result.getValues(int, Class) Result.getValues(String, Class)
  Result.getValues(Field, Converter) Result.getValues(int, Converter) Result.getValues(String,
  Converter) Missing values result in null. Empty values result in empty Strings
- fetchFromJSON: Fetch all data from a JSON string. This is the inverse of calling
  Formattable.formatJSON(). Use the various conversion methods to retrieve other data types from the
  Result: Result.getValues(Field, Class) Result.getValues(int, Class) Result.getValues(String,
  Class) Result.getValues(Field, Converter) Result.getValues(int, Converter)
  Result.getValues(String, Converter) Missing values result in null. Empty values result in empty
  Strings
- fetchFromXML: Fetch all data from an XML string. This is the inverse of calling
  Formattable.formatXML(). Use the various conversion methods to retrieve other data types from the
  Result: Result.getValues(Field, Class) Result.getValues(int, Class) Result.getValues(String,
  Class) Result.getValues(Field, Converter) Result.getValues(int, Converter)
  Result.getValues(String, Converter) Missing values result in null. Empty values result in empty
  Strings
- fetchFromStringData: Fetch all data from a list of strings. This is used by methods such as
  fetchFromCSV(String) fetchFromTXT(String) The first element of the argument list should contain
  column names. Subsequent elements contain actual data. The degree of all arrays contained in the
  argument should be the same, although this is not a requirement. jOOQ will ignore excess data, and
  fill missing data with null.
- with: Create a WITH clause to supply subsequent SELECT, UPDATE, INSERT, DELETE, and MERGE
  statements with CommonTableExpressions. The RECURSIVE keyword may be optional or unsupported in
  some databases, in case of which it will not be rendered. For optimal database interoperability
  and readability, however, it is suggested that you use with(String) for strictly non-recursive CTE
  and withRecursive(String) for strictly recursive CTE.
- withRecursive: Create a WITH clause to supply subsequent SELECT, UPDATE, INSERT, DELETE, and MERGE
  statements with CommonTableExpressions. The RECURSIVE keyword may be optional or unsupported in
  some databases, in case of which it will not be rendered. For optimal database interoperability
  and readability, however, it is suggested that you use with(String) for strictly non-recursive CTE
  and withRecursive(String) for strictly recursive CTE.
- selectFrom SELECT table.col1, table.col2 FROM table: Create a new DSL select statement, projecting
  the known columns from a table. This will project the known columns from the argument table
  querying Fields.fields(). If no known columns are available (e.g. because the table has been
  created using DSL.table(String)), then SELECT * is projected. Example: SELECT table.col1,
  table.col2 FROM table
- selectFrom SELECT * FROM table: Create a new DSL select statement, projecting *. Without knowing
  any columns from the argument table (see selectFrom(TableLike)), this will project SELECT *.
  Example: SELECT * FROM table
- select DSLContext create = DSL.using(configuration); create.select(fields) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This creates an attached, renderable and executable SELECT statement
  from this DSLContext. If you don't need to render or execute this SELECT statement (e.g. because
  you want to create a subselect), consider using the static DSL.select(Collection) instead.
  Example: DSLContext create = DSL.using(configuration); create.select(fields) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2); Note that
  passing an empty collection conveniently produces SELECT * semantics, i.e. it: Renders SELECT
  tab1.col1, tab1.col2, …, tabN.colN if all columns are known Renders SELECT * if not all columns
  are known, e.g. when using plain SQL
- select DSLContext create = DSL.using(configuration); create.select(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2)
  .execute();: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.select(SelectFieldOrAsterisk...) instead. Example: DSLContext create =
  DSL.using(configuration); create.select(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2)
  .execute(); Note that passing an empty collection conveniently produces SELECT * semantics, i.e.
  it: Renders SELECT tab1.col1, tab1.col2, …, tabN.colN if all columns are known Renders SELECT * if
  not all columns are known, e.g. when using plain SQL
- select using(configuration) .select(field1) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as select(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Field.in(Select), Field.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.select(SelectField)
  instead. Example: using(configuration) .select(field1) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row2.in(Select),
  Row2.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField) instead. Example: using(configuration)
  .select(field1, field2) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row3.in(Select),
  Row3.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row4.in(Select),
  Row4.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, field4, field5) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row5.in(Select),
  Row5.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .select(field1, field2, field3, field4, field5)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field5, field6) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row6.in(Select),
  Row6.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .select(field1, field2, field3, .., field5,
  field6) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field6, field7) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row7.in(Select),
  Row7.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .select(field1, field2, field3,
  .., field6, field7) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field7, field8) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row8.in(Select),
  Row8.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration) .select(field1,
  field2, field3, .., field7, field8) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field8, field9) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row9.in(Select),
  Row9.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .select(field1, field2, field3, .., field8, field9) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row10.in(Select),
  Row10.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row11.in(Select),
  Row11.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row12.in(Select),
  Row12.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .select(field1, field2, field3, .., field11, field12)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field12, field13) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row13.in(Select),
  Row13.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .select(field1, field2, field3, .., field12,
  field13) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field13, field14) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row14.in(Select),
  Row14.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .select(field1, field2, field3,
  .., field13, field14) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field14, field15) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row15.in(Select),
  Row15.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration) .select(field1,
  field2, field3, .., field14, field15) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field15, field16) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row16.in(Select),
  Row16.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .select(field1, field2, field3, .., field15, field16) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row17.in(Select),
  Row17.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row18.in(Select),
  Row18.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .select(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row19.in(Select),
  Row19.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .select(field1, field2, field3, .., field18, field19)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field19, field20) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row20.in(Select),
  Row20.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .select(field1, field2, field3, .., field19,
  field20) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field20, field21) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row21.in(Select),
  Row21.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .select(field1, field2, field3,
  .., field20, field21) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .select(field1, field2, field3, .., field21, field22) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row22.in(Select),
  Row22.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration) .select(field1,
  field2, field3, .., field21, field22) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct DSLContext create = DSL.using(configuration); create.selectDistinct(fields)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectDistinct(Collection) instead. Example: DSLContext create = DSL.using(configuration);
  create.selectDistinct(fields) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2); Note that passing an empty collection
  conveniently produces SELECT DISTINCT * semantics, i.e. it: Renders SELECT DISTINCT tab1.col1,
  tab1.col2, …, tabN.colN if all columns are known Renders SELECT DISTINCT * if not all columns are
  known, e.g. when using plain SQL
- selectDistinct DSLContext create = DSL.using(configuration); create.selectDistinct(field1, field2)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectDistinct(SelectFieldOrAsterisk...) instead. Example: DSLContext create =
  DSL.using(configuration); create.selectDistinct(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2); Note that
  passing an empty collection conveniently produces SELECT DISTINCT * semantics, i.e. it: Renders
  SELECT DISTINCT tab1.col1, tab1.col2, …, tabN.colN if all columns are known Renders SELECT
  DISTINCT * if not all columns are known, e.g. when using plain SQL
- selectDistinct using(configuration) .selectDistinct(field1) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Field.in(Select),
  Field.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField) instead. Example: using(configuration)
  .selectDistinct(field1) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row2.in(Select),
  Row2.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row3.in(Select),
  Row3.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row4.in(Select),
  Row4.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField) instead.
  Example: using(configuration) .selectDistinct(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, field4, field5)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row5.in(Select), Row5.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .selectDistinct(field1, field2, field3, field4, field5) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field5, field6)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row6.in(Select), Row6.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field5, field6) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field6, field7)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row7.in(Select), Row7.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field6, field7) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field7, field8)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row8.in(Select), Row8.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .selectDistinct(field1, field2, field3, .., field7, field8)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field8, field9)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row9.in(Select), Row9.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .selectDistinct(field1, field2, field3, ..,
  field8, field9) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field9, field10)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row10.in(Select), Row10.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .selectDistinct(field1, field2,
  field3, .., field9, field10) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field10, field11)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row11.in(Select), Row11.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .selectDistinct(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field11, field12)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row12.in(Select), Row12.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .selectDistinct(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field12, field13)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row13.in(Select), Row13.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field12, field13) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field13, field14)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row14.in(Select), Row14.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field13, field14) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field14, field15)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row15.in(Select), Row15.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .selectDistinct(field1, field2, field3, .., field14,
  field15) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field15, field16)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row16.in(Select), Row16.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .selectDistinct(field1, field2, field3, ..,
  field15, field16) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field16, field17)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row17.in(Select), Row17.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .selectDistinct(field1, field2,
  field3, .., field16, field17) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field17, field18)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row18.in(Select), Row18.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .selectDistinct(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field18, field19)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row19.in(Select), Row19.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .selectDistinct(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field19, field20)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row20.in(Select), Row20.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field19, field20) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field20, field21)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row21.in(Select), Row21.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .selectDistinct(field1, field2, field3, .., field20, field21) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .selectDistinct(field1, field2, field3, .., field21, field22)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row22.in(Select), Row22.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .selectDistinct(field1, field2, field3, .., field21,
  field22) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectZero DSLContext create = DSL.using(configuration); create.selectZero() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for a constant 0 literal. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectZero() instead. Example: DSLContext create = DSL.using(configuration);
  create.selectZero() .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectOne DSLContext create = DSL.using(configuration); create.selectOne() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for a constant 1 literal. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectOne() instead. Example: DSLContext create = DSL.using(configuration); create.selectOne()
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectCount DSLContext create = DSL.using(configuration); create.selectCount() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for COUNT(*). This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectCount() instead.
  Example: DSLContext create = DSL.using(configuration); create.selectCount() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectQuery: Create a new SelectQuery
- insertQuery: Create a new InsertQuery
- insertInto DSLContext create = DSL.using(configuration); create.insertInto(table) .set(field1,
  value1) .set(field2, value2) .newRecord() .set(field1, value3) .set(field2, value4)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. This type of insert may feel more convenient to some users, as it uses the
  UPDATE statement's SET a = b syntax. Example: DSLContext create = DSL.using(configuration);
  create.insertInto(table) .set(field1, value1) .set(field2, value2) .newRecord() .set(field1,
  value3) .set(field2, value4) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();
- insertInto using(configuration) .insertInto(table, field1) .values(field1) .values(field1)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .insertInto(table, field1) .values(field1)
  .values(field1) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2) .values(field1, field2)
  .values(field1, field2) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();: Create a new DSL insert statement. Example: using(configuration) .insertInto(table,
  field1, field2) .values(field1, field2) .values(field1, field2) .onDuplicateKeyUpdate()
  .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3) .values(field1, field2,
  field3) .values(field1, field2, field3) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2,
  value2) .execute();: Create a new DSL insert statement. Example: using(configuration)
  .insertInto(table, field1, field2, field3) .values(field1, field2, field3) .values(field1, field2,
  field3) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, field4) .values(field1,
  field2, field3, field4) .values(field1, field2, field3, field4) .onDuplicateKeyUpdate()
  .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL insert statement. Example:
  using(configuration) .insertInto(table, field1, field2, field3, field4) .values(field1, field2,
  field3, field4) .values(field1, field2, field3, field4) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, field4, field5)
  .values(field1, field2, field3, field4, field5) .values(field1, field2, field3, field4, field5)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .insertInto(table, field1, field2, field3, field4,
  field5) .values(field1, field2, field3, field4, field5) .values(field1, field2, field3, field4,
  field5) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field5, field6)
  .values(valueA1, valueA2, valueA3, .., valueA5, valueA6) .values(valueB1, valueB2, valueB3, ..,
  valueB5, valueB6) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field5, field6) .values(valueA1, valueA2, valueA3, .., valueA5, valueA6)
  .values(valueB1, valueB2, valueB3, .., valueB5, valueB6) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field6, field7)
  .values(valueA1, valueA2, valueA3, .., valueA6, valueA7) .values(valueB1, valueB2, valueB3, ..,
  valueB6, valueB7) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field6, field7) .values(valueA1, valueA2, valueA3, .., valueA6, valueA7)
  .values(valueB1, valueB2, valueB3, .., valueB6, valueB7) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field7, field8)
  .values(valueA1, valueA2, valueA3, .., valueA7, valueA8) .values(valueB1, valueB2, valueB3, ..,
  valueB7, valueB8) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field7, field8) .values(valueA1, valueA2, valueA3, .., valueA7, valueA8)
  .values(valueB1, valueB2, valueB3, .., valueB7, valueB8) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field8, field9)
  .values(valueA1, valueA2, valueA3, .., valueA8, valueA9) .values(valueB1, valueB2, valueB3, ..,
  valueB8, valueB9) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field8, field9) .values(valueA1, valueA2, valueA3, .., valueA8, valueA9)
  .values(valueB1, valueB2, valueB3, .., valueB8, valueB9) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field9, field10)
  .values(valueA1, valueA2, valueA3, .., valueA9, valueA10) .values(valueB1, valueB2, valueB3, ..,
  valueB9, valueB10) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field9, field10) .values(valueA1, valueA2, valueA3, .., valueA9, valueA10)
  .values(valueB1, valueB2, valueB3, .., valueB9, valueB10) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field10, field11)
  .values(valueA1, valueA2, valueA3, .., valueA10, valueA11) .values(valueB1, valueB2, valueB3, ..,
  valueB10, valueB11) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field10, field11) .values(valueA1, valueA2, valueA3, .., valueA10, valueA11)
  .values(valueB1, valueB2, valueB3, .., valueB10, valueB11) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field11, field12)
  .values(valueA1, valueA2, valueA3, .., valueA11, valueA12) .values(valueB1, valueB2, valueB3, ..,
  valueB11, valueB12) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field11, field12) .values(valueA1, valueA2, valueA3, .., valueA11, valueA12)
  .values(valueB1, valueB2, valueB3, .., valueB11, valueB12) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field12, field13)
  .values(valueA1, valueA2, valueA3, .., valueA12, valueA13) .values(valueB1, valueB2, valueB3, ..,
  valueB12, valueB13) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field12, field13) .values(valueA1, valueA2, valueA3, .., valueA12, valueA13)
  .values(valueB1, valueB2, valueB3, .., valueB12, valueB13) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field13, field14)
  .values(valueA1, valueA2, valueA3, .., valueA13, valueA14) .values(valueB1, valueB2, valueB3, ..,
  valueB13, valueB14) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field13, field14) .values(valueA1, valueA2, valueA3, .., valueA13, valueA14)
  .values(valueB1, valueB2, valueB3, .., valueB13, valueB14) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field14, field15)
  .values(valueA1, valueA2, valueA3, .., valueA14, valueA15) .values(valueB1, valueB2, valueB3, ..,
  valueB14, valueB15) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field14, field15) .values(valueA1, valueA2, valueA3, .., valueA14, valueA15)
  .values(valueB1, valueB2, valueB3, .., valueB14, valueB15) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field15, field16)
  .values(valueA1, valueA2, valueA3, .., valueA15, valueA16) .values(valueB1, valueB2, valueB3, ..,
  valueB15, valueB16) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field15, field16) .values(valueA1, valueA2, valueA3, .., valueA15, valueA16)
  .values(valueB1, valueB2, valueB3, .., valueB15, valueB16) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field16, field17)
  .values(valueA1, valueA2, valueA3, .., valueA16, valueA17) .values(valueB1, valueB2, valueB3, ..,
  valueB16, valueB17) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field16, field17) .values(valueA1, valueA2, valueA3, .., valueA16, valueA17)
  .values(valueB1, valueB2, valueB3, .., valueB16, valueB17) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field17, field18)
  .values(valueA1, valueA2, valueA3, .., valueA17, valueA18) .values(valueB1, valueB2, valueB3, ..,
  valueB17, valueB18) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field17, field18) .values(valueA1, valueA2, valueA3, .., valueA17, valueA18)
  .values(valueB1, valueB2, valueB3, .., valueB17, valueB18) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field18, field19)
  .values(valueA1, valueA2, valueA3, .., valueA18, valueA19) .values(valueB1, valueB2, valueB3, ..,
  valueB18, valueB19) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field18, field19) .values(valueA1, valueA2, valueA3, .., valueA18, valueA19)
  .values(valueB1, valueB2, valueB3, .., valueB18, valueB19) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field19, field20)
  .values(valueA1, valueA2, valueA3, .., valueA19, valueA20) .values(valueB1, valueB2, valueB3, ..,
  valueB19, valueB20) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field19, field20) .values(valueA1, valueA2, valueA3, .., valueA19, valueA20)
  .values(valueB1, valueB2, valueB3, .., valueB19, valueB20) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field20, field21)
  .values(valueA1, valueA2, valueA3, .., valueA20, valueA21) .values(valueB1, valueB2, valueB3, ..,
  valueB20, valueB21) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field20, field21) .values(valueA1, valueA2, valueA3, .., valueA20, valueA21)
  .values(valueB1, valueB2, valueB3, .., valueB20, valueB21) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto using(configuration) .insertInto(table, field1, field2, field3, .., field21, field22)
  .values(valueA1, valueA2, valueA3, .., valueA21, valueA22) .values(valueB1, valueB2, valueB3, ..,
  valueB21, valueB22) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();:
  Create a new DSL insert statement. Example: using(configuration) .insertInto(table, field1,
  field2, field3, .., field21, field22) .values(valueA1, valueA2, valueA3, .., valueA21, valueA22)
  .values(valueB1, valueB2, valueB3, .., valueB21, valueB22) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();
- insertInto DSLContext create = DSL.using(configuration); create.insertInto(table, field1, field2)
  .values(value1, value2) .values(value3, value4) .onDuplicateKeyUpdate() .set(field1, value1)
  .set(field2, value2) .execute();: Create a new DSL insert statement. Example: DSLContext create =
  DSL.using(configuration); create.insertInto(table, field1, field2) .values(value1, value2)
  .values(value3, value4) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();
- updateQuery: Create a new UpdateQuery
- update DSLContext create = DSL.using(configuration); create.update(table) .set(field1, value1)
  .set(field2, value2) .where(field1.greaterThan(100)) .execute();: Create a new DSL update
  statement. Example: DSLContext create = DSL.using(configuration); create.update(table)
  .set(field1, value1) .set(field2, value2) .where(field1.greaterThan(100)) .execute(); Note that
  some databases support table expressions more complex than simple table references. In MySQL, for
  instance, you can write create.update(t1.join(t2).on(t1.id.eq(t2.id))) .set(t1.value, value1)
  .set(t2.value, value2) .where(t1.id.eq(10)) .execute();
- mergeInto DSLContext create = DSL.using(configuration); create.mergeInto(table) .using(select)
  .on(condition) .whenMatchedThenUpdate() .set(field1, value1) .set(field2, value2)
  .whenNotMatchedThenInsert(field1, field2) .values(value1, value2) .execute();: Create a new DSL
  SQL standard MERGE statement. This statement is available from DSL syntax only. It is known to be
  supported in some way by any of these dialects: dialect support type documentation DB2 SQL:2008
  standard and major enhancements
  http://publib.boulder.ibm.com/infocenter/db2luw/v9/index.jsp?topic=/com.
  ibm.db2.udb.admin.doc/doc/r0010873.htm HSQLDB SQL:2008 standard
  http://hsqldb.org/doc/2.0/guide/dataaccess-chapt.html#N129BA Oracle SQL:2008 standard and minor
  enhancements http://download.oracle.com/docs/cd/B28359_01/server.111/b28286/ statements_9016.htm
  SQL Server Similar to SQL:2008 standard with some major enhancements http://msdn.microsoft.com/de-
  de/library/bb510625.aspx Sybase Similar to SQL:2008 standard with some major enhancements
  http://dcx.sybase.com/1100/en/dbreference_en11/merge-statement.html Example: DSLContext create =
  DSL.using(configuration); create.mergeInto(table) .using(select) .on(condition)
  .whenMatchedThenUpdate() .set(field1, value1) .set(field2, value2)
  .whenNotMatchedThenInsert(field1, field2) .values(value1, value2) .execute();
- mergeInto SQLDialect#HANA: Create a new DSL UPSERT statement (SQLDialect.H2 MERGE) or Ungültige
  Referenz SQLDialect#HANA UPSERT).
- mergeInto: Create a new DSL merge statement (H2-specific syntax).
- deleteQuery: Create a new DeleteQuery
- deleteFrom DSLContext create = DSL.using(configuration); create.deleteFrom(table)
  .where(field1.greaterThan(100)) .execute();: Create a new DSL delete statement. Example:
  DSLContext create = DSL.using(configuration); create.deleteFrom(table)
  .where(field1.greaterThan(100)) .execute(); Some but not all databases support aliased tables in
  delete statements. Note that some databases support table expressions more complex than simple
  table references. In MySQL, for instance, you can write this to form a multi table DELETE
  statement: create.delete(t1.join(t2).on(t1.id.eq(t2.id))) .where(t1.id.eq(10)) .execute(); For
  single table delete statements that depend on multiple tables, use the
  DeleteUsingStep.using(TableLike) clause, instead: create.delete(t1) .using(t2)
  .where(t1.id.eq(t2.id)) .and(t1.id.eq(10)) .execute();
- delete: Create a new DSL delete statement. This is an alias for deleteFrom(Table)
- batched: Run a BatchedRunnable on a BatchedConnection, delaying execution as long as possible
  before batching.
- batchedResult: Run a BatchedRunnable on a BatchedConnection, delaying execution as long as
  possible before batching.
- batch Statement s = connection.createStatement(); for (Query query : queries) {
  s.addBatch(query.getSQL(true)); } s.execute();: Create a batch statement to execute a set of
  queries in batch mode (without bind values). This essentially runs the following logic: Statement
  s = connection.createStatement(); for (Query query : queries) { s.addBatch(query.getSQL(true)); }
  s.execute();
- batch batch(query(queries[0]), query(queries[1]), …): Create a batch statement to execute a set of
  queries in batch mode (without bind values). This is a convenience method for calling
  batch(query(queries[0]), query(queries[1]), …).
- batch create.batch(query) .bind(valueA1, valueA2) .bind(valueB1, valueB2) .execute();: Create a
  batch statement to execute a set of queries in batch mode (with bind values). When running
  create.batch(query) .bind(valueA1, valueA2) .bind(valueB1, valueB2) .execute(); This essentially
  runs the following logic: Statement s = connection.prepareStatement(query.getSQL(false)); for
  (Object[] bindValues : allBindValues) { for (Object bindValue : bindValues) { s.setXXX(bindValue);
  } s.addBatch(); } s.execute(); Note: bind values will be inlined to a static batch query as in
  batch(Query...), if you choose to execute queries with Settings.getStatementType() ==
  StatementType.STATIC_STATEMENT
- batch batch(query(sql)): Create a batch statement to execute a set of queries in batch mode (with
  bind values). This is a convenience method for calling batch(query(sql)).
- batch: Create a batch statement to execute a set of queries in batch mode (with bind values). This
  is a convenience method for calling batch(Query) and then binding values one by one using
  BatchBindStep.bind(Object...) Note: bind values will be inlined to a static batch query as in
  batch(Query...), if you choose to execute queries with Settings.getStatementType() ==
  StatementType.STATIC_STATEMENT
- batch batch(query(sql), bindings): Create a batch statement to execute a set of queries in batch
  mode (with bind values). This is a convenience method for calling batch(query(sql), bindings).
- batchStore // Let's assume, odd numbers result in INSERTs and even numbers in UPDATES // Let's
  also assume a[n] are all of the same type, just as b[n], c[n]... int[] result =
  create.batchStore(a1, a2, a3, b1, a4, c1, b3, a5) .execute();: Create a batch statement to execute
  a set of INSERT and UPDATE queries in batch mode (with bind values) according to
  UpdatableRecord.store() semantics. This batch operation can be executed in two modes: With
  Settings.getStatementType() == StatementType.PREPARED_STATEMENT (the default) In this mode, record
  order is preserved as much as possible, as long as two subsequent records generate the same SQL
  (with bind variables). The number of executed batch operations corresponds to [number of distinct
  rendered SQL statements]. In the worst case, this corresponds to the number of total records. The
  record type order is preserved in the way they are passed to this method. This is an example of
  how statements will be ordered: // Let's assume, odd numbers result in INSERTs and even numbers in
  UPDATES // Let's also assume a[n] are all of the same type, just as b[n], c[n]... int[] result =
  create.batchStore(a1, a2, a3, b1, a4, c1, b3, a5) .execute(); The above results in result.length
  == 8 and the following 4 separate batch statements: INSERT a1, a3, a5 UPDATE a2, a4 INSERT b1, b3
  INSERT c1 With Settings.getStatementType() == StatementType.STATIC_STATEMENT This mode may be
  better for large and complex batch store operations, as the order of records is preserved
  entirely, and jOOQ can guarantee that only a single batch statement is serialised to the database.
  A note on MERGE / UPSERT semantics This method (just like UpdatableRecord.store()) does not
  implement the semantics of an actual UPSERT or MERGE statement, which delegates the decision of
  whether to INSERT or UPDATE a record to the database. The decision is made by the client (jOOQ)
  depending on whether each individual record has been fetched from the database prior to storing
  it.
- batchStore: Create a batch statement to execute a set of INSERT and UPDATE queries in batch mode
  (with bind values) according to UpdatableRecord.store() semantics.
- batchInsert: Create a batch statement to execute a set of INSERT queries in batch mode (with bind
  values) according to TableRecord.insert() semantics.
- batchUpdate: Create a batch statement to execute a set of UPDATE queries in batch mode (with bind
  values) according to UpdatableRecord.update() semantics.
- batchMerge: Create a batch statement to execute a set of MERGE queries in batch mode (with bind
  values) according to UpdatableRecord.merge() semantics.
- batchDelete // Let's assume a[n] are all of the same type, just as b[n], c[n]... int[] result =
  create.batchDelete(a1, a2, a3, b1, a4, c1, c2, a5) .execute();: Create a batch statement to
  execute a set of DELETE queries in batch mode (with bind values) according to
  UpdatableRecord.delete() sematics. This batch operation can be executed in two modes: With
  Settings.getStatementType() == StatementType.PREPARED_STATEMENT (the default) In this mode, record
  order is preserved as much as possible, as long as two subsequent records generate the same SQL
  (with bind variables). The number of executed batch operations corresponds to [number of distinct
  rendered SQL statements]. In the worst case, this corresponds to the number of total records. The
  record type order is preserved in the way they are passed to this method. This is an example of
  how statements will be ordered: // Let's assume a[n] are all of the same type, just as b[n],
  c[n]... int[] result = create.batchDelete(a1, a2, a3, b1, a4, c1, c2, a5) .execute(); The above
  results in result.length == 8 and the following 5 separate batch statements: DELETE a1, a2, a3
  DELETE b1 DELETE a4 DELETE c1, c2 DELETE a5 With Settings.getStatementType() ==
  StatementType.STATIC_STATEMENT This mode may be better for large and complex batch delete
  operations, as the order of records is preserved entirely, and jOOQ can guarantee that only a
  single batch statement is serialised to the database.
- batchDelete: Create a batch statement to execute a set of DELETE queries in batch mode (with bind
  values) according to UpdatableRecord.delete() sematics.
- ddl: Convenience method for Meta.ddl().
- alterDatabase: The ALTER DATABASE statement.
- alterDatabaseIfExists: The ALTER DATABASE IF EXISTS statement.
- alterDomain: The ALTER DOMAIN statement.
- alterDomainIfExists: The ALTER DOMAIN IF EXISTS statement.
- alterIndex: The ALTER INDEX statement.
- alterIndexIfExists: The ALTER INDEX IF EXISTS statement.
- alterSchema: The ALTER SCHEMA statement.
- alterSchemaIfExists: The ALTER SCHEMA IF EXISTS statement.
- alterSequence: The ALTER SEQUENCE statement.
- alterSequenceIfExists: The ALTER SEQUENCE IF EXISTS statement.
- alterType: The ALTER TYPE statement.
- alterTypeIfExists: The ALTER TYPE IF EXISTS statement.
- alterView: The ALTER VIEW statement.
- alterViewIfExists: The ALTER VIEW IF EXISTS statement.
- alterMaterializedView: The ALTER MATERIALIZED VIEW statement.
- alterMaterializedViewIfExists: The ALTER MATERIALIZED VIEW IF EXISTS statement.
- commentOnTable: The COMMENT ON TABLE statement.
- commentOnView: The COMMENT ON VIEW statement.
- commentOnMaterializedView: The COMMENT ON MATERIALIZED VIEW statement.
- commentOnColumn: The COMMENT ON COLUMN statement.
- createDatabase: The CREATE DATABASE statement.
- createDatabaseIfNotExists: The CREATE DATABASE IF NOT EXISTS statement.
- createDomain: The CREATE DOMAIN statement.
- createDomainIfNotExists: The CREATE DOMAIN IF NOT EXISTS statement.
- createIndex: The CREATE INDEX statement.
- createIndexIfNotExists: The CREATE INDEX IF NOT EXISTS statement.
- createUniqueIndex: The CREATE UNIQUE INDEX statement.
- createUniqueIndexIfNotExists: The CREATE UNIQUE INDEX IF NOT EXISTS statement.
- createTable: The CREATE TABLE statement.
- createTableIfNotExists: The CREATE TABLE IF NOT EXISTS statement.
- createTemporaryTable: The CREATE TEMPORARY TABLE statement.
- createTemporaryTableIfNotExists: The CREATE TEMPORARY TABLE IF NOT EXISTS statement.
- createGlobalTemporaryTable: The CREATE GLOBAL TEMPORARY TABLE statement.
- createGlobalTemporaryTableIfNotExists: The CREATE GLOBAL TEMPORARY TABLE IF NOT EXISTS statement.
- createView: The CREATE VIEW statement.
- createViewIfNotExists: The CREATE VIEW IF NOT EXISTS statement.
- createOrReplaceView: The CREATE OR REPLACE VIEW statement.
- createMaterializedView: The CREATE MATERIALIZED VIEW statement.
- createMaterializedViewIfNotExists: The CREATE MATERIALIZED VIEW IF NOT EXISTS statement.
- createOrReplaceMaterializedView: The CREATE OR REPLACE MATERIALIZED VIEW statement.
- createType: The CREATE TYPE statement.
- createTypeIfNotExists: The CREATE TYPE IF NOT EXISTS statement.
- createSchema: The CREATE SCHEMA statement.
- createSchemaIfNotExists: The CREATE SCHEMA IF NOT EXISTS statement.
- createSequence: The CREATE SEQUENCE statement.
- createSequenceIfNotExists: The CREATE SEQUENCE IF NOT EXISTS statement.
- dropDatabase: The DROP DATABASE statement.
- dropDatabaseIfExists: The DROP DATABASE IF EXISTS statement.
- dropDomain: The DROP DOMAIN statement.
- dropDomainIfExists: The DROP DOMAIN IF EXISTS statement.
- dropIndex: The DROP INDEX statement.
- dropIndexIfExists: The DROP INDEX IF EXISTS statement.
- dropSchema: The DROP SCHEMA statement.
- dropSchemaIfExists: The DROP SCHEMA IF EXISTS statement.
- dropSequence: The DROP SEQUENCE statement.
- dropSequenceIfExists: The DROP SEQUENCE IF EXISTS statement.
- dropTable: The DROP TABLE statement.
- dropTableIfExists: The DROP TABLE IF EXISTS statement.
- dropTemporaryTable: The DROP TEMPORARY TABLE statement.
- dropTemporaryTableIfExists: The DROP TEMPORARY TABLE IF EXISTS statement.
- dropType: The DROP TYPE statement.
- dropTypeIfExists: The DROP TYPE IF EXISTS statement.
- dropView: The DROP VIEW statement.
- dropViewIfExists: The DROP VIEW IF EXISTS statement.
- dropMaterializedView: The DROP MATERIALIZED VIEW statement.
- dropMaterializedViewIfExists: The DROP MATERIALIZED VIEW IF EXISTS statement.
- grant: The GRANT statement.
- revoke: The REVOKE statement.
- revokeGrantOptionFor: The REVOKE GRANT OPTION FOR statement.
- set: The SET statement. Set a vendor specific session configuration to a new value.
- setLocal: The SET LOCAL statement. Set a vendor specific transaction-local configuration to a new
  value.
- setCatalog: The SET CATALOG statement. Set the current catalog to a new value.
- setSchema: The SET SCHEMA statement. Set the current schema to a new value.
- truncate: The TRUNCATE statement.
- truncateTable: The TRUNCATE TABLE statement.
- startTransaction: The START TRANSACTION statement. Start a transaction
- savepoint: The SAVEPOINT statement. Specify a savepoint
- releaseSavepoint: The RELEASE SAVEPOINT statement. Release a savepoint
- commit: The COMMIT statement. Commit a transaction
- rollback: The ROLLBACK statement. Rollback a transaction
- alterTable: Create a new DSL ALTER TABLE statement.
- alterTableIfExists: Create a new DSL ALTER TABLE statement.
- lastID SQLDialect#ACCESS: Retrieve the last inserted ID. This is implemented for the following
  dialects: Ungültige Referenz SQLDialect#ACCESS : Using @@identity Ungültige Referenz
  SQLDialect#ASE : Using @@identity SQLDialect.DERBY: Using identity_val_local() SQLDialect.HSQLDB:
  Using identity() Ungültige Referenz SQLDialect#INFORMIX : Using dbinfo('sqlca.sqlerrd1') Ungültige
  Referenz SQLDialect#INGRES : Using last_identity() SQLDialect.MARIADB: Using last_insert_id()
  SQLDialect.MYSQL: Using last_insert_id() SQLDialect.POSTGRES: Using lastval() SQLDialect.SQLITE:
  Using last_insert_rowid() Ungültige Referenz SQLDialect#SQLSERVER : Using @@identity Ungültige
  Referenz SQLDialect#SYBASE : Using @@identity Ungültige Referenz SQLDialect#VERTICA : Using
  last_insert_id()
- nextval: Convenience method to fetch the NEXTVAL for a sequence directly from this DSLContext's
  underlying JDBC Connection.
- nextvals: Convenience method to fetch several NEXTVAL for a sequence directly from this
  DSLContext's underlying JDBC Connection. This is done using DSL.generateSeries(int, int).
- currval: Convenience method to fetch the CURRVAL for a sequence directly from this DSLContext's
  underlying JDBC Connection.
- newRecord: Create a new UDTRecord. The resulting record is attached to this Configuration by
  default. Use Settings.isAttachRecords() to override this behaviour.
- newResult: Create a new empty Result. The result is attached to this Configuration by default.
  This result can be used as a container for records.
- fetchMany: Execute a ResultQuery in the context of this DSLContext and return a cursor.
- fetchMap: Execute the query and return a Map with the first column as the map key and the second
  column as the map value. An exception is thrown, if the keys turn out to be non-unique in the
  result set. Use fetchGroups(ResultQuery) instead, if your keys are non-unique. Whether this
  fetches an intermediate Result (accessible by ExecuteListener implementations), or streams records
  directly to the collector producing the result is governed by
  Settings.getFetchIntermediateResult(). The resulting map is iteration order preserving.
- fetchGroups: Execute the query and return a Map with the first column as the map key and the
  second column as the map values. Unlike fetchMap(ResultQuery), this method allows for non-unique
  keys in the result set. Whether this fetches an intermediate Result (accessible by ExecuteListener
  implementations), or streams records directly to the collector producing the result is governed by
  Settings.getFetchIntermediateResult(). The resulting map is iteration order preserving.
- fetchByExample: Execute a "Query by Example" (QBE) based on an example record.
- fetchCount -- Original query: SELECT id, title FROM book WHERE title LIKE '%a%' -- Wrapped query:
  SELECT count(*) FROM ( SELECT id, title FROM book WHERE title LIKE '%a%' ): Execute a Select query
  in the context of this DSLContext and return a COUNT(*) value. This wraps a pre-existing SELECT
  query in another one to calculate the COUNT(*) value, without modifying the original SELECT. An
  example: -- Original query: SELECT id, title FROM book WHERE title LIKE '%a%' -- Wrapped query:
  SELECT count(*) FROM ( SELECT id, title FROM book WHERE title LIKE '%a%' ) This is particularly
  useful for those databases that do not support the COUNT(*) OVER() window function to calculate
  total results in paged queries.
- fetchCount SELECT COUNT(*) FROM table: Count the number of records in a table. This executes
  SELECT COUNT(*) FROM table
- fetchCount SELECT COUNT(*) FROM table WHERE condition: Count the number of records in a table that
  satisfy a condition. This executes SELECT COUNT(*) FROM table WHERE condition
- fetchExists -- Original query: SELECT id, title FROM book WHERE title LIKE '%a%' -- Wrapped query:
  SELECT EXISTS ( SELECT id, title FROM book WHERE title LIKE '%a%' ): Check if a Select would
  return any records, if it were executed. This wraps a pre-existing SELECT query in another one to
  check for result existence, without modifying the original SELECT. An example: -- Original query:
  SELECT id, title FROM book WHERE title LIKE '%a%' -- Wrapped query: SELECT EXISTS ( SELECT id,
  title FROM book WHERE title LIKE '%a%' )
- fetchExists SELECT EXISTS(SELECT * FROM table): Check if a table has any records. This executes
  SELECT EXISTS(SELECT * FROM table)
- fetchExists SELECT EXISTS(SELECT * FROM table WHERE condition): Check if a table has any records
  that satisfy a condition. This executes SELECT EXISTS(SELECT * FROM table WHERE condition)
- fetch SELECT table.col1, table.col2 FROM table: Execute and return all records for SELECT
  table.col1, table.col2 FROM table. The result and its contained records are attached to this
  Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
- fetch SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return all records for
  SELECT table.col1, table.col2 FROM table WHERE condition. The result and its contained records are
  attached to this Configuration by default. Use Settings.isAttachRecords() to override this
  behaviour.
- fetchOne SELECT table.col1, table.col2 FROM table: Execute and return zero or one record for
  SELECT table.col1, table.col2 FROM table. The resulting record is attached to this Configuration
  by default. Use Settings.isAttachRecords() to override this behaviour.
- fetchOne SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return zero or one
  record for SELECT table.col1, table.col2 FROM table WHERE condition. The resulting record is
  attached to this Configuration by default. Use Settings.isAttachRecords() to override this
  behaviour.
- fetchSingle SELECT table.col1, table.col2 FROM table: Execute and return exactly one record for
  SELECT table.col1, table.col2 FROM table. The resulting record is attached to this Configuration
  by default. Use Settings.isAttachRecords() to override this behaviour.
- fetchSingle SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return exactly
  one record for SELECT table.col1, table.col2 FROM table WHERE condition. The resulting record is
  attached to this Configuration by default. Use Settings.isAttachRecords() to override this
  behaviour.
- fetchSingle SELECT F1, F2, …, FN: Execute and return exactly one record for SELECT F1, F2, …, FN.
  The resulting record is attached to this Configuration by default. Use Settings.isAttachRecords()
  to override this behaviour. Convenience API for calling fetchSingle(ResultQuery) with
  DSL.select(SelectFieldOrAsterisk...).
- fetchOptional SELECT table.col1, table.col2 FROM table: Execute and return zero or one record for
  SELECT table.col1, table.col2 FROM table. The resulting record is attached to this Configuration
  by default. Use Settings.isAttachRecords() to override this behaviour.
- fetchOptional SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return zero or
  one record for SELECT table.col1, table.col2 FROM table WHERE condition. The resulting record is
  attached to this Configuration by default. Use Settings.isAttachRecords() to override this
  behaviour.
- fetchAny SELECT table.col1, table.col2 FROM table LIMIT 1: Execute and return zero or one record
  for SELECT table.col1, table.col2 FROM table LIMIT 1. The resulting record is attached to this
  Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
- fetchAny SELECT table.col1, table.col2 FROM table WHERE condition LIMIT 1: Execute and return zero
  or one record for SELECT table.col1, table.col2 FROM table WHERE condition LIMIT 1. The resulting
  record is attached to this Configuration by default. Use Settings.isAttachRecords() to override
  this behaviour.
- fetchLazy SELECT table.col1, table.col2 FROM table: Execute and return all records lazily for
  SELECT table.col1, table.col2 FROM table. The result and its contained records are attached to
  this Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
  Depending on your JDBC driver's default behaviour, this may load the whole database result into
  the driver's memory. In order to indicate to the driver that you may not want to fetch all records
  at once, use ResultQuery.fetchSize(int) and run ResultQuery.fetchLazy() instead, or specify
  Settings.setFetchSize(Integer) prior to calling this method. Client code is responsible for
  closing the cursor after use.
- fetchLazy SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return all records
  lazily for SELECT table.col1, table.col2 FROM table WHERE condition. The result and its contained
  records are attached to this Configuration by default. Use Settings.isAttachRecords() to override
  this behaviour. Depending on your JDBC driver's default behaviour, this may load the whole
  database result into the driver's memory. In order to indicate to the driver that you may not want
  to fetch all records at once, use ResultQuery.fetchSize(int) and run ResultQuery.fetchLazy()
  instead, or specify Settings.setFetchSize(Integer) prior to calling this method. Client code is
  responsible for closing the cursor after use.
- fetchAsync SELECT table.col1, table.col2 FROM table: Execute and return all records asynchronously
  for SELECT table.col1, table.col2 FROM table. The result and its contained records are attached to
  this Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
- fetchAsync SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return all
  records asynchronously for SELECT table.col1, table.col2 FROM table WHERE condition. The result
  and its contained records are attached to this Configuration by default. Use
  Settings.isAttachRecords() to override this behaviour.
- fetchStream SELECT table.col1, table.col2 FROM table: Execute and return all records lazily for
  SELECT table.col1, table.col2 FROM table. The result and its contained records are attached to
  this Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
  Depending on your JDBC driver's default behaviour, this may load the whole database result into
  the driver's memory. In order to indicate to the driver that you may not want to fetch all records
  at once, use ResultQuery.fetchSize(int) and run ResultQuery.fetchStream() instead, or specify
  Settings.setFetchSize(Integer) prior to calling this method. Client code is responsible for
  closing the stream after use.
- fetchStream SELECT table.col1, table.col2 FROM table WHERE condition: Execute and return all
  records lazily for SELECT table.col1, table.col2 FROM table WHERE condition. The result and its
  contained records are attached to this Configuration by default. Use Settings.isAttachRecords() to
  override this behaviour. Depending on your JDBC driver's default behaviour, this may load the
  whole database result into the driver's memory. In order to indicate to the driver that you may
  not want to fetch all records at once, use ResultQuery.fetchSize(int) and run
  ResultQuery.fetchStream() instead, or specify Settings.setFetchSize(Integer) prior to calling this
  method. Client code is responsible for closing the stream after use.
- executeInsert INSERT INTO [table] ([touched or modified columns in record]) VALUES ([touched or
  modified values in record]): Insert one record. This executes the following statement: INSERT INTO
  [table] ([touched or modified columns in record]) VALUES ([touched or modified values in record])
  Unlike UpdatableRecord.insert(), this does not change any of the argument record's internal
  Record.touched() flags, such that a subsequent call to UpdatableRecord.insert() might lead to
  another INSERT statement being executed. This context's Settings.getRecordDirtyTracking() may be
  used to specify whether Record.touched() or only Record.modified() fields are being taken into
  consideration for the INSERT statement. Also any optimistic locking related Settings do not apply
  for this method.
- executeUpdate UPDATE [table] SET [modified values in record] WHERE [record is supplied record]:
  Update a table. This executes the following statement: UPDATE [table] SET [modified values in
  record] WHERE [record is supplied record] This context's Settings.getRecordDirtyTracking() may be
  used to specify whether Record.touched() or only Record.modified() fields are being taken into
  consideration for the INSERT statement. Any optimistic locking related Settings do not apply for
  this method.
- executeUpdate UPDATE [table] SET [touched or modified values in record] WHERE [condition]: Update
  a table. This executes the following statement: UPDATE [table] SET [touched or modified values in
  record] WHERE [condition] This context's Settings.getRecordDirtyTracking() may be used to specify
  whether Record.touched() or only Record.modified() fields are being taken into consideration for
  the INSERT statement. Any optimistic locking related Settings do not apply for this method.
- executeDelete DELETE FROM [table] WHERE [record is supplied record]: Delete a record from a table.
  This executes the following statement: DELETE FROM [table] WHERE [record is supplied record] Any
  optimistic locking related Settings do not apply for this method.
- executeDelete DELETE FROM [table] WHERE [condition]: Delete a record from a table. This executes
  the following statement: DELETE FROM [table] WHERE [condition] Any optimistic locking related
  Settings do not apply for this method.

DataType (class, org.jooq)
A common interface to all dialect-specific data types. jOOQ provides built in data types through
SQLDataType. Users can define their own data types programmatically by calling
asConvertedDataType(Converter) or asConvertedDataType(Binding), for example. Custom data types can
also be defined on generated code using the <forcedType/> configuration, see the manual for more
details
Methods:
- getSQLDataType #getUserType(): Get the standard SQL data type of this (dialect-specific) data type
  if available.
- getSQLDataType: Get the standard SQL data type of this (dialect-specific) data type if available.
- getDataType: The dialect-specific data type representing this data type.
- getSQLType: Get JDBC Types value.
- getBinding: Get the data type binding associated with this data type.
- getConverter: Get the converter associated with this data type.
- getType #getUserType(): Retrieve the Java type associated with this data type. This is the same as
  Ungültige Referenz #getUserType() .
- getFromType: The Converter.fromType() (or database type) in case this DataType has a converter.
- getToType: The Converter.toType() (or user type) in case this DataType has a converter.
- getDomain: Get the defining DOMAIN type or NULL if there is no such type.
- getRow: Get the nested record's Row definition, if this is a isRecord(), or a isMultiset(), or
  NULL otherwise.
- getRecordType: Get the nested record's record type definition, if this is a isRecord(), or a
  isMultiset(), or NULL otherwise.
- getArrayType: Retrieve the Java type associated with ARRAYs of this data type.
- getArrayDataType // Doesn't work DataTypeUngültige Eingabe: "<"UserType[]> t1 =
  SQLDataType.INTEGER.asConvertedDataType(binding).getArrayDataType(); // Works DataTypeUngültige
  Eingabe: "<"UserType[]> t2 =
  SQLDataType.INTEGER.getArrayDataType().asConvertedDataType(arrayBinding);: Retrieve the data type
  for an ARRAY of this data type. Built-in data types, as well as custom data types that have a
  custom getConverter() can be translated to array data types using Converter.forArrays(). Data
  types with custom getBinding() cannot be translated to an array data type. Use this idiom,
  instead: // Doesn't work DataTypeUngültige Eingabe: "<"UserType[]> t1 =
  SQLDataType.INTEGER.asConvertedDataType(binding).getArrayDataType(); // Works DataTypeUngültige
  Eingabe: "<"UserType[]> t2 =
  SQLDataType.INTEGER.getArrayDataType().asConvertedDataType(arrayBinding);
- array: A convenient short for form getArrayDataType() for DSL usage
- getArrayComponentType: Retrieve the Java component type if this is an ARRAY type, or null,
  otherwise. E.g. for DataTypeUngültige Eingabe: "<"String[][][]>, this will return String[][].
- getArrayComponentDataType: Retrieve the Java component data type if this is an ARRAY type, or
  null, otherwise. E.g. for DataTypeUngültige Eingabe: "<"String[][][]>, this will return
  DataType<String[][]>.
- getArrayBaseType: Retrieve the Java base type if this is an ARRAY type, or getType(), otherwise.
  E.g. for DataTypeUngültige Eingabe: "<"String[][][]>, this will return String.
- getArrayBaseDataType: Retrieve the Java component data type if this is an ARRAY type, or this,
  otherwise. E.g. for DataTypeUngültige Eingabe: "<"String[][][]>, this will return
  DataType<String>.
- asEnumDataType: Retrieve the data type for a given enum data type.
- asConvertedDataType: Retrieve the data type for a given converter.
- asConvertedDataTypeFrom: Convenience method for converting this type to a read-only type using
  Converter.from(Class, Class, Function).
- asConvertedDataTypeTo: Convenience method for converting this type to a write-only type using
  Converter.to(Class, Class, Function).
- getTypeName: Retrieve the dialect-specific type name associated with this data type.
- getCastTypeName: Retrieve the dialect-specific type name associated with this data type used for
  casting. This is useful for some dialects that have specialised type names for cast expressions.
  Other dialects require type-length binding when casting, (e.g. VARCHAR(32767))
- getDialect: Retrieve the underlying SQLDialect.
- convert Convert#convert(Object, Class): Convert an arbitrary object into <T>. See Ungültige
  Referenz Convert#convert(Object, Class) for details about conversion rules. Notice this does not
  pass through any Configuration.converterProvider().
- nullability: Return a new data type like this, with a new nullability. [#5709] A nullable column
  cannot have an identity().
- nullable: Return a new data type like this, with a new nullability. This is the same as calling
  nullability(Nullability) with any of Nullability.NULL or Nullability.NOT_NULL as an argument.
  [#5709] A nullable column cannot have an identity().
- hidden: Return a new data type like this, with a new hidden attribute. This feature is implemented
  in commercial distributions only.
- readonly: Return a new data type like this, with a new readonly attribute. This feature is
  implemented in commercial distributions only.
- readonlyInternal: Get the readonly attribute of this data type, combined with other flags that
  influence readonly behaviour. A column may be marked as readonly() for various reasons, including:
  When it is marked as readonly explicitly by the code generator. When it is marked as readonly
  implicitly because it's a computed column with QOM.GenerationLocation.SERVER or with
  QOM.GenerationLocation.CLIENT and QOM.GenerationOption.VIRTUAL. Some columns are readonly for
  users, meaning users of the jOOQ API cannot write to them, but jOOQ, internally, may still write
  to those columns. Such columns may include: Columns that are computed with
  QOM.GenerationLocation.CLIENT and QOM.GenerationOption.STORED Columns used for optimistic locking
  This method returns the static information for this data type. The information may be overridden
  by a Settings value, e.g. Settings.isEmulateComputedColumns(), in case of which
  readonlyInternal(Configuration) should be called. This feature is implemented in commercial
  distributions only.
- computed: Whether this column is computed. This feature is implemented in commercial distributions
  only.
- computedOnServer: Whether this column is computed on the server. This is true only if all of these
  hold true: computed() generationLocation() == QOM.GenerationLocation.SERVER This method returns
  the static information for this data type. The information may be overridden by a Settings value,
  e.g. Settings.isEmulateComputedColumns(), in case of which computedOnServer(Configuration) should
  be called. This feature is implemented in commercial distributions only.
- computedOnClient: Whether this column is computed on the client. This is true only if all of these
  hold true: computed() generationLocation() == QOM.GenerationLocation.CLIENT This method returns
  the static information for this data type. The information may be overridden by a Settings value,
  e.g. Settings.isEmulateComputedColumns(), in case of which computedOnClient(Configuration) should
  be called. This feature is implemented in commercial distributions only.
- computedOnClientStored: Whether this column is computed on the client. This is true only if all of
  these hold true: computed() generationLocation() == QOM.GenerationLocation.CLIENT
  generationOption() == QOM.GenerationOption.STORED generatedAlwaysAsGenerator() produces a
  generator that Generator.supports(GeneratorStatementType) any of GeneratorStatementType.INSERT or
  GeneratorStatementType.UPDATE This method returns the static information for this data type. The
  information may be overridden by a Settings value, e.g. Settings.isEmulateComputedColumns(), in
  case of which computedOnClientStored(Configuration) should be called. This feature is implemented
  in commercial distributions only.
- computedOnClientStoredOn: Whether this column is computed on the client. This is true only if all
  of these hold true: computed() generationLocation() == QOM.GenerationLocation.CLIENT
  generationOption() == QOM.GenerationOption.STORED generatedAlwaysAsGenerator() produces a
  generator that Generator.supports(GeneratorStatementType) the argument statementType This method
  returns the static information for this data type. The information may be overridden by a Settings
  value, e.g. Settings.isEmulateComputedColumns(), in case of which
  computedOnClientStoredOn(GeneratorStatementType, Configuration) should be called. This feature is
  implemented in commercial distributions only.
- computedOnClientVirtual: Whether this column is computed on the client. This is true only if all
  of these hold true: computed() generationLocation() == QOM.GenerationLocation.CLIENT
  generationOption() == QOM.GenerationOption.VIRTUAL generatedAlwaysAsGenerator() produces a
  generator that Generator.supports(GeneratorStatementType) the type GeneratorStatementType.SELECT
  This method returns the static information for this data type. The information may be overridden
  by a Settings value, e.g. Settings.isEmulateComputedColumns(), in case of which
  computedOnClientVirtual(Configuration) should be called. This feature is implemented in commercial
  distributions only.
- generatedAlwaysAs: Set the computed column expression of this data type to a constant value. This
  implicitly sets readonly() to true. This feature is implemented in commercial distributions only.
- generatedAlwaysAsGenerator: Get the computed column expression of this data type, if any. This
  feature is implemented in commercial distributions only.
- stored: Set the generationOption() of the computed column expression to
  QOM.GenerationOption.STORED. If not supported by the dialect, this will be ignored. This feature
  is implemented in commercial distributions only.
- virtual: Set the generationOption() of the computed column expression to
  QOM.GenerationOption.VIRTUAL. If not supported by the dialect, this will be ignored. This feature
  is implemented in commercial distributions only.
- generationOption: Set the generationOption() of the computed column expression. If not supported
  by the dialect, this will be ignored. This feature is implemented in commercial distributions
  only.
- generationLocation: Set the generationLocation() of the computed column expression. Specifies
  whether the generatedAlwaysAs() expression is computed on the QOM.GenerationLocation.SERVER (by
  default) or in the QOM.GenerationLocation.CLIENT. The latter is supported in all dialects, the
  former only in relevant dialects. The computation happens in Insert, Update, or Merge statements
  in case generationOption() is QOM.GenerationOption.STORED, or in Select in case the
  generationOption() is QOM.GenerationOption.VIRTUAL. This feature is implemented in commercial
  distributions only.
- null_: Synonym for nullable(boolean), passing true as an argument.
- notNull: Synonym for nullable(boolean), passing false as an argument.
- collation: Return a new data type like this, with a new collation.
- characterSet: Return a new data type like this, with a new character set.
- autoIncrement: Return a new data type like this, with the identity(boolean) flag set to true.
  [#5709] The IDENTITY flag imposes a NOT NULL constraint, and removes all DEFAULT values. This is
  the same as calling identity(true).
- generatedByDefaultAsIdentity: Return a new data type like this, with the identity(boolean) flag
  set to true. [#5709] The IDENTITY flag imposes a NOT NULL constraint, and removes all DEFAULT
  values. This is the same as calling identity(true).
- identity: Return a new data type like this, with a new identity flag. [#5709] The IDENTITY flag
  imposes a NOT NULL constraint, and removes all DEFAULT values.
- defaultValue: Specify an expression to be applied as the DEFAULT value for this data type. [#5709]
  A defaulted column cannot have an identity(). This is an alias for default_(Object).
- default_: Specify an expression to be applied as the DEFAULT value for this data type. [#5709] A
  defaulted column cannot have an identity().
- defaulted: Get the defaultability of this data type.
- precision: Return a new data type like this, with a new precision value. This will have no effect
  if hasPrecision() is false This is the same as calling precision(int, int) with scale == 0
- hasPrecision: Whether this data type has a precision.
- precisionDefined: Whether the precision returned by precision() is defined. The default precision
  is 0 for all data types. If a data type does not have a precision (see hasPrecision()), or if it
  was initialised without precision (e.g. SQLDataType.TIMESTAMP), then the precision is not defined.
- scale: Return a new data type like this, with a new scale value. This will have no effect if
  hasScale() is false
- hasScale: Whether this data type has a scale.
- scaleDefined: Whether the precision returned by scale() is defined. The default scale is 0 for all
  data types. If a data type does not have a scale (see hasScale()), or if it was initialised
  without scale (e.g. SQLDataType.TIMESTAMP), then the scale is not defined.
- length: Return a new data type like this, with a new length value. This will have no effect if
  hasLength() is false
- hasLength: Whether this data type has a length.
- hasFixedLength: Whether this data type has a fixed length.
- lengthDefined: Whether the precision returned by length() is defined. The default length is 0 for
  all data types. If a data type does not have a length (see hasLength()), or if it was initialised
  without length (e.g. SQLDataType.TIMESTAMP), then the length is not defined.
- isNumeric: Whether this data type is any numeric data type. This applies to any of these types:
  SQLDataType.TINYINT SQLDataType.SMALLINT SQLDataType.INTEGER SQLDataType.BIGINT SQLDataType.FLOAT
  SQLDataType.DOUBLE SQLDataType.REAL SQLDataType.DECIMAL SQLDataType.DECIMAL_INTEGER
  SQLDataType.NUMERIC SQLDataType.DECFLOAT
- isInteger: Whether this data type is any integer data type. This applies to any of these types:
  SQLDataType.TINYINT SQLDataType.SMALLINT SQLDataType.INTEGER SQLDataType.BIGINT
- isFloat: Whether this data type is any floating point data type. This applies to any of these
  types: SQLDataType.FLOAT SQLDataType.DOUBLE SQLDataType.REAL SQLDataType.DECFLOAT
- isDecimal: Whether this data type is any decimal numeric data type. This applies to any of these
  types: SQLDataType.DECIMAL SQLDataType.DECIMAL_INTEGER SQLDataType.NUMERIC SQLDataType.DECFLOAT
- isBoolean: Whether this data type is any boolean data type. This applies to any of these types:
  SQLDataType.BIT SQLDataType.BOOLEAN
- isString: Whether this data type is any character data type. This applies to any of these types:
  SQLDataType.CHAR SQLDataType.CLOB SQLDataType.LONGNVARCHAR SQLDataType.LONGVARCHAR
  SQLDataType.NCHAR SQLDataType.NCLOB SQLDataType.NVARCHAR SQLDataType.VARCHAR
- isNString: Whether this data type is any national character data type. This applies to any of
  these types: SQLDataType.LONGNVARCHAR SQLDataType.NCHAR SQLDataType.NCLOB SQLDataType.NVARCHAR
- isDateTime: Whether this data type is any date or time type. This applies to any of these types.
  SQLDataType.DATE SQLDataType.TIME SQLDataType.TIMESTAMP SQLDataType.LOCALDATE
  SQLDataType.LOCALTIME SQLDataType.LOCALDATETIME SQLDataType.OFFSETTIME SQLDataType.OFFSETDATETIME
  SQLDataType.INSTANT SQLDataType.YEAR
- isDate: Whether this data type is any date type. This applies to any of these types.
  SQLDataType.DATE SQLDataType.LOCALDATE
- isTimestamp: Whether this data type is any timestamp type. This applies to any of these types.
  SQLDataType.TIMESTAMP SQLDataType.LOCALDATETIME
- isTimestampWithTimeZone: Whether this data type is any timestamp type. This applies to any of
  these types. SQLDataType.TIMESTAMPWITHTIMEZONE SQLDataType.INSTANT
- isTime: Whether this data type is any time type. This applies to any of these types.
  SQLDataType.TIME SQLDataType.LOCALTIME
- isTimeWithTimeZone: Whether this data type is any time type. This applies to any of these types.
  SQLDataType.TIMEWITHTIMEZONE
- isTemporal: Whether this data type is any date or time type. This applies to any of these types.
  SQLDataType.DATE SQLDataType.TIME SQLDataType.TIMESTAMP SQLDataType.LOCALDATE
  SQLDataType.LOCALTIME SQLDataType.LOCALDATETIME SQLDataType.OFFSETTIME SQLDataType.OFFSETDATETIME
  SQLDataType.INSTANT SQLDataType.YEAR YearToSecond YearToMonth DayToSecond This is a combination of
  isDateTime() or isInterval()
- isInterval: Whether this data type is any interval type. This applies to any of these types.
  YearToSecond YearToMonth DayToSecond
- isBinary: Whether this data type is any binary type. This applies to any of these types.
  SQLDataType.BINARY SQLDataType.BLOB SQLDataType.LONGVARBINARY SQLDataType.VARBINARY
- isLob: Whether this data type is best deserialised as a LOB. This applies to any of these types.
  SQLDataType.BLOB SQLDataType.CLOB SQLDataType.NCLOB
- isArray: Whether this data type is an array type.
- isAssociativeArray: Whether this data type is an array type.
- isEmbeddable: Whether this data type is an embeddable type.
- isUDT: Whether this data type is a UDT type.
- isRecord: Whether this data type is a nested record type. This is true for anonymous, structural
  nested record types constructed with DSL.row(SelectField...) or for nominal nested record types,
  such as isUDT() or isEmbeddable().
- isMultiset: Whether this data type is a nested collection type. This is true for anonymous,
  structural nested collection types constructed with DSL.multiset(TableLike) or
  DSL.multisetAgg(Field...).
- isEnum: Whether this data type is an enum type.
- isJSON: Whether this data type is a JSON type.
- isXML: Whether this data type is an XML type.
- isSpatial: Whether this data type is a spatial type.
- isUUID: Whether this data type is a UUID type.
- isRowId: Whether this data type is a RowId type.
- isOther: Whether this data type is an OTHER type. The SQLDataType.OTHER type maps any unknown data
  types to a jOOQ DataType. This includes unknown vendor specific types as well as unknown user
  defined types which do not have any custom Converter or Binding attached. The type may still be
  usable with the jOOQ API, but jOOQ's behaviour may not be well defined. Please note that any
  future minor release may add support for a vendor specific type, meaning the type loses its
  "otherness."

Delete (class, org.jooq)
A DELETE statement. Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.deleteFrom(ACTOR) .where(ACTOR.ACTOR_ID.in(1, 2, 3)) .execute(); Instances can be created using
DSL.deleteFrom(Table), DSLContext.deleteFrom(Table), or DSLContext.deleteQuery(Table) and overloads.

DeleteFinalStep (class, org.jooq)
This type is used for the Delete's DSL API. Example: DSLContext create = DSL.using(configuration);
create.delete(table) .where(field1.greaterThan(100)) .execute(); Referencing XYZ*Step types directly
from client code It is usually not recommended to reference any XYZ*Step types directly from client
code, or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases

DeleteQuery (class, org.jooq)
A DELETE statement (model API). This type is the model API representation of a Delete statement,
which can be mutated after creation. The advantage of this API compared to the DSL API is a more
simple approach to writing dynamic SQL. Instances can be created using
DSLContext.deleteQuery(Table).
Methods:
- addUsing: Add tables to the USING clause.
- addConditions: Beschreibung aus Schnittstelle kopiert: ConditionProvider
- addOrderBy: Adds ordering fields.
- addLimit: Limit the results of this select.
- setReturning: Configure the DELETE statement to return all fields in R.
- getReturnedRecord: The record holding returned values as specified by any of the setReturning()
  methods. If the DELETE statement returns several records, this is the same as calling
  getReturnedRecords().get(0) This implemented differently for every dialect: Firebird and Postgres
  have native support for DELETE … RETURNING clauses
- getReturnedRecords: The records holding returned values as specified by any of the setReturning()
  methods. If the DELETE statement returns several records, this is the same as calling
  getReturnedRecords().get(0) This implemented differently for every dialect: Firebird and Postgres
  have native support for DELETE … RETURNING clauses

DeleteWhereStep (class, org.jooq)
This type is used for the Delete's DSL API. Example: DSLContext create = DSL.using(configuration);
create.delete(table) .where(field1.greaterThan(100)) .execute(); Referencing XYZ*Step types directly
from client code It is usually not recommended to reference any XYZ*Step types directly from client
code, or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases
Methods:
- where: Add conditions to the query, connecting them with each other with Operator.AND.
- whereExists: Add an EXISTS clause to the query.
- whereNotExists: Add a NOT EXISTS clause to the query.

DiagnosticsContext (class, org.jooq)
A parameter object that is passed to DiagnosticsListener methods.
Methods:
- part DiagnosticsListener#transformPattern(DiagnosticsContext): The object that was diagnosed if
  available, or null, if there was no specific QueryPart to attach the diagnostic to.
- part: The object that was diagnosed if available, or null, if there was no specific QueryPart to
  attach the diagnostic to.
- transformedPart DiagnosticsListener#transformPattern(DiagnosticsContext): The transformed object
  from part() if available, or null, if there was no specific transformation to attach the
  diagnostic to. This helps diagnosing pattern transformations as indicated by Ungültige Referenz
  DiagnosticsListener#transformPattern(DiagnosticsContext) .
- message: A message describing the diagnostics and the object in question.
- resultSet: The ResultSet available in this context, or null, if there was no result set.
- resultSetConsumedRows: The number of rows that were consumed from resultSet(), or -1 if there was
  no result set.
- resultSetFetchedRows: The number of rows that were actually available from resultSet(), or -1 if
  there was no result set. Calling this method will try to scroll to the end of the resultSet(), in
  order to count the number of rows, which incurs overhead! If the result set is still being
  consumed (i.e. prior to the ResultSet.close() call), and scrolling back to the current row after
  scrolling to the end of resultSet() is not possible (e.g. because the driver supports only
  ResultSet.TYPE_FORWARD_ONLY), then this will return the same value as resultSetConsumedRows().
- resultSetConsumedColumnCount: The number of columns that were consumed from the resultSet(), or -1
  if there was no result set. If the result set is still being consumed (i.e. prior to the
  ResultSet.close() call), then this will return the number of columns that were retrieved from the
  resultSet() set thus far.
- resultSetFetchedColumnCount: The number of columns that were actually available from resultSet(),
  or -1 if there was no result set.
- resultSetConsumedColumnNames: The number of columns that were consumed from the resultSet(), or -1
  if there was no result set. If the result set is still being consumed (i.e. prior to the
  ResultSet.close() call), then this will return the number of columns that were retrieved from the
  resultSet() set thus far.
- resultSetFetchedColumnNames: The number of columns that were actually available from resultSet(),
  or -1 if there was no result set.
- resultSetUnnecessaryWasNullCall: There had been an unnecessary ResultSet.wasNull() call to check
  that a non-primitive type consumed previously was null, or the call was made more than once.
  resultSetColumnIndex() will return the relevant column index for which the ResultSet.wasNull()
  call was missing.
- resultSetMissingWasNullCall: There had been a missing ResultSet.wasNull() call on a previously
  consumed primitive type, which is reported to be ResultSetMetaData.isNullable(int).
  resultSetColumnIndex() will return the relevant column index for which the ResultSet.wasNull()
  call was missing.
- resultSetColumnIndex: The relevant column index (1 based) in the ResultSet if applicable, or 0 if
  there was no result set.
- actualStatement: The actual statement that is being executed.
- normalisedStatement: The normalised statement that all duplicates correspond to.
- duplicateStatements: The duplicate statements that all correspond to a single normalised
  statement. This set is used by at least:
  DiagnosticsListener.duplicateStatements(DiagnosticsContext)
- repeatedStatements DiagnosticsListener#consecutiveAggregation(DiagnosticsContext): The repeated
  statements that all correspond to a single normalised statement. This set is used by at least:
  DiagnosticsListener.repeatedStatements(DiagnosticsContext) Ungültige Referenz
  DiagnosticsListener#consecutiveAggregation(DiagnosticsContext)
- exception: The exception that occurred while diagnosing a statement.

DiagnosticsListener (class, org.jooq)
A diagnostics listener. Users can implement this in order to receive and handle diagnostics events
explicitly. A default implementation is available via LoggingDiagnosticsListener, which can be
activated using Settings.isDiagnosticsLogging(). Events are received on any
DSLContext.diagnosticsConnection() or DSLContext.diagnosticsDataSource(), if
Settings.getDiagnosticsConnection() is not turned DiagnosticsConnection.OFF. Use
DiagnosticsConnection.ON to turn diagnostics on for all of jOOQ's ConnectionProvider usage. For more
information about individual diagnostics, please also check out the manual pages:
https://www.jooq.org/doc/dev/manual/sql-execution/diagnostics/.
Methods:
- tooManyRowsFetched SELECT * FROM actor; SELECT * FROM actor;: The fetched JDBC ResultSet returned
  more rows than necessary. An event indicating that a JDBC ResultSet was fetched with A rows, but
  only B rows (B < A) were consumed. Typically, this problem can be remedied by applying the
  appropriate LIMIT clause in SQL, or SelectLimitStep.limit(Number) clause in jOOQ. This diagnostic
  can be turned off using Settings.isDiagnosticsTooManyRowsFetched().
- tooManyRowsFetched: The fetched JDBC ResultSet returned more rows than necessary. An event
  indicating that a JDBC ResultSet was fetched with A rows, but only B rows (B < A) were consumed.
  Typically, this problem can be remedied by applying the appropriate LIMIT clause in SQL, or
  SelectLimitStep.limit(Number) clause in jOOQ. This diagnostic can be turned off using
  Settings.isDiagnosticsTooManyRowsFetched().
- tooManyColumnsFetched: The fetched JDBC ResultSet returned more columns than necessary. An event
  indicating that a JDBC ResultSet was fetched with A columns, but only B (B < A) were consumed.
  Typically, this problem can be remedied by not running a SELECT * query when this isn't strictly
  required. This diagnostic can be turned off using Settings.isDiagnosticsTooManyColumnsFetched().
- unnecessaryWasNullCall: The fetched JDBC ResultSet returned a value for a column, on which
  ResultSet.wasNull() was called unnecessarily (more than once, or for a non-primitive type). This
  diagnostic can be turned off using Settings.isDiagnosticsUnnecessaryWasNullCall().
- missingWasNullCall: The fetched JDBC ResultSet returned a primitive type value for a column, which
  could have been null, but ResultSet.wasNull() was not called. This diagnostic can be turned off
  using Settings.isDiagnosticsMissingWasNullCall().
- duplicateStatements SELECT * FROM actor; SELECT * FROM actor;: The executed JDBC statement has
  duplicates. Many databases maintain an execution plan cache, which remembers execution plans for a
  given SQL string. These caches often use the verbatim SQL string (or a hash thereof) as a key,
  meaning that "similar" but not identical statements will produce different keys. This may be
  desired in rare cases when querying skewed data, as a hack to force the optimiser to calculate a
  new plan for a given "similar" but not identical query, but mostly, this is not desirable as
  calculating execution plans can turn out to be expensive. Examples of such duplicate statements
  include: Whitespace differences SELECT * FROM actor; SELECT * FROM actor; Inline bind values
  SELECT * FROM actor WHERE id = 1; SELECT * FROM actor WHERE id = 2; Aliasing and qualification
  SELECT a1.* FROM actor a1 WHERE id = ?; SELECT * FROM actor a2 WHERE a2.id = ?; Examples of
  identical statements (which are not considered duplicate, but
  repeatedStatements(DiagnosticsContext), if on the same Connection) are: SELECT * FROM actor WHERE
  id = ?; SELECT * FROM actor WHERE id = ?; This is a system-wide diagnostic that is not specific to
  individual Connection instances. Its caches are located in the Configuration that this listener
  pertains to. This diagnostic can be turned off using Settings.isDiagnosticsDuplicateStatements().
  Advanced duplicate statement recognition can be turned off using
  Settings.isDiagnosticsDuplicateStatementsUsingTransformPatterns().
- repeatedStatements SELECT * FROM actor WHERE id = ?; SELECT * FROM actor WHERE id = ?;: The
  executed JDBC statement is repeated consecutively on the same JDBC Connection. This problem goes
  by many names, the most famous one being the N + 1 problem, when a single (1) query for a parent
  entity requires many (N) subsequent queries for child entities. This could have been prevented by
  rewriting the parent query to use a JOIN. If such a rewrite is not possible (or not easy), the
  subsequent N queries could at least profit (depending on the exact query): From reusing the
  PreparedStatement From being batched From being re-written as a bulk fetch or write query This
  problem can be aggravated if combined with the duplicateStatements(DiagnosticsContext) problem, in
  case of which the repeated statements might not be diagnosed as easily. Repeated statements may or
  may not be "identical". In the following example, there are two repeated and identical statements:
  SELECT * FROM actor WHERE id = ?; SELECT * FROM actor WHERE id = ?; In this example, we have three
  repeated statements, only some of which are also identical: SELECT * FROM actor WHERE id = ?;
  SELECT * FROM actor WHERE id = ?; SELECT * FROM actor WHERE id = ?; This is a Connection-specific
  diagnostic that is reset every time Connection.close() is called for explicitly created
  DSLContext.diagnosticsConnection(), or if DiagnosticsConnection.ON is specified, also globally on
  a TransactionContext level (if available), or Configuration level. This diagnostic can be turned
  off using Settings.isDiagnosticsRepeatedStatements().
- exception: Something went wrong while diagnosing a SQL query. The actual exception will be
  provided by DiagnosticsContext.exception(). Likely exceptions include: A ParserException because
  jOOQ couldn't parse user defined SQL. A user exception from a custom DiagnosticsListener
  implementation.

Domain (class, org.jooq)
The meta model of a SQL DOMAIN
Methods:
- getChecks: The DOMAIN's condition.

DropTableFinalStep (class, org.jooq)
A step in the construction of the DROP TABLE statement. Referencing XYZ*Step types directly from
client code It is usually not recommended to reference any XYZ*Step types directly from client code,
or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases

DropTableStep (class, org.jooq)
A step in the construction of the DROP TABLE statement. Referencing XYZ*Step types directly from
client code It is usually not recommended to reference any XYZ*Step types directly from client code,
or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases
Methods:
- cascade: Add the CASCADE clause to the DROP TABLE statement.
- restrict: Add the RESTRICT clause to the DROP TABLE statement.

ExecuteListener (class, org.jooq)
An event listener for Query, Routine, or ResultSet render, prepare, bind, execute, fetch steps.
ExecuteListener is a base type for loggers, debuggers, profilers, data collectors that can be hooked
into a jOOQ DSLContext using the Configuration.executeListenerProviders() property, passing Settings
to DSL.using(java.sql.Connection, SQLDialect, Settings). jOOQ will use that configuration at the
beginning of a query execution event to get a hold of all provided listeners via
ExecuteListenerProvider.provide(). The DefaultExecuteListenerProvider will always return the same
ExecuteListener instance, but user defined providers can define any custom listener lifecycle, e.g.
one instance per execution to store state between the moment when a query execution starts, and the
moment when a query execution finishes in the listener. Alternatively, such data can be stored in
Scope.data(). Advanced ExecuteListeners can also provide custom implementations of Connection,
PreparedStatement, ResultSet, SQLException or RuntimeException to jOOQ in appropriate methods. The
following table explains how every type of statement / operation invokes callback methods in the
correct order for all registered ExecuteListeners. Find a legend below the table for the various use
cases. Callback method Use case [1] Use case [2] Use case [3] Use case [4] Use case [5] Use case [6]
start(ExecuteContext) Yes, 1x Yes, 1x Yes, 1x Yes, 1x Yes, 1x Yes, 1x Ungültige Referenz
#transformStart(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every query) Yes, 1x
Ungültige Referenz #transformEnd(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every
query) Yes, 1x renderStart(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every query) Yes,
1x renderEnd(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every query) Yes, 1x
prepareStart(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every query) Yes, 1x
prepareEnd(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, Nx (for every query) Yes, 1x
bindStart(ExecuteContext) Yes, 1x No No Yes, Nx (for every value set) No Yes, 1x
bindEnd(ExecuteContext) Yes, 1x No No Yes, Nx (for every value set) No Yes, 1
executeStart(ExecuteContext) Yes, 1x Yes, 1x No Yes, 1x Yes, 1x Yes, 1x executeEnd(ExecuteContext)
Yes, 1x Yes, 1x No Yes, 1x Yes, 1x Yes, 1x outStart(ExecuteContext) No No No No No Yes, 1x
outEnd(ExecuteContext) No No No No No Yes, 1x fetchStart(ExecuteContext) Yes, 1x (Nx for
ResultQuery.fetchMany() Yes, 1x (Nx for ResultQuery.fetchMany() Yes, 1x No No No
resultStart(ExecuteContext) Maybe, 1x (Nx for Cursor.fetchNext(int) Maybe, 1x (Nx for
Cursor.fetchNext(int) Maybe, 1x No No No recordStart(ExecuteContext) Yes, Nx Yes, Nx Yes, Nx No No
No recordEnd(ExecuteContext) Yes, Nx Yes, Nx Yes, Nx No No No resultEnd(ExecuteContext) Maybe, 1x
(Nx for Cursor.fetchNext(int) Maybe, 1x (Nx for Cursor.fetchNext(int) Maybe, 1x No No No
fetchEnd(ExecuteContext) Yes, 1x (Nx for ResultQuery.fetchMany() Yes, 1x (Nx for
ResultQuery.fetchMany() Yes, 1x No No No end(ExecuteContext) Yes, 1x Yes, 1x Yes, 1x Yes, 1x Yes, 1x
Yes, 1x warning(ExecuteContext) Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x
exception(ExecuteContext) Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x Maybe, 1x Legend: Used
with ResultQuery of statement type StatementType.PREPARED_STATEMENT Used with ResultQuery of
statement type StatementType.STATIC_STATEMENT Used with DSLContext.fetch(ResultSet) or with
ResultQuery.fetch() Used with DSLContext.batch(Query) Used with DSLContext.batch(Query[]) Used with
DSLContext.batch(Queries) Used with a Routine standalone call If nothing is specified, the default
is to use LoggerListener as the only event listener, as configured in Settings.isExecuteLogging()
Methods:
- start: Called to initialise an ExecuteListener. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise Overridable attributes in ExecuteContext:
  ExecuteContext.connectionProvider(ConnectionProvider): The connection provider used for execution.
  This may be particularly interesting if a Query was de-serialised and is thus lacking the
  underlying connection
- renderStart: Called before rendering SQL from a QueryPart. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise
- renderEnd: Called after rendering SQL from a QueryPart. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement that is about to
  be executed, or null if the SQL statement is unknown. ExecuteContext.params(): The bind values
  that are bound to the PreparedStatement. Overridable attributes in ExecuteContext:
  ExecuteContext.sql(String): The rendered SQL statement that is about to be executed. You can
  modify this statement freely. ExecuteContext.params(Param[]): Bind values that are to be bound to
  the PreparedStatement.
- prepareStart: Called before preparing / creating the SQL statement. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. Overridable attributes in ExecuteContext:
  ExecuteContext.sql(String): The rendered SQL statement that is about to be executed. You can
  modify this statement freely. ExecuteContext.params(Param[]): Bind values that are to be bound to
  the PreparedStatement. ExecuteContext.statement(): The PreparedStatement about to be executed. At
  this stage, no such statement is available yet, but if provided, the execution lifecycle will skip
  preparing a statement. This can be used e.g. to implement a transaction-bound prepared statement
  cache. A custom PreparedStatement needs to take into account Settings.getStatementType(), and
  adefault void bind variable markers for StatementType.STATIC_STATEMENT. Flags such as
  Query.queryTimeout(int), Query.poolable(boolean), ResultQuery.maxRows(int), which correspond to
  mutable flags on a PreparedStatement, are set by jOOQ even if a listener provides the statement.
  Flags such as ResultQuery.resultSetConcurrency(int), ResultQuery.resultSetHoldability(int),
  ResultQuery.resultSetType(int), which correspond to immutable flags that are set on the statement
  at statement creation are not set on a statement provided by a listener.
- prepareEnd: Called after preparing / creating the SQL statement. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Overridable attributes in ExecuteContext: ExecuteContext.params(Param[]): Bind values that are to
  be bound to the PreparedStatement. ExecuteContext.statement(PreparedStatement): The Statement,
  PreparedStatement, or CallableStatement that is about to be executed. You can modify this
  statement freely, or wrap ExecuteContext.statement() with your enriched statement wrapper
- bindStart: Called before bind variables to the PreparedStatement. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.CallableStatement when you are
  executing a jOOQ Routine Overridable attributes in ExecuteContext: ExecuteContext.params(Param[]):
  Bind values that are to be bound to the PreparedStatement.
  ExecuteContext.statement(PreparedStatement): The PreparedStatement, or CallableStatement that is
  about to be executed. You can modify this statement freely, or wrap ExecuteContext.statement()
  with your enriched statement wrapper Note that this method is not called when executing queries of
  type StatementType.STATIC_STATEMENT
- bindEnd: Called after bind variables to the PreparedStatement. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.CallableStatement when you are
  executing a jOOQ Routine Overridable attributes in ExecuteContext:
  ExecuteContext.statement(PreparedStatement): The Statement, PreparedStatement, or
  CallableStatement that is about to be executed. You can modify this statement freely, or wrap
  ExecuteContext.statement() with your enriched statement wrapper Note that this method is not
  called when executing queries of type StatementType.STATIC_STATEMENT
- executeStart: Called before executing a statement. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement that is about to
  be executed, or null if the SQL statement is unknown. ExecuteContext.params(): The bind values
  that are bound to the PreparedStatement. ExecuteContext.statement(): The PreparedStatement that is
  about to be executed, or null if no statement is known to jOOQ. This can be any of the following:
  A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is being executed as
  StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver wrapped in a
  java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Overridable attributes in ExecuteContext: ExecuteContext.statement(PreparedStatement): The
  Statement, PreparedStatement, or CallableStatement that is about to be executed. You can modify
  this statement freely, or wrap ExecuteContext.statement() with your enriched statement wrapper
  Other attributes in ExecuteContext, affected by this lifecycle phase:
  ExecuteContext.statementExecutionCount() is incremented.
- executeEnd: Called after executing a statement. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement that is about to
  be executed, or null if the SQL statement is unknown. ExecuteContext.params(): The bind values
  that are bound to the PreparedStatement. ExecuteContext.statement(): The PreparedStatement that is
  about to be executed, or null if no statement is known to jOOQ. This can be any of the following:
  A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is being executed as
  StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver wrapped in a
  java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched or null, if the Query
  returns no result set, or if a Routine is being executed. ExecuteContext.rows(): The number of
  affected rows if applicable. In case a ResultSet is fetched, this number is only available at the
  fetchEnd(ExecuteContext) event. ExecuteContext.serverOutput(): The server output if available.
  This may be fetched when Settings.getFetchServerOutputSize() > 0 Overridable attributes in
  ExecuteContext: ExecuteContext.resultSet(ResultSet): The ResultSet that is about to be fetched.
  You can modify this result set freely, or wrap ExecuteContext.resultSet() with your enriched
  result set wrapper
- outStart: Called before fetching out parameter values from a CallableStatement. Available
  attributes from ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.routine(): The Routine object,
  if a jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL
  statement that is about to be executed, or null if the SQL statement is unknown.
  ExecuteContext.params(): The bind values that are bound to the PreparedStatement.
  ExecuteContext.statement(): The PreparedStatement that is about to be executed, or null if no
  statement is known to jOOQ. This can be any of the following: A java.sql.CallableStatement when
  you are executing a jOOQ Routine ExecuteContext.sqlWarning(): The SQLWarning that was emitted by
  the database or null if no warning was emitted. Note that this method is called only when
  executing standalone routine calls.
- outEnd: Called after fetching out parameter values from a CallableStatement. Available attributes
  from ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.routine(): The Routine object,
  if a jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL
  statement that is about to be executed, or null if the SQL statement is unknown.
  ExecuteContext.params(): The bind values that are bound to the PreparedStatement.
  ExecuteContext.statement(): The PreparedStatement that is about to be executed, or null if no
  statement is known to jOOQ. This can be any of the following: A java.sql.CallableStatement when
  you are executing a jOOQ Routine ExecuteContext.sqlWarning(): The SQLWarning that was emitted by
  the database or null if no warning was emitted. Note that this method is called only when
  executing standalone routine calls.
- fetchStart: Called before fetching data from a ResultSet into a Result type. Available attributes
  from ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched.
  ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if no warning
  was emitted. Overridable attributes in ExecuteContext: ExecuteContext.resultSet(ResultSet): The
  ResultSet that is about to be fetched. You can modify this result set freely, or wrap
  ExecuteContext.resultSet() with your enriched result set wrapper In case of multiple ResultSets
  with ResultQuery.fetchMany(), this is called several times, once per ResultSet Note that this
  method is not called when executing queries that do not return a result, or when executing
  routines.
- resultStart: Called before fetching a set of records from a ResultSet. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched. ExecuteContext.result():
  The set of records that are about to be fetched. ExecuteContext.resultLevel(): The result nesting
  level, in case the upcoming ExecuteContext.result() is a DSL.multiset(TableLike) or other type of
  nested result. ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or
  null if no warning was emitted. Executions without Result Not all types of execution produce
  results of type Result. For example, these do not: ResultQuery.iterator() ResultQuery.stream()
  ResultQuery.collect(Collector) (including all Collector based fetches, such as e.g. a
  ResultQuery.fetchMap(Field, Field), ResultQuery.fetchGroups(Field, Field),
  ResultQuery.fetchSet(Field), and all the overloads) Publisher.subscribe(Subscriber) In any of
  these cases, no resultStart(ExecuteContext) event is fired. Note that this method is also not
  called when executing queries that do not return a result, or when executing routines. This is
  also not called when fetching single records, with Cursor.fetchNext() for instance.
- recordStart: Called before fetching a record from a ResultSet. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched. ExecuteContext.record():
  The Record that is about to be fetched. ExecuteContext.recordLevel(): The record nesting level, in
  case the upcoming ExecuteContext.record() is a Row or other type of nested record. The level is
  also increased if a record is contained in a nested ExecuteContext.result().
  ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if no warning
  was emitted. Note that this method is not called when executing queries that do not return a
  result, or when executing routines.
- recordEnd: Called after fetching a record from a ResultSet. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched. ExecuteContext.record():
  The last Record that was fetched. ExecuteContext.recordLevel(): The record nesting level, in case
  the upcoming ExecuteContext.record() is a Row or other type of nested record. The level is also
  increased if a record is contained in a nested ExecuteContext.result().
  ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if no warning
  was emitted. Note that this method is not called when executing queries that do not return a
  result, or when executing routines.
- resultEnd: Called after fetching a set of records from a ResultSet. Available attributes from
  ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  ExecuteContext.resultSet(): The ResultSet that is about to be fetched. ExecuteContext.record():
  The last Record that was fetched. ExecuteContext.result(): The set of records that were fetched.
  ExecuteContext.resultLevel(): The result nesting level, in case the upcoming
  ExecuteContext.result() is a DSL.multiset(TableLike) or other type of nested result.
  ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if no warning
  was emitted. Executions without Result Not all types of execution produce results of type Result.
  For example, these do not: ResultQuery.iterator() ResultQuery.stream()
  ResultQuery.collect(Collector) (including all Collector based fetches, such as e.g. a
  ResultQuery.fetchMap(Field, Field), ResultQuery.fetchGroups(Field, Field),
  ResultQuery.fetchSet(Field), and all the overloads) Publisher.subscribe(Subscriber) In any of
  these cases, no resultEnd(ExecuteContext) event is fired. Note that this method is also not called
  when executing queries that do not return a result, or when executing routines. This is also not
  called when fetching single records, with Cursor.fetchNext() for instance.
- fetchEnd: Called after fetching data from a ResultSet. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement that is about to
  be executed, or null if the SQL statement is unknown. ExecuteContext.params(): The bind values
  that are bound to the PreparedStatement. ExecuteContext.statement(): The PreparedStatement that is
  about to be executed, or null if no statement is known to jOOQ. This can be any of the following:
  A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is being executed as
  StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver wrapped in a
  java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Note that the Statement is already closed! ExecuteContext.resultSet(): The ResultSet that was
  fetched. Note that the ResultSet is already closed! ExecuteContext.rows(): The number of affected
  rows if applicable. ExecuteContext.serverOutput(): The server output if available. This may be
  fetched when Settings.getFetchServerOutputSize() > 0 ExecuteContext.record(): The last Record that
  was fetched. ExecuteContext.result(): The last set of records that were fetched.
  ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if no warning
  was emitted. In case of multiple ResultSets with ResultQuery.fetchMany(), this is called several
  times, once per ResultSet Note that this method is not called when executing queries that do not
  return a result, or when executing routines.
- end: Called at the end of the execution lifecycle. Available attributes from ExecuteContext:
  ExecuteContext.connection(): The connection used for execution Scope.configuration(): The
  execution configuration ExecuteContext.query(): The Query object, if a jOOQ query is being
  executed or null otherwise ExecuteContext.routine(): The Routine object, if a jOOQ routine is
  being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement that is about to
  be executed, or null if the SQL statement is unknown. ExecuteContext.params(): The bind values
  that are bound to the PreparedStatement. ExecuteContext.statement(): The PreparedStatement that is
  about to be executed, or null if no statement is known to jOOQ. This can be any of the following:
  A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is being executed as
  StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver wrapped in a
  java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Note that the Statement is already closed! ExecuteContext.resultSet(): The ResultSet that was
  fetched or null, if no result set was fetched. Note that the ResultSet may already be closed!
  ExecuteContext.rows(): The number of affected rows if applicable. ExecuteContext.serverOutput():
  The server output if available. This may be fetched when Settings.getFetchServerOutputSize() > 0
  ExecuteContext.record(): The last Record that was fetched or null if no records were fetched.
  ExecuteContext.result(): The last set of records that were fetched or null if no records were
  fetched. ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database or null if
  no warning was emitted.
- exception: Called in the event of an exception at any moment of the execution lifecycle. Available
  attributes from ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Note that the Statement may be closed! ExecuteContext.resultSet(): The ResultSet that was fetched
  or null, if no result set was fetched. Note that the ResultSet may already be closed!
  ExecuteContext.rows(): The number of affected rows if applicable. ExecuteContext.serverOutput():
  The server output if available. This may be fetched when Settings.getFetchServerOutputSize() > 0
  ExecuteContext.record(): The last Record that was fetched or null if no records were fetched.
  ExecuteContext.result(): The last set of records that were fetched or null if no records were
  fetched. ExecuteContext.exception(): The RuntimeException that is about to be thrown
  ExecuteContext.sqlException(): The SQLException that was thrown by the database
- warning: Called in the event of a warning at any moment of the execution lifecycle. Available
  attributes from ExecuteContext: ExecuteContext.connection(): The connection used for execution
  Scope.configuration(): The execution configuration ExecuteContext.query(): The Query object, if a
  jOOQ query is being executed or null otherwise ExecuteContext.routine(): The Routine object, if a
  jOOQ routine is being executed or null otherwise ExecuteContext.sql(): The rendered SQL statement
  that is about to be executed, or null if the SQL statement is unknown. ExecuteContext.params():
  The bind values that are bound to the PreparedStatement. ExecuteContext.statement(): The
  PreparedStatement that is about to be executed, or null if no statement is known to jOOQ. This can
  be any of the following: A java.sql.PreparedStatement from your JDBC driver when a jOOQ Query is
  being executed as StatementType.PREPARED_STATEMENT A java.sql.Statement from your JDBC driver
  wrapped in a java.sql.PreparedStatement when your jOOQ Query is being executed as
  StatementType.STATIC_STATEMENT A java.sql.CallableStatement when you are executing a jOOQ Routine
  Note that the Statement may be closed! ExecuteContext.resultSet(): The ResultSet that was fetched
  or null, if no result set was fetched. Note that the ResultSet may already be closed!
  ExecuteContext.rows(): The number of affected rows if applicable. ExecuteContext.serverOutput():
  The server output if available. This may be fetched when Settings.getFetchServerOutputSize() > 0
  ExecuteContext.record(): The last Record that was fetched or null if no records were fetched.
  ExecuteContext.result(): The last set of records that were fetched or null if no records were
  fetched. ExecuteContext.sqlWarning(): The SQLWarning that was emitted by the database
  ExecuteContext.exception(): The RuntimeException that is about to be thrown or null, if no
  exception is being thrown. ExecuteContext.sqlException(): The SQLException that was thrown by the
  database or null, if no exception is being thrown. This method is only invoked if a warning
  appears. Note that fetching of warnings can be disabled using Settings.isFetchWarnings()
- onStart: Create an ExecuteListener with a start(ExecuteContext) implementation.
- onEnd: Create an ExecuteListener with a end(ExecuteContext) implementation.
- onRenderStart: Create an ExecuteListener with a renderStart(ExecuteContext) implementation.
- onRenderEnd: Create an ExecuteListener with a renderEnd(ExecuteContext) implementation.
- onPrepareStart: Create an ExecuteListener with a prepareStart(ExecuteContext) implementation.
- onPrepareEnd: Create an ExecuteListener with a prepareEnd(ExecuteContext) implementation.
- onBindStart: Create an ExecuteListener with a bindStart(ExecuteContext) implementation.
- onBindEnd: Create an ExecuteListener with a bindEnd(ExecuteContext) implementation.
- onExecuteStart: Create an ExecuteListener with a executeStart(ExecuteContext) implementation.
- onExecuteEnd: Create an ExecuteListener with a executeEnd(ExecuteContext) implementation.
- onOutStart: Create an ExecuteListener with a outStart(ExecuteContext) implementation.
- onOutEnd: Create an ExecuteListener with a outEnd(ExecuteContext) implementation.
- onFetchStart: Create an ExecuteListener with a fetchStart(ExecuteContext) implementation.
- onFetchEnd: Create an ExecuteListener with a fetchEnd(ExecuteContext) implementation.
- onResultStart: Create an ExecuteListener with a resultStart(ExecuteContext) implementation.
- onResultEnd: Create an ExecuteListener with a resultEnd(ExecuteContext) implementation.
- onRecordStart: Create an ExecuteListener with a recordStart(ExecuteContext) implementation.
- onRecordEnd: Create an ExecuteListener with a recordEnd(ExecuteContext) implementation.
- onException: Create an ExecuteListener with a exception(ExecuteContext) implementation.
- onWarning: Create an ExecuteListener with a warning(ExecuteContext) implementation.

Field (class, org.jooq)
A column expression. Column expressions or fields can be used in a variety of SQL statements and
clauses, including (non-exhaustive list): SELECT clause, e.g. through DSL.select(SelectField) (every
Field is a subtype of SelectField) WHERE clause, e.g. through SelectWhereStep.where(Field)
(Field<Boolean> can behave like a Condition, regardless if your RDBMS supports the BOOLEAN type)
GROUP BY clause, e.g. through SelectGroupByStep.groupBy(GroupField...) (every Field is a subtype of
GroupField) HAVING clause, e.g. through SelectHavingStep.having(Field) ORDER BY clause, e.g. through
SelectOrderByStep.orderBy(OrderField) (every Field is a subtype of OrderField) When creating a
Condition, e.g. through eq(Field) As a function argument, e.g. through DSL.abs(Field) Many more...
Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.select(ACTOR.LAST_NAME) // Field reference .from(ACTOR) .groupBy(ACTOR.LAST_NAME) // Field
reference .orderBy(ACTOR.LAST_NAME) // Field reference .fetch(); Instances can be created using a
variety of ways, including: DSL.field(String) and overloads for plain SQL field expression.
DSL.field(Name) and overloads for field identifier references. DSL.field(Condition) for predicates
as fields. DSL.field(Select) for correlated subqueries. TableField referenced from generated tables
DSL.val(Object) and overloads to create bind variables explicitly DSL.inline(Object) and overloads
to create inline values (constants, literals) explicitly
Methods:
- getName MY_TABLE.as("t1", f -> "prefix_" + f.getName());: The name of the field. The name is any
  of these: The formal name of the field, if it is a physical table/view field The alias of an
  aliased field A generated / unspecified value for any other expression The name of a parameter if
  it is a named Param
- getName: The name of the field. The name is any of these: The formal name of the field, if it is a
  physical table/view field The alias of an aliased field A generated / unspecified value for any
  other expression The name of a parameter if it is a named Param
- getComment: The comment given to the field. If this Field is a generated field from your database,
  it may provide its DDL comment through this method. All other column expressions return the empty
  string "" here, never null.
- as MY_TABLE.as("t1", f -> "prefix_" + f.getName());: Create an alias for this field. Note that the
  case-sensitivity of the returned field depends on Settings.getRenderQuotedNames(). By default,
  field aliases are quoted, and thus case-sensitive in many SQL dialects! This works like
  as(String), except that field aliases are provided by a function. This is useful, for instance, to
  prefix all columns with a common prefix (on Table.as(String, Function)): MY_TABLE.as("t1", f ->
  "prefix_" + f.getName()); And then to use the same function also for individual fields:
  MY_TABLE.MY_COLUMN.as(f -> "prefix_" + f.getName());
- equals: Check whether this QueryPart can be considered equal to another QueryPart. In general,
  QueryPart equality is defined in terms of QueryPart.toString() equality. In other words, two query
  parts are considered equal if their rendered SQL (with inlined bind variables) is equal. This
  means that the two query parts do not necessarily have to be of the same type. Some QueryPart
  implementations may choose to override this behaviour for improved performance, as
  QueryPart.toString() is an expensive operation, if called many times. Watch out! This is
  Object.equals(Object), not a jOOQ DSL feature!
- as: Beschreibung aus Schnittstelle kopiert: SelectField
- convert: Beschreibung aus Schnittstelle kopiert: SelectField
- convertFrom: Beschreibung aus Schnittstelle kopiert: SelectField
- convertTo: Beschreibung aus Schnittstelle kopiert: SelectField
- comment: Attach a Comment to this field, for use in DDL statements, such as
  DSLContext.createTable(Table).
- cast: Cast this field to the type of another field. Casting converts expressions between data
  types directly in SQL using SQL CAST expressions or similar. If you want to convert data types
  only in jOOQ without any effect on generated SQL, you can use coerce(Field) instead.
- coerce // This binds an int value to a JDBC PreparedStatement, // where a String is expected
  DSL.val(1).coerce(VARCHAR); // This binds an int value to a JDBC PreparedStatement // and casts it
  to VARCHAR in SQL DSL.val(1).cast(VARCHAR);: Coerce this field to the type of another field.
  Unlike with cast(Field), coercing doesn't affect the way the database sees a Field's type. This is
  how coercing affects your SQL: Bind values // This binds an int value to a JDBC PreparedStatement,
  // where a String is expected DSL.val(1).coerce(VARCHAR); // This binds an int value to a JDBC
  PreparedStatement // and casts it to VARCHAR in SQL DSL.val(1).cast(VARCHAR); Other Field types //
  This fetches a String value for the BOOK.ID field from JDBC BOOK.ID.coerce(VARCHAR); // This
  fetches a String value for the BOOK.ID field from JDBC // after casting it to VARCHAR in the
  database BOOK.ID.cast(VARCHAR);
- asc: Create an ascending sort field from this field. This is the same as calling sort(SortOrder)
  with SortOrder.ASC
- desc: Create a descending sort field from this field. This is the same as calling sort(SortOrder)
  with SortOrder.DESC
- sortDefault: Create a default sorted (implicit ASC) from this field. This is the same as calling
  sort(SortOrder) with SortOrder.DEFAULT
- sort: Create an ascending/descending sort field from this field.
- sortAsc CASE [this] WHEN [sortList.get(0)] THEN 0 WHEN [sortList.get(1)] THEN 1 ... WHEN
  [sortList.get(n)] THEN n ELSE null END ASC: Create an indirected sort field. Create a sort field
  of the form CASE [this] WHEN [sortList.get(0)] THEN 0 WHEN [sortList.get(1)] THEN 1 ... WHEN
  [sortList.get(n)] THEN n ELSE null END ASC Note: You can use this in combination with
  SortField.nullsFirst() or SortField.nullsLast() to specify whether the default should have highest
  or lowest priority.
- sortAsc CASE [this] WHEN [sortList[0]] THEN 0 WHEN [sortList[1]] THEN 1 ... WHEN [sortList[n]]
  THEN n ELSE null END ASC: Create an indirected sort field. Create a sort field of the form CASE
  [this] WHEN [sortList[0]] THEN 0 WHEN [sortList[1]] THEN 1 ... WHEN [sortList[n]] THEN n ELSE null
  END ASC Note: You can use this in combination with SortField.nullsFirst() or SortField.nullsLast()
  to specify whether the default should have highest or lowest priority.
- sortDesc CASE [this] WHEN [sortList.get(0)] THEN 0 WHEN [sortList.get(1)] THEN 1 ... WHEN
  [sortList.get(n)] THEN n ELSE null END DESC: Create an indirected sort field. Create a sort field
  of the form CASE [this] WHEN [sortList.get(0)] THEN 0 WHEN [sortList.get(1)] THEN 1 ... WHEN
  [sortList.get(n)] THEN n ELSE null END DESC Note: You can use this in combination with
  SortField.nullsFirst() or SortField.nullsLast() to specify whether the default should have highest
  or lowest priority.
- sortDesc CASE [this] WHEN [sortList[0]] THEN 0 WHEN [sortList[1]] THEN 1 ... WHEN [sortList[n]]
  THEN n ELSE null END DESC: Create an indirected sort field. Create a sort field of the form CASE
  [this] WHEN [sortList[0]] THEN 0 WHEN [sortList[1]] THEN 1 ... WHEN [sortList[n]] THEN n ELSE null
  END DESC Note: You can use this in combination with SortField.nullsFirst() or
  SortField.nullsLast() to specify whether the default should have highest or lowest priority.
- sort CASE [this] WHEN [sortMap.key(0)] THEN sortMap.value(0) WHEN [sortMap.key(1)] THEN
  sortMap.value(1) ... WHEN [sortMap.key(n)] THEN sortMap.value(n) ELSE null END DESC: Create an
  indirected sort field. Create a sort field of the form (in pseudo code) CASE [this] WHEN
  [sortMap.key(0)] THEN sortMap.value(0) WHEN [sortMap.key(1)] THEN sortMap.value(1) ... WHEN
  [sortMap.key(n)] THEN sortMap.value(n) ELSE null END DESC Note: You can use this in combination
  with SortField.nullsFirst() or SortField.nullsLast() to specify whether the default should have
  highest or lowest priority.
- nullsFirst: Convenience method for sortDefault() and then SortField.nullsFirst().
- nullsLast: Convenience method for sortDefault() and then SortField.nullsLast().
- binaryLike: The BINARY_LIKE operator. The LIKE operator for binary strings
- eq: The EQ operator.
- equal: The EQUAL operator, an alias for the EQ operator.
- ge: The GE operator.
- greaterOrEqual: The GREATER_OR_EQUAL operator, an alias for the GE operator.
- greaterThan: The GREATER_THAN operator, an alias for the GT operator.
- gt: The GT operator.
- in: The IN operator. The subquery must return exactly one field. This is not checked by jOOQ and
  will result in syntax errors in the database, if not used correctly.
- isDistinctFrom: The IS_DISTINCT_FROM operator. The DISTINCT predicate allows for creating NULL
  safe comparisons where the two operands are tested for non-equality
- isNull: The IS_NULL operator.
- isNotDistinctFrom: The IS_NOT_DISTINCT_FROM operator. The NOT DISTINCT predicate allows for
  creating NULL safe comparisons where the two operands are tested for equality
- isNotNull: The IS_NOT_NULL operator.
- le: The LE operator.
- lessOrEqual: The LESS_OR_EQUAL operator, an alias for the LE operator.
- lessThan: The LESS_THAN operator, an alias for the LT operator.
- like: The LIKE operator.
- likeIgnoreCase: The LIKE_IGNORE_CASE operator. Create a condition to case-insensitively pattern-
  check this field against a value. This translates to this ilike value in SQLDialect.POSTGRES, or
  to lower(this) like lower(value) in all other dialects.
- lt: The LT operator.
- ne: The NE operator.
- notBinaryLike: The NOT_BINARY_LIKE operator. The NOT LIKE operator for binary strings
- notEqual: The NOT_EQUAL operator, an alias for the NE operator.
- notIn: The NOT_IN operator. The subquery must return exactly one field. This is not checked by
  jOOQ and will result in syntax errors in the database, if not used correctly. If any of the passed
  values is NULL, then the condition will be NULL (or false, depending on the dialect) as well. This
  is standard SQL behaviour.
- notLike: The NOT_LIKE operator.
- notLikeIgnoreCase: The NOT_LIKE_IGNORE_CASE operator. Create a condition to case-insensitively
  pattern-check this field against a value. This translates to this not ilike value in
  SQLDialect.POSTGRES, or to lower(this) not like lower(value) in all other dialects.
- notSimilarTo: The NOT_SIMILAR_TO operator.
- similarTo: The SIMILAR_TO operator.
- isDocument: The IS_DOCUMENT operator. Create a condition to check if this field contains XML data.
- isNotDocument: The IS_NOT_DOCUMENT operator. Create a condition to check if this field does not
  contain XML data.
- isJson: The IS_JSON operator. Create a condition to check if this field contains JSON data.
- isNotJson: The IS_NOT_JSON operator. Create a condition to check if this field does not contain
  JSON data.
- bitAnd: The BIT_AND operator.
- bitNand: The BIT_NAND operator.
- bitNor: The BIT_NOR operator.
- bitNot: The BIT_NOT operator.
- bitOr: The BIT_OR operator.
- bitXNor: The BIT_XNOR operator.
- bitXor: The BIT_XOR operator.
- mod: The MOD operator.
- modulo: The MODULO operator, an alias for the MOD operator.
- rem: The REM operator, an alias for the MOD operator.
- power: The POWER operator.
- pow: The POW operator, an alias for the POWER operator.
- shl: The SHL operator. Left shift all bits in a number
- shr: The SHR operator. Right shift all bits in a number
- contains // Use this expression val(new Integer[] { 1, 2, 3 }).contains(new Integer[] { 1, 2 }) //
  ... to render this SQL ARRAY[1, 2, 3] @> ARRAY[1, 2]: The CONTAINS operator. Convenience method
  for like(String, char) including proper adding of wildcards and escaping. SQL: this like ('%' ||
  escape(value, '\') || '%') escape '\' Note: This also works with numbers, for instance
  val(1133).contains(13) If you're using SQLDialect.POSTGRES, then you can use this method also to
  express the "ARRAY contains" operator. For example: // Use this expression val(new Integer[] { 1,
  2, 3 }).contains(new Integer[] { 1, 2 }) // ... to render this SQL ARRAY[1, 2, 3] @> ARRAY[1, 2]
  Note, this does not correspond to the Oracle Text CONTAINS() function. Refer to Ungültige Referenz
  OracleDSL#contains(Field, String) instead.
- containsIgnoreCase: The CONTAINS_IGNORE_CASE operator. Convenience method for
  likeIgnoreCase(String, char) including proper adding of wildcards and escaping. This translates to
  this ilike ('%' || escape(value, '\') || '%') escape '\' in SQLDialect.POSTGRES, or to lower(this)
  like lower(('%' || escape(value, '\') || '%') escape '\') in all other dialects.
- endsWith: The ENDS_WITH operator. Convenience method for like(String, char) including proper
  adding of wildcards and escaping. SQL: this like ('%' || escape(value, '\')) escape '\' Note: This
  also works with numbers, for instance val(1133).endsWith(33)
- endsWithIgnoreCase: The ENDS_WITH_IGNORE_CASE operator. Convenience method for like(String, char)
  including proper adding of wildcards and escaping. SQL: lower(this) like ('%' ||
  lower(escape(value, '\'))) escape '\' Note: This also works with numbers, for instance
  val(1133).endsWithIgnoreCase(33)
- startsWith: The STARTS_WITH operator. Convenience method for like(String, char) including proper
  adding of wildcards and escaping. SQL: this like (escape(value, '\') || '%') escape '\' Note: This
  also works with numbers, for instance val(1133).startsWith(11)
- startsWithIgnoreCase: The STARTS_WITH_IGNORE_CASE operator. Convenience method for like(String,
  char) including proper adding of wildcards and escaping. SQL: lower(this) like
  (lower(escape(value, '\')) || '%') escape '\' Note: This also works with numbers, for instance
  val(1133).startsWithIgnoreCase(11)
- neg -[this]: Negate this field to get its negative value. This renders the same on all dialects:
  -[this]
- unaryMinus: Negate this field to get its negative value. This is an alias for neg(), which can be
  recognised by the Kotlin language for operator overloading.
- unaryPlus: Get this field as its positive value (no effect on SQL). This can be recognised by the
  Kotlin language for operator overloading.
- add: An arithmetic expression adding this to value.
- plus: An alias for add(Number).
- sub: An arithmetic expression subtracting value from this.
- subtract: An alias for sub(Number).
- minus: An alias for sub(Number).
- mul: An arithmetic expression multiplying this with value. If this is a numeric field, then the
  result is a number of the same type as this field. If this is an INTERVAL field, then the result
  is also an INTERVAL field (see Interval)
- multiply: An alias for mul(Number).
- times: An alias for mul(Number).
- div: An arithmetic expression dividing this by value. If this is a numeric field, then the result
  is a number of the same type as this field. If this is an INTERVAL field, then the result is also
  an INTERVAL field (see Interval)
- divide: An alias for div(Number).
- likeRegex <regex like predicate> ::= <row value predicand> <regex like predicate part 2> <regex
  like predicate part 2> ::= [ NOT ] LIKE_REGEX <XQuery pattern> [ FLAG <XQuery option flag> ]:
  Create a condition to regex-pattern-check this field against a pattern. The SQL:2008 standard
  specifies a <regex like predicate> of the following form: <regex like predicate> ::= <row value
  predicand> <regex like predicate part 2> <regex like predicate part 2> ::= [ NOT ] LIKE_REGEX
  <XQuery pattern> [ FLAG <XQuery option flag> ] This particular LIKE_REGEX operator comes in
  several flavours for various databases. jOOQ supports regular expressions as follows: SQL dialect
  SQL syntax Pattern syntax Documentation Ungültige Referenz SQLDialect#ASE - - - Ungültige Referenz
  SQLDialect#DB2 - - - SQLDialect.DERBY - - - SQLDialect.H2 [search] REGEXP [pattern] Java https
  ://www.h2database.com/html/grammar.html#condition_right_hand_side SQLDialect.HSQLDB
  REGEXP_MATCHES([search], [pattern]) Java http://hsqldb.org/doc/guide/builtinfunctions-
  chapt.html#N13577 Ungültige Referenz SQLDialect#INGRES - - - SQLDialect.MYSQL [search] REGEXP
  [pattern] POSIX http://dev .mysql.com/doc/refman/5.6/en/regexp.html Ungültige Referenz
  SQLDialect#ORACLE REGEXP_LIKE([search], [pattern]) POSIX
  http://docs.oracle.com/cd/E14072_01/server.112/e10592/conditions007.htm# sthref1994
  SQLDialect.POSTGRES [search] ~ [pattern] POSIX
  http://www.postgresql.org/docs/9.1/static/functions-matching.html# FUNCTIONS-POSIX-REGEXP
  SQLDialect.SQLITE [search] REGEXP [pattern] ? This module has to be loaded explicitly
  http://www.sqlite.org/ lang_expr.html Ungültige Referenz SQLDialect#SQLSERVER - - - Ungültige
  Referenz SQLDialect#SYBASE [search] REGEXP [pattern] Perl
  http://infocenter.sybase.com/help/topic/com.sybase.help.sqlanywhere.12.0 .1/dbreference/like-
  regexp-similarto.html
- likeRegex: Create a condition to regex-pattern-check this field against a pattern. See
  likeRegex(String) for more details
- notLikeRegex: Create a condition to regex-pattern-check this field against a pattern. See
  likeRegex(String) for more details
- notContains: Inverse of contains(Object).
- notContainsIgnoreCase: Inverse of containsIgnoreCase(Object)
- in SQLDialect#ORACLE: Create a condition to check this field against several values. SQL: this in
  (values…) Note that generating dynamic SQL with arbitrary-length IN predicates can cause cursor
  cache contention in some databases that use unique SQL strings as a statement identifier (e.g.
  Ungültige Referenz SQLDialect#ORACLE ). In order to prevent such problems, you could use
  Settings.isInListPadding() to produce less distinct SQL strings (see also [#5600]), or you could
  avoid IN lists, and replace them with: IN predicates on temporary tables IN predicates on unnested
  array bind variables
- notIn SQLDialect#ORACLE: Create a condition to check this field against several values. Note that
  if any of the passed values is NULL, then the condition will be NULL (or false, depending on the
  dialect) as well. This is standard SQL behaviour. SQL: this not in (values…) Note that generating
  dynamic SQL with arbitrary-length NOT IN predicates can cause cursor cache contention in some
  databases that use unique SQL strings as a statement identifier (e.g. Ungültige Referenz
  SQLDialect#ORACLE ). In order to prevent such problems, you could use Settings.isInListPadding()
  to produce less distinct SQL strings (see also [#5600]), or you could avoid IN lists, and replace
  them with: NOT IN predicates on temporary tables NOT IN predicates on unnested array bind
  variables
- between: Create a condition to check this field against some bounds. This is the same as calling
  between(minValue).and(maxValue) SQL: this between minValue and maxValue
- betweenSymmetric: Create a condition to check this field against some bounds. This is the same as
  calling betweenSymmetric(minValue).and(maxValue) SQL: this between symmetric minValue and maxValue
- notBetween: Create a condition to check this field against some bounds. This is the same as
  calling notBetween(minValue).and(maxValue) SQL: this not between minValue and maxValue
- notBetweenSymmetric: Create a condition to check this field against some bounds. This is the same
  as calling notBetweenSymmetric(minValue).and(maxValue) SQL: this not between symmetric minValue
  and maxValue
- compare: Compare this field with a value using a dynamic comparator.
- isTrue: Create a condition to check this field against known string literals for true. SQL:
  lcase(this) in ("1", "y", "yes", "true", "on", "enabled")
- isFalse: Create a condition to check this field against known string literals for false. SQL:
  lcase(this) in ("0", "n", "no", "false", "off", "disabled")
- equalIgnoreCase: lower(this) = lower(value).
- notEqualIgnoreCase: lower(this) != lower(value).
- sign:
- abs:
- round:
- floor:
- ceil:
- sqrt:
- exp:
- ln:
- log:
- acos:
- asin:
- atan:
- atan2:
- cos:
- sin:
- tan:
- cot:
- sinh:
- cosh:
- tanh:
- coth:
- deg:
- rad:
- count:
- countDistinct:
- max:
- min:
- sum:
- avg:
- median:
- stddevPop:
- stddevSamp:
- varPop:
- varSamp:
- countOver:
- maxOver:
- minOver:
- sumOver:
- avgOver:
- firstValue:
- lastValue:
- lead:
- lag:
- stddevPopOver:
- stddevSampOver:
- varPopOver:
- varSampOver:
- upper: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- lower: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- trim: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- rtrim: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- ltrim: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- rpad: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- lpad: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- repeat: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- replace: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- position: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- ascii: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- collate: Apply a collation operator to this column expression.
- concat: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- substring: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- length: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- charLength: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- bitLength: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- octetLength: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- extract:
- greatest:
- least:
- nvl: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- nvl2: This method is part of the pre-2.0 API. This API is maintained for backwards-compatibility.
  It may be removed in the future. Consider using equivalent methods from DSLContext
- nullif: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- decode: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- coalesce: This method is part of the pre-2.0 API. This API is maintained for backwards-
  compatibility. It may be removed in the future. Consider using equivalent methods from DSLContext
- field: The inverse operation of Fields.field(Field). This method can be used in its method
  reference form conveniently on a generated table, for instance, when mapping records in a stream.
- get DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::get)
  .forEach(System.out::println);: The inverse operation of Record.get(Field). This method can be
  used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::get) .forEach(System.out::println);
- getValue DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::getValue)
  .forEach(System.out::println);: The inverse operation of Record.getValue(Field). This method can
  be used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::getValue) .forEach(System.out::println);
- original DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::original)
  .forEach(System.out::println);: The inverse operation of Record.original(Field). This method can
  be used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::original) .forEach(System.out::println);
- changed DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::changed)
  .forEach(System.out::println);: The inverse operation of Record.changed(Field). This method can be
  used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::changed) .forEach(System.out::println);
- touched DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::touched)
  .forEach(System.out::println);: The inverse operation of Record.touched(Field). This method can be
  used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::touched) .forEach(System.out::println);
- reset DSL.using(configuration) .fetch("select * from t") .stream() .forEach(MY_TABLE.ID::reset);:
  The inverse operation of Record.reset(Field). This method can be used in its method reference form
  conveniently on a generated table, for instance, when mapping records in a stream:
  DSL.using(configuration) .fetch("select * from t") .stream() .forEach(MY_TABLE.ID::reset);
- from DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE.ID::from)
  .forEach(System.out::println);: The inverse operation of Record.into(Field). This method can be
  used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE.ID::from) .forEach(System.out::println);

ForeignKey (class, org.jooq)
A ForeignKey is an object referencing a UniqueKey. It represents a FOREIGN KEY relationship between
two tables. Instances of this type cannot be created directly. They are available from generated
code.
Methods:
- getDeleteRule: The foreign key's ON DELETE rule, or null if it's not specified, which defaults to
  QOM.ForeignKeyRule.NO_ACTION.
- getUpdateRule: The foreign key's ON UPDATE rule, or null if it's not specified, which defaults to
  QOM.ForeignKeyRule.NO_ACTION.
- getInverseKey: The inverse key.
- getKey: The referenced UniqueKey.
- getKeyFields: The fields that make up the referenced UniqueKey. This returns the order in which
  the fields of getKey() are referenced, which is usually the same as the fields of Key.getFields(),
  but not necessarily so.
- getKeyFieldsArray: The fields that make up the referenced UniqueKey. This returns the order in
  which the fields of getKey() are referenced, which is usually the same as the fields of
  Key.getFieldsArray(), but not necessarily so.
- fetchParent: Fetch a parent record of a given record through this foreign key This returns a
  parent record referenced by a given record through this foreign key, as if fetching from
  parent(Record). If no parent record was found, this returns null
- fetchParents: Fetch parent records of a given set of record through this foreign key This returns
  parent records referenced by any record in a given set of records through this foreign key, as if
  fetching from parents(Record...).
- fetchChildren: Fetch child records of a given record through this foreign key This returns childs
  record referencing a given record through this foreign key, as if fetching from children(Record).
- parent: Get a table expression representing the parent of a record, given this foreign key.
- parents: Get a table expression representing the parents of a record, given this foreign key.
- children: Get a table expression representing the children of a record, given this foreign key.

GroupField (class, org.jooq)
An expression to be used exclusively in GROUP BY clauses. The SELECT … GROUP BY clause accepts a
variety of expressions, mostly ordinary Field expressions, but also some special expressions usable
only in the GROUP BY clause, such as DSL.groupingSets(Field[][]). Example: // Assuming import static
org.jooq.impl.DSL.*; using(configuration) .select(ACTOR.LAST_NAME) .from(ACTOR)
.groupBy(ACTOR.LAST_NAME) // GroupField reference here .fetch(); Instances can be created using
DSL.groupingSets(Field[][]) and related methods, or by creating a subtype.

Insert (class, org.jooq)
An INSERT statement. Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.insertInto(ACTOR) .columns(ACTOR.FIRST_NAME, ACTOR.LAST_NAME) .values("John", "Doe") .execute();
Instances can be created using DSL.insertInto(Table), or DSLContext.insertQuery(Table) and
overloads.

InsertFinalStep (class, org.jooq)
This type is used for the Insert's DSL API. Example: DSLContext create = DSL.using(configuration);
create.insertInto(table, field1, field2) .values(value1, value2) .values(value3, value4)
.onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute(); Referencing XYZ*Step
types directly from client code It is usually not recommended to reference any XYZ*Step types
directly from client code, or assign them to local variables. When writing dynamic SQL, creating a
statement's components dynamically, and passing them to the DSL API statically is usually a better
choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases

InsertQuery (class, org.jooq)
An INSERT statement (model API). This type is the model API representation of a Insert statement,
which can be mutated after creation. The advantage of this API compared to the DSL API is a more
simple approach to writing dynamic SQL. Instances can be created using DSLContext.insertQuery(Table)
and overloads.
Methods:
- newRecord INSERT IGNORE INTO …: Adds a new Record to the insert statement for multi-record inserts
  Calling this method will cause subsequent calls to StoreQuery.addValue(Field, Object) (and
  similar) to fill the next record. If this call is not followed by StoreQuery.addValue(Field,
  Object) calls, then this call has no effect. If this call is done on a fresh insert statement
  (without any values yet), then this call has no effect either.
- newRecord: Adds a new Record to the insert statement for multi-record inserts Calling this method
  will cause subsequent calls to StoreQuery.addValue(Field, Object) (and similar) to fill the next
  record. If this call is not followed by StoreQuery.addValue(Field, Object) calls, then this call
  has no effect. If this call is done on a fresh insert statement (without any values yet), then
  this call has no effect either.
- addRecord: Short for calling newRecord() and StoreQuery.setRecord(Record).
- onConflict: Whether a ON CONFLICT clause should be added to this INSERT statement. When setting
  this flag to true, be sure to also add values "for update" using the addValueForUpdate(Field,
  Field) methods.
- onConflictOnConstraint: Whether use a ON CONFLICT or ON CONFLICT ON CONSTRAINT clause in this
  INSERT statement.
- onDuplicateKeyUpdate: Whether a ON DUPLICATE KEY UPDATE clause should be added to this INSERT
  statement. When setting this flag to true, be sure to also add values "for update" using the
  addValueForUpdate(Field, Field) methods. The ON DUPLICATE KEY UPDATE flag is mutually exclusive
  with the ON DUPLICATE KEY IGNORE flag (see onDuplicateKeyIgnore(boolean). Setting one will unset
  the other
- onDuplicateKeyIgnore INSERT IGNORE INTO …: Whether an ON DUPLICATE KEY IGNORE clause should be
  added to this INSERT statement. This clause is not actually supported in this form by any
  database, but can be emulated as such: Dialect Emulation SQLDialect.MYSQL and SQLDialect.MARIADB
  INSERT IGNORE INTO … Ungültige Referenz SQLDialect#POSTGRES_9_5 and SQLDialect.SQLITE INSERT INTO
  … ON CONFLICT DO NOTHING Ungültige Referenz SQLDialect#DB2 SQLDialect.HSQLDB Ungültige Referenz
  SQLDialect#ORACLE Ungültige Referenz SQLDialect#SQLSERVER Ungültige Referenz SQLDialect#SYBASE
  MERGE INTO [dst] USING ([values]) ON [dst.key] = [values.key] WHEN NOT MATCHED THEN INSERT .. All
  the others INSERT INTO [dst] ( ... ) SELECT [values] WHERE NOT EXISTS ( SELECT 1 FROM [dst] WHERE
  [dst.key] = [values.key] ) The ON DUPLICATE KEY UPDATE flag is mutually exclusive with the ON
  DUPLICATE KEY IGNORE flag (see onDuplicateKeyIgnore(boolean). Setting one will unset the other
- addValueForUpdate: Add a value to the ON DUPLICATE KEY UPDATE clause of this INSERT statement,
  where this is supported.
- addValuesForUpdate: Add multiple values to the ON DUPLICATE KEY UPDATE clause of this INSERT
  statement, where this is supported. Please assure that key/value pairs have matching <T> types.
  Values can either be of type <T> or Field<T>
- setRecordForUpdate: Add multiple values to the ON DUPLICATE KEY UPDATE clause of this INSERT
  statement, where this is supported. This works like StoreQuery.setRecord(Record).
- onConflictWhere: Adds a new condition the onConflict(Field...) clause. This is for use with
  SQLDialect.POSTGRES's onConflict(Field...) clause.
- addConditions: Adds a new condition to the query, connecting it to existing conditions with
  Operator.AND. This is for use with SQLDialect.POSTGRES's onConflict(Field...) clause.
- setDefaultValues: Set an empty record with the DEFAULT VALUES clause.
- setSelect: Use a SELECT statement as the source of values for the INSERT statement.
- setReturning: Configure the INSERT or UPDATE statement to return all fields in R. This feature
  works with INSERT statements for all SQL dialects
- getReturnedRecord: The record holding returned values as specified by any of the
  StoreQuery.setReturning() methods. If the insert statement returns several records, this is the
  same as calling getReturnedRecords().get(0) This implemented differently for every dialect:
  Firebird and Postgres have native support for INSERT … RETURNING and UPDATE … RETURNING clauses
  HSQLDB, Oracle, and DB2 JDBC drivers allow for retrieving any table column as "generated key" in
  one statement Derby, H2, Ingres, MySQL, SQL Server only allow for retrieving IDENTITY column
  values as "generated key". If other fields are requested, a second statement is issued. Client
  code must assure transactional integrity between the two statements. Sybase and SQLite allow for
  retrieving IDENTITY values as @@identity or last_inserted_rowid() values. Those values are fetched
  in a separate SELECT statement. If other fields are requested, a second statement is issued.
  Client code must assure transactional integrity between the two statements. This feature works
  with INSERT statements for all SQL dialects
- getReturnedRecords: The records holding returned values as specified by any of the
  StoreQuery.setReturning() methods. This implemented differently for every dialect: Firebird and
  Postgres have native support for INSERT … RETURNING and UPDATE … RETURNING clauses HSQLDB, Oracle,
  and DB2 JDBC drivers allow for retrieving any table column as "generated key" in one statement
  Derby, H2, Ingres, MySQL, SQL Server only allow for retrieving IDENTITY column values as
  "generated key". If other fields are requested, a second statement is issued. Client code must
  assure transactional integrity between the two statements. Sybase and SQLite allow for retrieving
  IDENTITY values as @@identity or last_inserted_rowid() values. Those values are fetched in a
  separate SELECT statement. If other fields are requested, a second statement is issued. Client
  code must assure transactional integrity between the two statements. [#5070] Due to an early API
  design flaw, this method historically returns the type R, not a more generic type Record. This
  means that only actual columns in R can be returned. For a more generic set of column expressions,
  use StoreQuery.getResult() instead. This feature works with INSERT statements for all SQL dialects

InsertSetStep (class, org.jooq)
This type is used for the Insert's alternative DSL API. Example: DSLContext create =
DSL.using(configuration); create.insertInto(table) .set(field1, value1) .set(field2, value2)
.newRecord() .set(field1, value3) .set(field2, value4) .onDuplicateKeyUpdate() .set(field1, value1)
.set(field2, value2) .execute(); Referencing XYZ*Step types directly from client code It is usually
not recommended to reference any XYZ*Step types directly from client code, or assign them to local
variables. When writing dynamic SQL, creating a statement's components dynamically, and passing them
to the DSL API statically is usually a better choice. See the manual's section about dynamic SQL for
details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing
the XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're
less composable and not easy to get right when dynamic SQL gets complex They're less readable They
might have binary incompatible changes between minor releases
Methods:
- columns: Set the columns for insert.
- set: Set a value for a field in the INSERT statement.
- setNull: Set a null value for a field in the INSERT statement. This method is convenience for
  calling set(Field, Object), without the necessity of casting the Java null literal to (T).
- values: Add values to the insert statement with implicit field names.
- defaultValues: Add an empty record with default values.
- select: Use a SELECT statement as the source of values for the INSERT statement. This variant of
  the INSERT … SELECT statement does not allow for specifying a subset of the fields inserted into.
  It will insert into all fields of the table specified in the INTO clause. Use
  DSLContext.insertInto(Table, Field...) or DSLContext.insertInto(Table, Collection) instead, to
  define a field set for insertion.

JSON (class, org.jooq)
A JSON wrapper type for JSON data obtained from the database. The wrapper represents JSON data() in
serialised string form. A CAST(NULL AS JSON) value is represented by a null reference of type JSON,
not as data() == null. This is consistent with jOOQ's general way of returning NULL from Result and
Record methods. Unlike the normalising JSONB data type, the JSON type uses a purely text based,
formatting-preserving representation of the JSON content, meaning that e.g. the following two
documents are not equal, due to their different object attribute order and formatting: {"a":1,"b":2}
{"b": 2, "a": 1} This impacts the behaviour of equals(Object) hashCode() toString()
Methods:
- data: Beschreibung aus Schnittstelle kopiert: Data
- valueOf: Create a new JSON instance from string data input.
- json: Create a new JSON instance from string data input. This is the same as valueOf(String), but
  it can be static imported.
- jsonOrNull: Create a new JSON instance from string data input, or null if the input is null.
- hashCode: JSON specifics: The JSON type uses a text-based, formatting-preserving representation of
  the JSON content, meaning that two equivalent JSON documents are considered not equal if their
  formatting or object attribute ordering differs (see JSON for details).
- equals: JSON specifics: The JSON type uses a text-based, formatting-preserving representation of
  the JSON content, meaning that two equivalent JSON documents are considered not equal if their
  formatting or object attribute ordering differs (see JSON for details).
- toString: JSON specifics: The JSON type uses a text-based, formatting-preserving representation of
  the JSON content, meaning that two equivalent JSON documents are considered not equal if their
  formatting or object attribute ordering differs (see JSON for details).

JSONB (class, org.jooq)
A JSON wrapper type for JSONB data obtained from the database. The wrapper represents JSONB data()
in serialised string form. A CAST(NULL AS JSONB) value is represented by a null reference of type
JSONB, not as data() == null. This is consistent with jOOQ's general way of returning NULL from
Result and Record methods. Unlike the purely text based, formatting-preserving JSON data type, the
JSONB type uses a normalised representation of the JSON content, meaning that e.g. the following two
documents are equal, despite their different object attribute order and formatting: {"a":1,"b":2}
{"b": 2, "a": 1} This impacts the behaviour (and performance!) of equals(Object) hashCode()
toString() The data() content, however, is not normalised.
Methods:
- data: Beschreibung aus Schnittstelle kopiert: Data
- valueOf: Create a new JSONB instance from string data input.
- jsonb: Create a new JSONB instance from string data input. This is the same as valueOf(String),
  but it can be static imported.
- jsonbOrNull: Create a new JSONB instance from string data input, or null if the input is null.
- hashCode: JSONB specifics: The JSONB type uses a normalised representation of the JSON content,
  meaning that two equivalent JSON documents are considered equal (see JSONB for details). This
  impacts both behaviour and performance!
- equals: JSONB specifics: The JSONB type uses a normalised representation of the JSON content,
  meaning that two equivalent JSON documents are considered equal (see JSONB for details). This
  impacts both behaviour and performance!
- toString: JSONB specifics: The JSONB type uses a normalised representation of the JSON content,
  meaning that two equivalent JSON documents are considered equal (see JSONB for details). This
  impacts both behaviour and performance!

JSONFormat (class, org.jooq)
A JSON formatting type, which can be used to configure JSON imports / exports. The default format is
the following, using header() equal to true and applying JSONFormat.RecordFormat.ARRAY:
{"fields":[{"name":"field-1","type":"type-1"}, {"name":"field-2","type":"type-2"}, ...,
{"name":"field-n","type":"type-n"}], "records":[[value-1-1,value-1-2,...,value-1-n],
[value-2-1,value-2-2,...,value-2-n]]} If header() is set to false, then the result is simply the
records array, either using JSONFormat.RecordFormat.ARRAY: [[value-1-1,value-1-2,...,value-1-n],
[value-2-1,value-2-2,...,value-2-n]] or, using JSONFormat.RecordFormat.OBJECT: [{"field-1":
value-1-1, "field-2": value-1-2,..., "field-n": value-1-n}, {"field-1": value-2-1, "field-2":
value-2-2,..., "field-n": value-2-n}] The type is immutable, meaning calls to setters like
header(boolean) do not modify the original reference, but return a new one instead.
Methods:
- DEFAULT_FOR_RESULTS:
- DEFAULT_FOR_RECORDS:
- JSONFormat:
- mutable: Whether this configuration object is mutable.
- format: The new value for the formatting flag, defaulting to false.
- newline: The new newline character, defaulting to \n.
- globalIndent: The new global indentation size applied on all levels, defaulting to 0.
- indent: The new indentation size per level value, defaulting to 2.
- indentString: Convenience method to get an indentation string at a given level.
- header: Whether to emit a header row with column names, defaulting to true.
- recordFormat: The record format to be applied, defaulting to JSONFormat.RecordFormat.ARRAY.
- objectNulls: The null format to be applied to objects, defaulting to
  JSONFormat.NullFormat.NULL_ON_NULL.
- arrayNulls: The null format to be applied to arrays, defaulting to
  JSONFormat.NullFormat.NULL_ON_NULL.
- wrapSingleColumnRecords: Whether to wrap single column records in the recordFormat().
- quoteNested: Whether nested JSON or JSONB content should be quoted like a string, or nested into
  JSON formatted output.

Key (class, org.jooq)
A Key is an object representing a UNIQUE KEY, a PRIMARY KEY, or a FOREIGN KEY. Instances of this
type cannot be created directly. They are available from generated code.
Methods:
- getTable: The Key's owner table
- getFields: The fields that make up the KEY
- getFieldsArray: The fields that make up the KEY
- constraint: Get this KEY as a formal Constraint specification.
- enforced: Whether this key is being enforced.
- nullable: Whether this key is (partially) nullable.

Keyword (class, org.jooq)
A SQL keyword. A Keyword is a QueryPart that renders a SQL keyword according to the settings
specified in Settings.getRenderKeywordCase(). It is useful mostly in jOOQ's internals and for users
who wish to make extensive use of "plain SQL templating". Example: // Assuming import static
org.jooq.impl.DSL.*; Field<Integer> field = field( "{0}({1} {2} {3})", SQLDataType.INTEGER,
keyword("extract"), keyword("year"), keyword("from"), ACTOR.LAST_UPDATE ); Instances can be created
using DSL.keyword(String) and overloads.

Loader (class, org.jooq)
The Loader API is used for configuring data loads. This type is the final type holding information
about the outcome of the data load.
Methods:
- errors: A list of errors that might have happened during the load.
- processed: The number of processed rows.
- executed: The number of executed statements, bulk statements, or batch statements.
- ignored: The number of ignored rows. If using LoaderOptionsStep.onDuplicateKeyIgnore() along with
  LoaderOptionsStep.batchAll() or LoaderOptionsStep.batchAfter(int), it may be possible that some
  dialects will not produce the correct ignored count, as the respective JDBC drivers cannot produce
  this count over Statement.executeBatch() and related methods.
- stored: The number of inserted or updated rows.
- result: The results that are also returned from Loader.

LoaderCSVStep (class, org.jooq)
The Loader API is used for configuring data loads. The step in constructing the Loader object where
you can set the mandatory CSV loader options. Referencing XYZ*Step types directly from client code
It is usually not recommended to reference any XYZ*Step types directly from client code, or assign
them to local variables. When writing dynamic SQL, creating a statement's components dynamically,
and passing them to the DSL API statically is usually a better choice. See the manual's section
about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql.
Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable implementations
(as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL gets complex
They're less readable They might have binary incompatible changes between minor releases
Methods:
- fields: Specify the the fields to be loaded into the table in the correct order. The CSV column at
  index i is inserted into the table field at index i. If fields[i] == null or fields.length <= i,
  then the CSV column is skipped.
- fieldsFromSource: Indicate that all input fields which have a corresponding field in the target
  table (with the same name) should be loaded.
- fieldsCorresponding: Indicate that all input fields which have a corresponding field in the target
  table (with the same name) should be loaded.

LoaderJSONStep (class, org.jooq)
The Loader API is used for configuring data loads. The step in constructing the Loader object where
you can set the mandatory JSON loader options.
Methods:
- fields: Specify the fields to be loaded into the table in the correct order. The JSON column at
  index i is inserted into the table field at index i. If fields[i] == null or fields.length <= i,
  then the JSON column is skipped.
- fieldsFromSource: Indicate that all input fields which have a corresponding field in the target
  table (with the same name) should be loaded.
- fieldsCorresponding: Indicate that all input fields which have a corresponding field in the target
  table (with the same name) should be loaded.

LoaderXMLStep (class, org.jooq)
The Loader API is used for configuring data loads. The step in constructing the Loader object where
you can set the mandatory XML loader options. Referencing XYZ*Step types directly from client code
It is usually not recommended to reference any XYZ*Step types directly from client code, or assign
them to local variables. When writing dynamic SQL, creating a statement's components dynamically,
and passing them to the DSL API statically is usually a better choice. See the manual's section
about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql.
Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable implementations
(as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL gets complex
They're less readable They might have binary incompatible changes between minor releases

Merge (class, org.jooq)
A MERGE statement. Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.mergeInto(CUSTOMER) .using(selectFrom(CUSTOMER_IMPORT)) .on(CUSTOMER.ID.eq(CUSTOMER_IMPORT.ID))
.whenMatchedThenUpdate() .set(CUSTOMER.FIRST_NAME, CUSTOMER_IMPORT.FIRST_NAME)
.set(CUSTOMER.LAST_NAME, CUSTOMER_IMPORT.LAST_NAME) .whenNotMatchedThenInsert(CUSTOMER.FIRST_NAME,
CUSTOMER.LAST_NAME) .values(CUSTOMER_IMPORT.FIRST_NAME, CUSTOMER_IMPORT.LAST_NAME) .execute();
Instances can be created using DSL.mergeInto(Table) and overloads.

Meta (class, org.jooq)
A wrapping object for DatabaseMetaData or for other sources of database meta information (e.g.
InformationSchema) This object can be obtained through DSLContext.meta() in order to provide
convenient access to your database meta data. This abstraction has two purposes: To increase API
convenience, as no checked SQLException is thrown, only the unchecked DataAccessException To
increase API convenience, as the returned objects are always jOOQ objects, not JDBC ResultSet
objects with hard-to-remember API constraints This type is a Scope with independent lifecycle and
its own Scope.data() map.
Methods:
- getCatalogs: Get all catalog objects from the underlying meta data source. For those databases
  that don't really support JDBC meta data catalogs, a single empty catalog (named "") will be
  returned. In other words, there is always at least one catalog in a database.
- getCatalog: Get a catalog object by name from the underlying meta data source, or null if no such
  object exists.
- getSchemas: Get all schema objects from the underlying meta data source.
- getTables: Get all table objects from the underlying meta data source.
- getDomains: Get all domain objects from the underlying meta data source.
- getSequences: Get all sequence objects from the underlying meta data source.
- getPrimaryKeys: Get all primary keys from the underlying meta data source.
- getUniqueKeys: Get all unique keys from the underlying meta data source.
- getForeignKeys: Get all foreign keys from the underlying meta data source.
- getIndexes: Get all indexes from the underlying meta data sources.
- filterCatalogs: Create a wrapper Meta instance filtering out some catalogs.
- filterSchemas: Create a wrapper Meta instance filtering out some schemas.
- filterTables: Create a wrapper Meta instance filtering out some tables.
- filterDomains: Create a wrapper Meta instance filtering out some domains.
- filterSequences: Create a wrapper Meta instance filtering out some sequences.
- filterPrimaryKeys: Create a wrapper Meta instance filtering out some primary keys.
- filterUniqueKeys: Create a wrapper Meta instance filtering out some unique keys.
- filterForeignKeys: Create a wrapper Meta instance filtering out some foreign keys.
- filterIndexes: Create a wrapper Meta instance filtering out some indexes.
- snapshot: Eager-create an in-memory copy of this Meta instance without any connection to the
  original data source.
- ddl: Generate a creation script for the entire meta data.
- apply: Apply a migration to this meta to produce a new Meta.
- migrateTo: Generate a migration script to get from this meta data to another one. See
  migrateTo(Meta, MigrationConfiguration) for more details.
- informationSchema: Export to the InformationSchema format. This allows for serialising schema meta
  information as XML using JAXB. See also Constants.XSD_META for details.

Name (class, org.jooq)
An identifier. A Name or identifier is a QueryPart that renders a SQL identifier according to the
settings specified in Settings.getRenderQuotedNames() and Settings.getRenderNameCase(). Example: //
Assuming import static org.jooq.impl.DSL.*; using(configuration) .select( field(name("FIRST_NAME"),
SQLDataType.VARCHAR), field(name("LAST_NAME"), SQLDataType.VARCHAR)) .from(table(name("ACTOR")))
.fetch(); Instances can be created using DSL.name(String) and overloads.
Methods:
- first: Get the first segment of the qualified name (usually a Catalog or Schema name).
- last: Get the last segment of the qualified name (usually a Table, Field, or Parameter name).
- empty: Whether this is the empty name. An unnamed object will have an "" empty string as its name.
  If a table has no explicit schema, it will be located in the default schema whose name is "".
- qualified: Whether this is a qualified name. This is true as soon as getName() has a length of
  more than 1 and qualifier() is not null.
- qualifierQualified: Whether this is a qualified name and the qualifier() is also a qualified name.
  This is true as soon as getName() has a length of more than 2 and qualifier() is not null and its
  qualified() property is also true.
- qualifier: This name's qualifier (if it is qualified()), or null.
- unqualifiedName: This name, unqualified.
- quoted: Whether this is a quoted name.
- quotedName: This name, quoted.
- unquotedName: This name, unquoted.
- parts: Get the individual, unqualified name parts of this name.
- append: Appends name to this name.
- getName: The qualified name of this SQL identifier.
- as: Create an empty WindowDefinition from this name. A window definition renders itself
  differently, depending on Context.declareWindows(). There are two rendering modes: Declaration:
  The window definition renders its window name (this) along with the AS (window specification)
  clause. This typically happens in WINDOW clauses. Reference: The window definition renders its
  alias identifier. This happens everywhere else.
- asMaterialized: Specify a materialized subselect to refer to by the Name to form a common table
  expression. This adds the PostgreSQL 12 MATERIALIZED hint to the common table expression
  definition, or silently ignores it, if the hint is not supported. Column names are implicitly
  inherited from the SELECT statement. A common table expression renders itself differently,
  depending on Context.declareCTE(). There are two rendering modes: Declaration: The common table
  expression renders its CTE name (this) along with the AS (query) clause. This typically happens in
  WITH clauses. Reference: The common table expression renders its alias identifier. This happens
  everywhere else.
- asNotMaterialized: Specify a non-materialized subselect to refer to by the Name to form a common
  table expression. This adds the PostgreSQL 12 NOT MATERIALIZED hint to the common table expression
  definition, or silently ignores it, if the hint is not supported. Column names are implicitly
  inherited from the SELECT statement. A common table expression renders itself differently,
  depending on Context.declareCTE(). There are two rendering modes: Declaration: The common table
  expression renders its CTE name (this) along with the AS (query) clause. This typically happens in
  WITH clauses. Reference: The common table expression renders its alias identifier. This happens
  everywhere else.
- fields: Add a list of fields to this name to make this name a DerivedColumnList. The
  DerivedColumnList can then be used along with a subselect to form a CommonTableExpression to be
  used with WITH clauses.
- equals: Beschreibung aus Schnittstelle kopiert: QueryPart
- equalsIgnoreCase: Compare this name with another one ignoring case.
- compareTo: Compare two unquotedName() by their qualified string versions.

ParseContext (class, org.jooq)
A publicly available API for the internal parse context that allows for parsing SQL fragements. This
type is a Scope with independent lifecycle and its own Scope.data() map.
Methods:
- parseDialect: Convenient access to Settings.getParseDialect().
- parseFamily: Convenient access to Settings.getParseDialect()'s family.
- parseCategory: Convenient access to Settings.getParseDialect()'s category.
- languageContext: The current language context.
- characters: Get access to the underlying SQL string.
- character: The character at the current position().
- position: The current position.
- peek: Peek at the next character.
- peekKeyword: Peek at the next keyword.
- parse: Parse a single character or fail if it cannot be parsed.
- parseIf: Try parsing a single character.
- parseKeyword: Parse a keyword or fail if the keyword cannot be parsed. The argument keyword should
  be in UPPER CASE and is allowed to contain spaces. Spaces separating keyword parts are interpreted
  as any arbitrary amount of whitespace. For example, when parsing "ORDER BY", then "order by" will
  be parsed as well.
- parseKeywordIf: Try parsing a keyword. The argument keyword should be in UPPER CASE and is allowed
  to contain spaces. Spaces separating keyword parts are interpreted as any arbitrary amount of
  whitespace. For example, when parsing "ORDER BY", then "order by" will be parsed as well.
- parseIdentifier: Parse an (unqualified) identifier or fail if the current token is not an
  identifier.
- parseIdentifierIf: Try parsing an (unqualified) identifier.
- parseName: Parse a name (a qualified identifier) or fail if the current token is not a name.
- parseNameIf: Try parsing a name (a qualified identifier).
- parseFunctionNameIf: Try parsing a function name.
- parseStringLiteral: Parse a string literal or fail if the current token is not a string literal.
- parseStringLiteralIf: Try parsing a string literal.
- parseUnsignedIntegerLiteral: Parse an unsigned integer literal or fail if the current token is not
  an unsigned integer literal.
- parseUnsignedIntegerLiteralIf: Try parsing an unsigned integer literal.
- parseSignedIntegerLiteral: Parse a signed integer literal or fail if the current token is not a
  signed integer literal.
- parseSignedIntegerLiteralIf: Try parsing an signed integer literal.
- parseDataType: Parse a DataType expression or fail if the current expression is not a data type.
- parseField: Parse a Field expression or fail if the current expression is not a field.
- parseSortField: Parse a SortField expression or fail if the current expression is not a sort
  field.
- parseCondition: Parse a Condition expression or fail if the current expression is not a condition.
- parseTable: Parse a Table expression or fail if the current expression is not a table.
- parseList: Convenience method to parse a list of at least 1 elements.
- parseParenthesised: Convenience method to parse parenthesised content.
- exception: An exception that can be thrown from the current position.

Parser (class, org.jooq)
A SQL parser.
Methods:
- parse: Parse a SQL string into a set of Queries.
- parseQuery: Parse a SQL string into a Query.
- parseStatement: Parse a SQL string into a procedural Statement.
- parseResultQuery: Parse a SQL string into a ResultQuery.
- parseSelect: Parse a SQL string into a Select statement.
- parseTable: Parse a SQL string into a Table.
- parseField: Parse a SQL string into a Field.
- parseRow: Parse a SQL string into a Row.
- parseCondition: Parse a SQL string into a Condition.
- parseName: Parse a SQL string into a name Name.

Query (class, org.jooq)
Any query. Instances can be created using DSL.query(String) and overloads, or by creating a subtype.
Methods:
- execute: Execute the query, if it has been created with a proper configuration.
- executeAsync: Execute the query in a new CompletionStage. The result is asynchronously completed
  by a task running in an Executor provided by the underlying Configuration.executorProvider().
- isExecutable: Whether this query is executable in its current state. DML queries may be incomplete
  in structure and thus not executable. Calling execute() on such queries has no effect, but beware
  that AttachableQueryPart.getSQL() may not render valid SQL!
- bind: Bind a new value to a named parameter. [#1886] If the bind value with name param is inlined
  ( Param.isInline()) or if this query was created with StatementType.STATIC_STATEMENT and there is
  an underlying PreparedStatement kept open because of keepStatement(boolean), the underlying
  PreparedStatement will be closed automatically in order for new bind values to have an effect.
- poolable: Specify whether any JDBC Statement created by this query should be
  Statement.setPoolable(boolean). If this method is not called on jOOQ types, then jOOQ will not
  specify the flag on JDBC either, resulting in JDBC's default behaviour.
- queryTimeout: Specify the query timeout in number of seconds for the underlying JDBC Statement.
- keepStatement: Keep the query's underlying statement open after execution. This indicates to jOOQ
  that the query's underlying Statement or PreparedStatement should be kept open after execution. If
  it is kept open, client code is responsible for properly closing it using CloseableQuery.close(),
  e.g. via a try-with-resources statement.
- cancel: Cancel the underlying statement. This cancels the query's underlying Statement or
  PreparedStatement. If there is no underlying open and running statement, this call is simply
  ignored.

Record (class, org.jooq)
A database result record. A record essentially combines a list of columns (Field) with a
corresponding list of values, each value being of the respective field's type. While records can be
seen as generic column / value mappings, their concrete implementations often specialise the above
description in any of the following ways: Table records Records originating from a concrete database
table (or view) are modelled by jOOQ as TableRecord or UpdatableRecord, if they contain a primary
key. If you're using jOOQ's code generator, you can generate even more concrete types of table
records, i.e. one table record per table. UDT records Ungültige Referenz SQLDialect#ORACLE and
SQLDialect.POSTGRES formally support user defined types (UDT), which are modelled by jOOQ as
UDTRecord. In addition to being regular records (column / value mappings), they also implement the
JDBC SQLData API in order to be streamed to a JDBC PreparedStatement or from a JDBC ResultSet
Records of well-defined degree When projecting custom record types in SQL, new ad-hoc types of a
certain degree are formed on the fly. Records with degree <= 22 are reflected by jOOQ through the
Record1, Record2, ... Record22 classes, which cover the respective row value expressions Row1, Row2,
... Row22 Note that generated TableRecords and UDTRecords also implement a Record[N] interface, if N
<= 22 Record implements Comparable jOOQ records have a natural ordering implemented in the same way
as this is defined in the SQL standard. For more details, see the compareTo(Record) method.
Importing Record Starting from Java 14, the Record type conflicts with Record, which is always
imported by default. According to Java Language Specification, this means that jOOQ's Record type
can no longer be imported on demand. This is not sufficient: import org.jooq.*; You have to do this
instead: import org.jooq.*; import org.jooq.Record;
Methods:
- valuesRow // For arbitrary values of i record.getValue(i) == record.intoArray()[i]: Get this
  record's values as a Row.
- valuesRow: Get this record's values as a Row.
- get: Get a value from this Record, providing a field, using Fields.field(Field) for lookup. If
  this record contains a field with the same Field.getName() as the argument field, that value is
  retrieved.
- set: Set a value into this record, using Fields.field(Field) for lookup. This will always set the
  touched(Field) flag for the given field, no matter if setting the value actually changes the
  value. Changing Table.getPrimaryKey() values will set all touched() flags to true, in order to
  produce complete INSERT statements on subsequent UpdatableRecord.store() operations.
- with: Set a value into this record, using Fields.field(Field) for lookup. Like set(Field, Object)
  but returning this for fluent setting of multiple values.
- size: Get the number of fields of this record.
- original: Get this record containing the original values as fetched from the database. Record
  values can be freely modified after having fetched a record from the database. Every record also
  references the originally fetched values. This method returns a new record containing those
  original values.
- changed: Check if this record has been changed from its original as fetched from the database. If
  this returns false, then it can be said that record.equals(record.original()) is true.
- touched: Check if this record has been touched since it was created or fetched from the database.
  A record may have been touched() (a setter was called) without having been modified() (a value was
  changed).
- modified: Check if this record has been modified since it was created or fetched from the
  database. When a record is modified(), then it has always been touched() as well. Unlike the
  touched() property, this property cannot be set and is derived only from the comparison between
  this record and the original() record.
- reset: Reset all values to their original() values and all touched() flags to false.
- intoArray // For arbitrary values of i record.getValue(i) == record.intoArray()[i]: Convert this
  record into an array. The resulting array has the same number of elements as this record has
  fields. The resulting array contains data as such: // For arbitrary values of i record.getValue(i)
  == record.intoArray()[i] This is the same as calling into(Object[].class)
- intoList // For arbitrary values of i record.getValue(i) == record.intoList().get(i): Convert this
  record into a list. The resulting list has the same number of elements as this record has fields.
  The resulting array contains data as such: // For arbitrary values of i record.getValue(i) ==
  record.intoList().get(i) This is the same as calling Arrays.asList(intoArray())
- intoStream: Convert this record into a stream. The resulting stream has the same number of
  elements as this record has fields. The resulting stream contains data as such: This is the same
  as calling into(Stream.class)
- intoMap: Return this record as a name/value map. This is the inverse operation to fromMap(Map)
- into: Copy this record into a new record holding only a subset of the previous fields, using
  Fields.field(Field) for lookup.
- intoResultSet: Generate an in-memory JDBC ResultSet containing the data of this Record. Use this
  as an adapter for JDBC-compliant code that expects a ResultSet to operate on, rather than a jOOQ
  Result. The returned ResultSet allows for the following behaviour according to the JDBC
  specification: ResultSet.CLOSE_CURSORS_AT_COMMIT: The cursors (i.e. Statement object) are no
  longer available ResultSet.CONCUR_READ_ONLY: You cannot update the database through this
  ResultSet, as the underlying Result object does not hold any open database refences anymore
  ResultSet.FETCH_FORWARD: The fetch direction is forward only, and cannot be changed
  ResultSet.TYPE_SCROLL_INSENSITIVE: You can use any of the ResultSet's scrolling methods, e.g.
  ResultSet.next() or ResultSet.previous(), etc. You may use DSLContext.fetch(ResultSet) to unwind
  this wrapper again. This is the same as creating a new Result with this Record only, and then
  calling Result.intoResultSet() on that Result
- map: Map this record into a custom mapper callback.
- from jakarta.persistence.Column: Load data into this record from a source. The mapping algorithm
  is this: If source is an array Loading of data is delegated to fromArray(Object...) If source is a
  Map Loading of data is delegated to fromMap(Map) If source is an Iterable Loading of data is
  equivalent to loading fromArray(Object...), transforming the Iterable to an array, first. If any
  JPA Ungültige Referenz jakarta.persistence.Column annotations are found on the Class of the
  provided source, only those are used (assuming the jOOQ-jpa-extensions module is on the classpath
  and Configuration.annotatedPojoMemberProvider() configures it. Matching candidates are: Public no-
  argument instance methods annotated with jakarta.persistence.Column Public no-argument instance
  methods starting with getXXX or isXXX, if there exists a matching public single-argument setXXX()
  instance method that is annotated with jakarta.persistence.Column Public instance member fields
  annotated with jakarta.persistence.Column Additional matching rules: Ungültige Referenz
  jakarta.persistence.Column#name() must match Field.getName(). All other annotation attributes are
  ignored Only the first match per field is used Matching methods have a higher priority than
  matching member fields Explicitly matching methods have a higher priority than implicitly matching
  methods (implicitly matching getter = setter is annotated) Static methods / member fields are
  ignored If there are no JPA jakarta.persistence.Column annotations, or jOOQ can't find the
  jakarta.persistence API on the classpath, jOOQ will map members by naming convention: If
  Field.getName() is MY_field (case-sensitive!), then this field's value will be fetched from the
  first of these: Public no-argument instance method MY_field() Public no-argument instance method
  myField() Public no-argument instance method getMY_field() Public no-argument instance method
  getMyField() Public instance member field MY_field Public instance member field myField Other
  restrictions primitive types are supported. General notes The resulting record will have its
  internal "touched" flags set to true for all values. This means that UpdatableRecord.store() will
  perform an INSERT statement. If you wish to store the record using an UPDATE statement, use
  DSLContext.executeUpdate(UpdatableRecord) instead. This is the same as calling record.from(source,
  record.fields())
- from: Load data into this record from a source, providing some fields, using Fields.field(Field)
  for lookup. This is the same as from(Object), except that only fields contained in the fields
  argument will be mapped.
- fromMap: Load data from a map into this record, using Fields.field(String) for lookup. The
  argument map is expected to hold field-name / value pairs where field-names correspond to actual
  field names as provided by Fields.field(String). Missing fields will be left untouched. Excess
  fields will be ignored. This is the inverse operation to intoMap(). This is the same as calling
  record.fromMap(map, record.fields())
- fromArray: Load data from an array into this record. The argument array is expected to hold values
  for this record's field indexes. Missing values will be left untouched. Excess values will be
  ignored. This is the inverse operation to intoArray()
- hashCode: Get a hash code of this Record, based on the underlying row value expression. In order
  to fulfill the general contract of Object.hashCode() and Object.equals(Object), a Record's hash
  code value depends on all hash code values of this Record's underlying column values.
- equals -- A row value expression comparison predicate SELECT * FROM my_table WHERE (1, 'A') = (1,
  'A'): Compare this Record with another Record for equality. Two records are considered equal if
  They have the same degree For every i BETWEEN 0 AND degree, r1[i] = r2[i] Note, that the above
  rules correspond to the SQL comparison predicate behaviour as illustrated in the following
  example: -- A row value expression comparison predicate SELECT * FROM my_table WHERE (1, 'A') =
  (1, 'A') Unlike SQL, jOOQ allows to compare also incompatible records, e.g. records ... whose
  degrees are not equal (results in false) ... whose column types are not equal (results in false)
  ... whose record types are not equal (irrelevant for the result) It can be said that for all R1,
  R2, if R1.equal(R2), then R1.compareTo(R2) == 0
- compareTo (r1[0] < r2[0]) OR (r1[0] = r2[0] AND r1[1] < r2[1]) OR ... OR (r1[0] = r2[0] AND ...
  AND r1[N-1] = r2[N-1] AND r1[N] < r2[N]): Compares this Record with another Record according to
  their natural ordering. jOOQ Records implement Comparable to allow for naturally ordering Records
  in a "SQL way", i.e. according to the following rules: Records being compared must have the same
  ROW type Two Records are comparable if and only if they have the same ROW type, i.e. if their
  fieldsRow() methods return fields of the same type and degree. Comparison rules Assume the
  following notations: X[i] means X.getValue(i) X = Y means X.compareTo(Y) == 0 X < Y means
  X.compareTo(Y) < 0 X[i] = Y[i] means (X[i] == null && Y[i] == null) || X[i].compareTo(Y[i]) == 0
  X[i] < Y[i] means Y[i] == null || X[i].compareTo(Y[i]) < 0. This corresponds to the SQL NULLS LAST
  clause. Then, for two comparable Records r1 and r2, x = r1.compareTo(r2) yields: x = -1: if (r1[0]
  < r2[0]) OR (r1[0] = r2[0] AND r1[1] < r2[1]) OR ... OR (r1[0] = r2[0] AND ... AND r1[N-1] =
  r2[N-1] AND r1[N] < r2[N]) x = 0: if OR (r1[0] = r2[0] AND ... AND r1[N-1] = r2[N-1] AND r1[N] =
  r2[N]) x = 1: if (r1[0] > r2[0]) OR (r1[0] = r2[0] AND r1[1] > r2[1]) OR ... OR (r1[0] = r2[0] AND
  ... AND r1[N-1] = r2[N-1] AND r1[N] > r2[N]) Note, that the above rules correspond to the SQL
  ordering behaviour as illustrated in the following examples: -- A SQL ORDER BY clause, ordering
  all records by columns in their order SELECT a, b, c FROM my_table ORDER BY 1, 2, 3 -- A row value
  expression comparison predicate SELECT * FROM my_table WHERE (a, b, c) < (1, 2, 3) See
  Row1.lessThan(Row1), Row2.lessThan(Row2), ..., Row22.lessThan(Row22) for more details about row
  value expression comparison predicates Alternative sorting behaviour can be achieved through
  Result.sortAsc(java.util.Comparator) and similar methods.
- getValue: Get a value from this Record, providing a field, using Fields.field(Field) for lookup.
  [#2211] Future versions of jOOQ might remove this method. It is recommended to use get(Field)
  instead.
- setValue: Set a value into this record, using Fields.field(Field) for lookup. [#2211] Future
  versions of jOOQ might remove this method. It is recommended to use set(Field, Object) instead.

RecordListener (class, org.jooq)
A listener for manipulation events on UpdatableRecords. Users may want to centrally inject custom
behaviour when manipulating their UpdatableRecord objects, performing CRUD. This service provider
allows to hook in callback method implementations for before or after any of these methods:
UpdatableRecord.store() UpdatableRecord.insert() UpdatableRecord.update() UpdatableRecord.delete()
UpdatableRecord.refresh() A RecordListener does not act as a client-side trigger. As such, it does
not affect any bulk DML statements (e.g. a DSLContext.update(Table)), whose affected records are not
available to clients. For those purposes, use a server-side trigger Ungültige Referenz
DSLContext#createTrigger(Name) if records should be changed, or a VisitListener if the SQL query
should be changed, independently of data.
Methods:
- storeStart: Called before storing an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to storing. Note that modifying the record's primary key value may
  influence whether storing results in an INSERT or UPDATE statement. A store event will generate a
  nested insertStart(RecordContext) or updateStart(RecordContext) event.
- storeEnd: Called after storing an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after storing. Note that modifying the record's primary key value may
  influence whether storing results in an INSERT or UPDATE statement. A store event will generate a
  nested insertEnd(RecordContext) or updateEnd(RecordContext) event.
- insertStart: Called before inserting an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to inserting.
- insertEnd: Called after inserting an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after inserting.
- updateStart: Called before updating an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to updating.
- updateEnd: Called after updating an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after updating.
- mergeStart: Called before merging an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to merging.
- mergeEnd: Called after merging an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after merging.
- deleteStart: Called before deleting an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to deleting.
- deleteEnd: Called after deleting an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after deleting.
- loadStart: Called before loading an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to loading.
- loadEnd: Called after loading an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after loading.
- refreshStart: Called before refreshing an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() prior to refreshing.
- refreshEnd: Called after refreshing an UpdatableRecord. Implementations are allowed to modify
  RecordContext.record() after refreshing.
- exception: Called when an exception occurs.
- onStoreStart: Create a RecordListener with a onStoreStart(Consumer) implementation.
- onStoreEnd: Create a RecordListener with a onStoreEnd(Consumer) implementation.
- onInsertStart: Create a RecordListener with a onInsertStart(Consumer) implementation.
- onInsertEnd: Create a RecordListener with a onInsertEnd(Consumer) implementation.
- onUpdateStart: Create a RecordListener with a onUpdateStart(Consumer) implementation.
- onUpdateEnd: Create a RecordListener with a onUpdateEnd(Consumer) implementation.
- onMergeStart: Create a RecordListener with a onMergeStart(Consumer) implementation.
- onMergeEnd: Create a RecordListener with a onMergeEnd(Consumer) implementation.
- onDeleteStart: Create a RecordListener with a onDeleteStart(Consumer) implementation.
- onDeleteEnd: Create a RecordListener with a onDeleteEnd(Consumer) implementation.
- onLoadStart: Create a RecordListener with a onLoadStart(Consumer) implementation.
- onLoadEnd: Create a RecordListener with a onLoadEnd(Consumer) implementation.
- onRefreshStart: Create a RecordListener with a onRefreshStart(Consumer) implementation.
- onRefreshEnd: Create a RecordListener with a onRefreshEnd(Consumer) implementation.
- onException: Create a RecordListener with a onException(Consumer) implementation.

RecordMapper (class, org.jooq)
A RecordMapper is a mapper that can receive Record objects, when fetching data from the database,
transforming them into a custom type <E>. RecordMapper is used behind the scenes in methods like
ResultQuery.fetchInto(Class), Result.into(Class), Record.into(Class) and other methods called
into(Class), where the argument class is a Class of type E. The default RecordMapper behaviour in
the context of a Configuration can be overridden through that configuration's
Configuration.recordMapperProvider() SPI. Custom record mappers can be constructed using lambda
expressions, using various Records.mapping(Function1), Records.mapping(Function2), etc. utilities,
and other ways. A RecordMapper is never asked to map null record values, which can be obtained using
methods like ResultQuery.fetchOne(RecordMapper), or by using RowN types as nested records in scalar
subqueries, mapping them e.g. via Row2.mapping(Function2). Instead, null is produced without passing
by this SPI. The inverse operation is modelled by RecordUnmapper.
Methods:
- map: Map a record into a POJO.
- apply:

Result (class, org.jooq)
A wrapper for database results returned by SelectQuery.
Methods:
- recordType // For arbitrary values of i, j result.getValue(i, j) == result.intoArray()[i][j]: Get
  this result's record type.
- recordType: Get this result's record type.
- getValue: Convenience method to fetch a value at a given position in the result, using
  Fields.field(Field) for lookup.
- getValues: Convenience method to fetch all values for a given field. This is especially useful,
  when selecting only a single field, using Fields.field(Field) for lookup.
- isEmpty: Whether there are any records contained in this Result.
- isNotEmpty: Whether there are any records contained in this Result.
- collect: Collect all records of this result. This is the same as calling Stream.collect(Collector)
  on Collection.stream().
- intoMaps: Return the generated result as a list of name/value maps.
- intoMap: Return a Map with one of the result's columns as key and the corresponding records as
  value, using Fields.field(Field) for lookup. An InvalidResultException is thrown, if the key turns
  out to be non-unique in the result set. Use intoGroups(Field) instead, if your keys are non-
  unique. The resulting map is iteration order preserving.
- intoGroups: Return a Map with one of the result's columns as key and a list of corresponding
  records as value, using Fields.field(Field) for lookup. Unlike intoMap(Field), this method allows
  for non-unique keys in the result set. The resulting map is iteration order preserving.
- intoArrays // For arbitrary values of i, j result.getValue(i, j) == result.intoArray()[i][j]:
  Convert this result into an array of arrays. The resulting array has the same number of first-
  dimension elements as this result has records. It has the same number of second-dimension elements
  as this result's records have fields. The resulting array contains data as such: // For arbitrary
  values of i, j result.getValue(i, j) == result.intoArray()[i][j]
- intoArray result.intoArray(fieldIndex)[recordIndex]: Return all values for a field index from the
  result. You can access data like this result.intoArray(fieldIndex)[recordIndex]
- intoArray result.intoArray(fieldName)[recordIndex]: Return all values for a field name from the
  result, using Fields.field(String) for lookup. You can access data like this
  result.intoArray(fieldName)[recordIndex]
- intoArray result.intoArray(field)[recordIndex]: Return all values for a field from the result,
  using Fields.field(Field) for lookup. You can access data like this
  result.intoArray(field)[recordIndex]
- intoSet: Map results into a custom mapper callback.
- into: Copy all records from this result into a new result with new records holding only a subset
  of the previous fields, using Fields.field(Field) for lookup.
- intoResultSet: Generate an in-memory JDBC ResultSet containing the data of this Result. Use this
  as an adapter for JDBC-compliant code that expects a ResultSet to operate on, rather than a jOOQ
  Result. The returned ResultSet allows for the following behaviour according to the JDBC
  specification: ResultSet.CLOSE_CURSORS_AT_COMMIT: The cursors (i.e. Statement object) are no
  longer available ResultSet.CONCUR_READ_ONLY: You cannot update the database through this
  ResultSet, as the underlying Result object does not hold any open database refences anymore
  ResultSet.FETCH_FORWARD: The fetch direction is forward only, and cannot be changed
  ResultSet.TYPE_SCROLL_INSENSITIVE: You can use any of the ResultSet's scrolling methods, e.g.
  ResultSet.next() or ResultSet.previous(), etc. You may use DSLContext.fetch(ResultSet) to unwind
  this wrapper again.
- map: Map results into a custom mapper callback.
- sortAsc: Sort this result by one of its contained fields, using Fields.field(Field) for lookup.
  nulls are sorted last by this method.
- sortDesc: Reverse-sort this result by one of its contained fields, using Fields.field(Field) for
  lookup. nulls are sorted last by this method.
- fetchParents: Fetch parent records of this record, given a foreign key, as if fetching from
  parents(ForeignKey).
- fetchChildren: Fetch child records of this record, given a foreign key, as if fetching from
  children(ForeignKey).
- parents: Get a table expression representing the parents of all of this result's records, given a
  foreign key.
- children: Get a table expression representing the children of all of this result's records, given
  a foreign key.
- attach: Attach this result and all of its contained records to a new Configuration.
- detach: Detach this result and all of its contained records from their current Configuration. This
  is the same as calling attach(null).

ResultQuery (class, org.jooq)
A query that can return results. jOOQ distinguishes between ordinary Query types, such as Insert,
Update, Delete, and any DDLQuery, which are meant to produce side effects in a database, and the
ResultQuery, which is meant to produce a Result through various means. The most common way to create
a result is by calling fetch(), or by using the query's iterator() method in a foreach loop:
Result<TRecord> result = ctx.select(T.A, T.B).from(T).fetch(); for (TRecord record : ctx.select(T.A,
T.B).from(T)) { // ... } Most approaches to fetching results in ResultQuery (including the above),
fetch the entire JDBC ResultSet eagerly into memory, which allows for closing the underlying JDBC
resources as quickly as possible. Such operations are not resourceful, i.e. users do not need to
worry about closing any resources. None of the many ways of fetching data will affect the SQL query
projection (SELECT clause). Hence, users must make sure not to fetch any unnecessary columns,
themselves. There are, however, some ways of fetching results lazily, and thus in a resourceful way.
These include: fetchLazy() and related methods, which produce a Cursor for imperative style
consumption of resulting records. fetchStream() and related methods, which produce a Java Stream for
functional style consumption of resulting records. In both cases, it is recommended to explicitly
close the underlying resources (i.e. JDBC ResultSet) using try-with-resources: try (Cursor<TRecord>
cursor = ctx.select(T.A, T.B).from(T).fetchLazy()) { for (;;) { TRecord record = cursor.fetchNext();
if (record == null) break; // ... } } try (Stream<TRecord> stream = ctx.select(T.A,
T.B).from(T).fetchStream()) { stream.forEach(record -> { // ... }); } While most instances of
ResultQuery implement Select, there also exist other types of ResultQuery constructed e.g. from
plain SQL APIs, such as DSLContext.resultQuery(String).
Methods:
- fetch try (Stream<R> stream = query.stream()) { // Do things with stream }: Execute the query and
  return the generated result. The result and its contained records are attached to the original
  Configuration by default. Use Settings.isAttachRecords() to override this behaviour. Lifecycle
  guarantees This method completes the whole ConnectionProvider and ExecuteListener lifecycles,
  eagerly fetching all results into memory. Underlying JDBC ResultSets are always closed. Underlying
  JDBC PreparedStatements are closed, unless keepStatement(boolean) is set. In order to keep open
  ResultSets and fetch records lazily, use fetchLazy() instead and then operate on Cursor. This
  method is not affected by Settings.getFetchIntermediateResult().
- fetch: Execute the query and return the generated result. The result and its contained records are
  attached to the original Configuration by default. Use Settings.isAttachRecords() to override this
  behaviour. Lifecycle guarantees This method completes the whole ConnectionProvider and
  ExecuteListener lifecycles, eagerly fetching all results into memory. Underlying JDBC ResultSets
  are always closed. Underlying JDBC PreparedStatements are closed, unless keepStatement(boolean) is
  set. In order to keep open ResultSets and fetch records lazily, use fetchLazy() instead and then
  operate on Cursor. This method is not affected by Settings.getFetchIntermediateResult().
- fetchResultSet: Execute the query and return the generated result as a JDBC ResultSet. This is the
  same as calling fetchLazy(). resultSet() and will return a ResultSet wrapping the JDBC driver's
  ResultSet. Closing this ResultSet may close the producing Statement or PreparedStatement,
  depending on your setting for keepStatement(boolean). You can use this method when you want to use
  jOOQ for query execution, but not for result fetching. The returned ResultSet can also be used
  with DSLContext.fetch(ResultSet).
- iterator: Execute the query using fetch() and return the generated result as an Iterator.
- spliterator: Execute the query using fetch() and return the generated result as an Spliterator.
- forEach: Execute the query and consume its results.
- fetchStream try (Stream<R> stream = query.stream()) { // Do things with stream }: Stream this
  query. This is just a synonym for stream(). Clients should ensure the Stream is properly closed,
  e.g. in a try-with-resources statement: try (Stream<R> stream = query.stream()) { // Do things
  with stream } If users prefer more fluent style streaming of queries, ResultSet can be registered
  and closed via ExecuteListener, or via "smart" third-party DataSources. Depending on your JDBC
  driver's default behaviour, this may load the whole database result into the driver's memory. In
  order to indicate to the driver that you may not want to fetch all records at once, use
  fetchSize(int) or Settings.setFetchSize(Integer) prior to calling this method.
- fetchStreamInto try (Stream<R> stream = query.stream()) { // Do things with stream }: Stream this
  query, mapping records into a custom type. This is the same as calling fetchStream().map(r ->
  r.into(type)). See Record.into(Class) for more details. Clients should ensure the Stream is
  properly closed, e.g. in a try-with-resources statement: try (Stream<R> stream = query.stream()) {
  // Do things with stream } If users prefer more fluent style streaming of queries, ResultSet can
  be registered and closed via ExecuteListener, or via "smart" third-party DataSources. Depending on
  your JDBC driver's default behaviour, this may load the whole database result into the driver's
  memory. In order to indicate to the driver that you may not want to fetch all records at once, use
  fetchSize(int) or Settings.setFetchSize(Integer) prior to calling this method.
- stream try (Stream<R> stream = query.stream()) { // Do things with stream }: Stream this query.
  This is essentially the same as fetchLazy() but instead of returning a Cursor, a Java 8 Stream is
  returned. Clients should ensure the Stream is properly closed, e.g. in a try-with-resources
  statement: try (Stream<R> stream = query.stream()) { // Do things with stream } If users prefer
  more fluent style streaming of queries, ResultSet can be registered and closed via
  ExecuteListener, or via "smart" third-party DataSources. Depending on your JDBC driver's default
  behaviour, this may load the whole database result into the driver's memory. In order to indicate
  to the driver that you may not want to fetch all records at once, use fetchSize(int) or
  Settings.setFetchSize(Integer) prior to calling this method.
- collect try (Stream<R> stream = resultQuery.stream()) { X result = stream.collect(collector); }:
  Reduce the execution results of this query using a Collector. This works in the same way as
  calling the following code: try (Stream<R> stream = resultQuery.stream()) { X result =
  stream.collect(collector); } ... with the exception of allowing client code to ignore the need for
  managing resources, which are handled inside of the collect() method. Whether this fetches an
  intermediate Result (accessible by ExecuteListener implementations), or streams records directly
  to the collector is governed by Settings.getFetchIntermediateResult().
- fetchLazy: Execute the query and "lazily" return the generated result. The returned Cursor holds a
  reference to the executed PreparedStatement and the associated ResultSet. Data can be fetched (or
  iterated over) lazily, fetching records from the ResultSet one by one. Depending on your JDBC
  driver's default behaviour, this may load the whole database result into the driver's memory. In
  order to indicate to the driver that you may not want to fetch all records at once, use
  fetchSize(int) or Settings.setFetchSize(Integer) prior to calling this method. Client code is
  responsible for closing the cursor after use.
- fetchMany String sql = "sp_help 'my_table'";: Execute a query, possibly returning several result
  sets. Example (Sybase ASE): String sql = "sp_help 'my_table'"; The result and its contained
  records are attached to the original Configuration by default. Use Settings.isAttachRecords() to
  override this behaviour.
- fetchOne: Execute the query and return at most one resulting value for a field from the generated
  result, using Fields.field(Field) for lookup. This is the same as calling fetchOne() and then
  Record.get(Field). As such, the query projection (SELECT clause) is not affected. Make sure not to
  fetch any unnecessary data.
- fetchOneMap: Execute the query and return at most one resulting record as a name/value map.
- fetchOneArray query.fetchOneArray()[fieldIndex]: Execute the query and return at most one
  resulting record as an array You can access data like this query.fetchOneArray()[fieldIndex]
- fetchOneInto E result = null; Record r = q.fetchOne(); if (r != null) result = r.into(type);: Map
  resulting records onto a custom type. This is the same as calling E result = null; Record r =
  q.fetchOne(); if (r != null) result = r.into(type); . See Record.into(Class) for more details
- fetchOneInto Z result = null; Record r = q.fetchOne(); if (r != null) result = r.into(table);: Map
  resulting records onto a custom record. This is the same as calling Z result = null; Record r =
  q.fetchOne(); if (r != null) result = r.into(table); . See Record.into(Table) for more details The
  resulting record is attached to the original Configuration by default. Use
  Settings.isAttachRecords() to override this behaviour.
- fetchSingle: Execute the query and return exactly one resulting value for a field from the
  generated result, using Fields.field(Field) for lookup. This is the same as calling fetchSingle()
  and then Record.get(Field). As such, the query projection (SELECT clause) is not affected. Make
  sure not to fetch any unnecessary data.
- fetchSingleMap: Execute the query and return exactly one resulting record as a name/value map.
- fetchSingleArray query.fetchSingleArray()[fieldIndex]: Execute the query and return exactly one
  resulting record as an array You can access data like this query.fetchSingleArray()[fieldIndex]
- fetchSingleInto E result = null; Record r = q.fetchSingle(); if (r != null) result =
  r.into(type);: Map resulting records onto a custom type. This is the same as calling E result =
  null; Record r = q.fetchSingle(); if (r != null) result = r.into(type); . See Record.into(Class)
  for more details
- fetchSingleInto Z result = null; Record r = q.fetchSingle(); if (r != null) result =
  r.into(table);: Map resulting records onto a custom record. This is the same as calling Z result =
  null; Record r = q.fetchSingle(); if (r != null) result = r.into(table); . See Record.into(Table)
  for more details The resulting record is attached to the original Configuration by default. Use
  Settings.isAttachRecords() to override this behaviour.
- fetchOptional: Execute the query and return at most one resulting value for a field from the
  generated result, using Fields.field(Field) for lookup. This is the same as calling
  fetchOptional() and then Record.get(Field). As such, the query projection (SELECT clause) is not
  affected. Make sure not to fetch any unnecessary data.
- fetchOptionalMap: Execute the query and return at most one resulting record as a name/value map.
- fetchOptionalArray: Execute the query and return at most one resulting record as an array.
- fetchOptionalInto Optional<E> result = q.fetchOptional().map(r -> r.into(type));: Map resulting
  records onto a custom type. This is the same as calling Optional<E> result =
  q.fetchOptional().map(r -> r.into(type)); . See Record.into(Class) for more details
- fetchOptionalInto Optional<Z> result = q.fetchOptional().map(r -> r.into(table));: Map resulting
  records onto a custom record. This is the same as calling Optional<Z> result =
  q.fetchOptional().map(r -> r.into(table)); . See Record.into(Table) for more details The resulting
  record is attached to the original Configuration by default. Use Settings.isAttachRecords() to
  override this behaviour.
- fetchAny: Execute the query and return at most one resulting value for a field from the generated
  result, using Fields.field(Field) for lookup. This is the same as calling fetchAny() and then
  Record.get(Field). As such, the query projection (SELECT clause) is not affected. Make sure not to
  fetch any unnecessary data.
- fetchAnyMap: Execute the query and return at most one resulting record as a name/value map.
- fetchAnyArray query.fetchAnyArray()[fieldIndex]: Execute the query and return at most one
  resulting record as an array You can access data like this query.fetchAnyArray()[fieldIndex]
- fetchAnyInto E result = null; Record r = q.fetchAny(); if (r != null) result = r.into(type);: Map
  resulting records onto a custom type. This is the same as calling E result = null; Record r =
  q.fetchAny(); if (r != null) result = r.into(type); . See Record.into(Class) for more details
- fetchAnyInto Z result = null; Record r = q.fetchOne(); if (r != null) result = r.into(table);: Map
  resulting records onto a custom record. This is the same as calling Z result = null; Record r =
  q.fetchOne(); if (r != null) result = r.into(table); . See Record.into(Table) for more details The
  resulting record is attached to the original Configuration by default. Use
  Settings.isAttachRecords() to override this behaviour.
- fetchMaps: Execute the query and return the generated result as a list of name/value maps. Whether
  this fetches an intermediate Result (accessible by ExecuteListener implementations), or streams
  records directly to the collector producing the result is governed by
  Settings.getFetchIntermediateResult().
- fetchMap: Execute the query and return a Map with one of the result's columns as key and the
  corresponding records as value, using Fields.field(Field) for lookup. An exception is thrown, if
  the key turns out to be non-unique in the result set. Use fetchGroups(Field) instead, if your keys
  are non-unique The resulting records are attached to the original Configuration by default. Use
  Settings.isAttachRecords() to override this behaviour. Whether this fetches an intermediate Result
  (accessible by ExecuteListener implementations), or streams records directly to the collector
  producing the result is governed by Settings.getFetchIntermediateResult(). The resulting map is
  iteration order preserving.
- fetchGroups: Execute the query and return a Map with one of the result's columns as key and a list
  of corresponding records as value, using Fields.field(Field) for lookup. Unlike fetchMap(Field),
  this method allows for non-unique keys in the result set. The resulting records are attached to
  the original Configuration by default. Use Settings.isAttachRecords() to override this behaviour.
  Whether this fetches an intermediate Result (accessible by ExecuteListener implementations), or
  streams records directly to the collector producing the result is governed by
  Settings.getFetchIntermediateResult(). The resulting map is iteration order preserving.
- fetchArrays query.fetchArray()[recordIndex][fieldIndex]: Execute the query and return the
  generated result as an Object matrix. You can access data like this
  query.fetchArray()[recordIndex][fieldIndex]
- fetchArray: Execute the query and return the generated result as an array of records.
- fetchArray query.fetchArray(fieldIndex)[recordIndex]: Execute the query and return all values for
  a field index from the generated result. You can access data like this
  query.fetchArray(fieldIndex)[recordIndex]
- fetchArray query.fetchArray(fieldName)[recordIndex]: Execute the query and return all values for a
  field name from the generated result, using Fields.field(String) for lookup. You can access data
  like this query.fetchArray(fieldName)[recordIndex]
- fetchArray query.fetchArray(field)[recordIndex]: Execute the query and return all values for a
  field from the generated result, using Fields.field(Field) for lookup. You can access data like
  this query.fetchArray(field)[recordIndex]
- fetchSet: Fetch results into a custom mapper callback. Whether this fetches an intermediate Result
  (accessible by ExecuteListener implementations), or streams records directly to the collector
  producing the result is governed by Settings.getFetchIntermediateResult().
- fetchInto: Map resulting records onto a custom type. Whether this fetches an intermediate Result
  (accessible by ExecuteListener implementations), or streams records directly to the collector
  producing the result is governed by Settings.getFetchIntermediateResult().
- fetchAsync: Fetch results in a new CompletionStage. The result is asynchronously completed by a
  task running in an Executor provided by the underlying Configuration.executorProvider().
- getResult: Return the result generated by a previous call to execute().
- getRecordType: The record type produced by this query.
- bind: Beschreibung aus Schnittstelle kopiert: Query
- poolable: Beschreibung aus Schnittstelle kopiert: Query
- queryTimeout: Beschreibung aus Schnittstelle kopiert: Query
- keepStatement: Beschreibung aus Schnittstelle kopiert: Query
- maxRows: Specify the maximum number of rows returned by the underlying Statement. This is not the
  same as setting a LIMIT … OFFSET clause onto the statement, where the result set is restricted
  within the database.
- fetchSize: Specify the fetch size of the underlying Statement. Regardless of this setting,
  fetchLazy() is the only way in jOOQ not to fetch all data in memory. However, you may influence
  how your JDBC driver interacts with your database through specifying a fetch size. Dialect-
  specific remarks: MySQL uses Integer.MIN_VALUE as an indicator to fetch resulting rows row-by-row
  in conjunction with ResultSet.TYPE_FORWARD_ONLY (set in resultSetType(int)) and
  ResultSet.CONCUR_READ_ONLY (set in resultSetConcurrency(int)). See this page here for details.
  PostgreSQL does not like fetch sizes being combined with Connection.getAutoCommit() == true. For
  more information, see this page here
- resultSetConcurrency: Specify the ResultSet concurrency of ResultSet objects created by jOOQ. This
  will affect the way you may perceive ResultSet objects obtained from any of these methods:
  fetchResultSet() Cursor.resultSet() ExecuteContext.resultSet()
- resultSetType: Specify the ResultSet type of ResultSet objects created by jOOQ. This will affect
  the way you may perceive ResultSet objects obtained from any of these methods: fetchResultSet()
  Cursor.resultSet() ExecuteContext.resultSet()
- resultSetHoldability: Specify the ResultSet holdability of ResultSet objects created by jOOQ. This
  will affect the way you may perceive ResultSet objects obtained from any of these methods:
  fetchResultSet() Cursor.resultSet() ExecuteContext.resultSet()
- coerce: Coerce the result record type of this query to that of a table.

Row (class, org.jooq)
A row value expression. Row value expressions are mainly useful for use in predicates, when
comparing several values in one go, which can be more elegant than expanding the row value
expression predicate in other equivalent syntaxes. This is especially true for non-equality
predicates. For instance, the following two predicates are equivalent in SQL: (A, B) > (X, Y) (A >
X) OR (A = X AND B > Y) Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.select() .from(CUSTOMER) .where(row(CUSTOMER.FIRST_NAME, CUSTOMER.LAST_NAME).in(
select(ACTOR.FIRST_NAME, ACTOR.LAST_NAME).from(ACTOR) )) .fetch(); Note: Not all databases support
row value expressions, but many row value expression operations can be emulated on all databases.
See relevant row value expression method Javadocs for details. Instances can be created using
DSL.row(Object...) and overloads.
Methods:
- size: Get the degree of this row value expression.
- isNull: Check if this row value expression contains only NULL values. Row NULL predicates can be
  emulated in those databases that do not support such predicates natively: (A, B) IS NULL is
  equivalent to A IS NULL AND B IS NULL
- isNotNull: Check if this row value expression contains no NULL values. Row NOT NULL predicates can
  be emulated in those databases that do not support such predicates natively: (A, B) IS NOT NULL is
  equivalent to A IS NOT NULL AND B IS NOT NULL Note that the two following predicates are NOT
  equivalent: (A, B) IS NOT NULL, which is the same as (A IS NOT NULL) AND (B IS NOT NULL) NOT((A,
  B) IS NULL), which is the same as (A IS NOT NULL) OR (B IS NOT NULL)
- $fields: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

SQLDialect (enum, org.jooq)
Dialects and dialect families as supported by jOOQ. The commercial jOOQ distributions support a
variety of dialects, which are grouped into dialect families. For instance, the PostgreSQL dialect
family POSTGRES is specialised by its dialects Ungültige Referenz #POSTGRES_9_3 Ungültige Referenz
#POSTGRES_9_4 Ungültige Referenz #POSTGRES_9_5 Ungültige Referenz #POSTGRES_10 Ungültige Referenz
#POSTGRES_11 Ungültige Referenz #POSTGRES_12 Ungültige Referenz #POSTGRES_13 Ungültige Referenz
#POSTGRES_14 The open source jOOQ distributions only support the dialect family, which corresponds
to the latest supported dialect version of the commercial distribution. A full list of mappings
between dialect families and latest supported version can be seen here
https://www.jooq.org/download/support-matrix. If a dialect is documented but does not seem to be
available in your jOOQ Edition, you may be using the wrong edition, e.g. because of a transitive
dependency introduced by Spring Boot. See this article about how to exclude such transitive
dependencies from your classpath https://blog.jooq.org/how-to-use-jooqs-commercial-distributions-
with-spring-boot/.
Methods:
- DEFAULT #FIREBIRD_3_0: The default SQL dialect. This dialect is chosen in the absence of a more
  explicit dialect. It is not intended to be used with any actual database as it may combined
  dialect-specific things from various dialects.
- DEFAULT: The default SQL dialect. This dialect is chosen in the absence of a more explicit
  dialect. It is not intended to be used with any actual database as it may combined dialect-
  specific things from various dialects.
- CLICKHOUSE: The ClickHouse dialect family. This dialect is in EXPERIMENTAL state. The dialect
  works very differently from most more standards compliant dialects, and we're still exploring how
  much we should tweak generated SQL to make ClickHouse behave more. The main difference is in how
  NULL values are handled. While NOT NULL being the default modifier on a type is a reasonable
  choice, auto-converting all NULL values to the type's default (e.g. 0 for INTEGER) seems like a
  stretch, and hard to prevent via jOOQ's standardisation.
- CUBRID: The CUBRID dialect family.
- DERBY: The Apache Derby dialect family.
- DUCKDB: The DuckDB dialect family.
- FIREBIRD #FIREBIRD_3_0: The Firebird dialect family. This family behaves like the versioned
  dialect Ungültige Referenz #FIREBIRD_3_0 .
- H2: The H2 dialect family.
- HSQLDB: The Hypersonic dialect family.
- IGNITE: The Apache Ignite dialect family.
- MARIADB #MARIADB_10_5: The MariaDB dialect family. This family behaves like the versioned dialect
  Ungültige Referenz #MARIADB_10_5 .
- MYSQL #MYSQL_8_0_31: The MySQL dialect family. This family behaves like the versioned dialect
  Ungültige Referenz #MYSQL_8_0_31 .
- POSTGRES #POSTGRES_17: The PostgreSQL dialect family. This family behaves like the versioned
  dialect Ungültige Referenz #POSTGRES_17 . While this family (and its dialects) have been observed
  to work to some extent on Amazon RedShift as well, we strongly suggest you use the official
  Ungültige Referenz #REDSHIFT support, instead.
- SQLITE #SQLITE_3_40: The SQLite dialect family. This family behaves like the versioned dialect
  Ungültige Referenz #SQLITE_3_40 .
- TRINO: The Trino dialect family.
- YUGABYTEDB: The YugabyteDB dialect family.
- values #POSTGRESPLUS: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge
  ihrer Deklaration zurück.
- values: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge ihrer Deklaration
  zurück.
- valueOf: Gibt die Enum-Konstante dieser Klasse mit dem angegebenen Namen zurück. Die Zeichenfolge
  muss exakt mit einer ID übereinstimmen, mit der eine Enum-Konstante in dieser Klasse deklariert
  wird. (Zusätzliche Leerzeichen sind nicht zulässig.)
- families: Get a list of all family() values.
- predecessors: Get a set of dialects preceding a given set of dialects. The resulting set of
  dialects contain all the families and dialect versions that precede the argument dialects,
  including the argument dialects.
- supportedUntil: Get a set of supported dialect versions and predecessors given a dialect version.
  The resulting set of dialects contain all the families and dialect versions that precede the
  argument dialect, including the argument dialect.
- supportedBy: Get a set of supported dialect versions and successors given a dialect version. The
  resulting set of dialects contain all the families and dialect versions that support the argument
  dialect, i.e. that succeed it, including the argument dialect.
- commercial: Whether this dialect is supported with the jOOQ commercial license only.
- supported #POSTGRESPLUS: Whether this dialect is supported by jOOQ as an output dialect.
  Unsupported, non-output dialects include: DEFAULT: A hypothetical dialect used for
  QueryPart.toString() calls of unattached query parts. Ungültige Referenz #POSTGRESPLUS : A not yet
  supported dialect.
- family SQLSERVER == SQLSERVER2012.family(); SQLSERVER == SQLSERVER2008.family(); SQLSERVER ==
  SQLSERVER.family();: The dialect family. This returns the dialect itself, if it has no "parent
  family". E.g. SQLSERVER == SQLSERVER2012.family(); SQLSERVER == SQLSERVER2008.family(); SQLSERVER
  == SQLSERVER.family();
- category: The dialect category.
- isFamily: Whether this dialect is a family().
- isVersioned: Whether this dialect is a versioned dialect or a family with versioned dialects.
- predecessor #POSTGRES_9_4: The predecessor dialect. If this is a dialect version (e.g. Ungültige
  Referenz #POSTGRES_9_4 ) within a family (e.g. POSTGRES), then the predecessor will point to the
  historically previous dialect version (e.g. Ungültige Referenz #POSTGRES_9_3 ) within the same
  family, or to the dialect itself if there was no predecessor explicitly supported by jOOQ.
- precedes // Do this block only if the chosen dialect supports PostgreSQL 9.4+ features if
  (POSTGRES_9_4.precedes(dialect)) { } // Do this block only if the chosen dialect supports
  PostgreSQL 9.3+ features else if (POSTGRES_9_3.precedes(dialect)) { } // Fall back to pre-
  PostgreSQL 9.3 behaviour else { }: Whether this dialect precedes an other dialect from the same
  family. This returns: true if this dialect is the same as the other dialect true if this dialect
  precedes the other dialect via any number of calls to predecessor() The above also implies that:
  false if the two dialects do not belong to the same family This is useful to see if some feature
  is supported by "at least" a given dialect version. Example: // Do this block only if the chosen
  dialect supports PostgreSQL 9.4+ features if (POSTGRES_9_4.precedes(dialect)) { } // Do this block
  only if the chosen dialect supports PostgreSQL 9.3+ features else if
  (POSTGRES_9_3.precedes(dialect)) { } // Fall back to pre-PostgreSQL 9.3 behaviour else { }
- precedesStrictly // Do this block only if the chosen dialect was before PostgreSQL 9.3- if
  (dialect.precedesStrictly(POSTGRES)) { } // Do this block only if the chosen dialect was before
  PostgreSQL 9.4- else if (dialect.precedesStrictly(POSTGRES)) { } // Fall back to post-PostgreSQL
  9.4+ behaviour else { }: Whether this dialect strictly precedes an other dialect from the same
  family. This returns: false if this dialect is the same as the other dialect true if this dialect
  precedes the other dialect via any number of calls to predecessor() The above also implies that:
  false if the two dialects do not belong to the same family This is useful to see if some feature
  is supported by "at least" a given dialect version. Example: // Do this block only if the chosen
  dialect was before PostgreSQL 9.3- if (dialect.precedesStrictly(POSTGRES)) { } // Do this block
  only if the chosen dialect was before PostgreSQL 9.4- else if (dialect.precedesStrictly(POSTGRES))
  { } // Fall back to post-PostgreSQL 9.4+ behaviour else { }
- supports: Check whether this dialect supports another one. This is: false if dialects don't belong
  to the same family true if either dialect isFamily() true if other dialect precedes this dialect
  The other argument dialect is typically referenced from a Support annotation, whereas this dialect
  is the user dialect.
- supportsDatabaseVersion: Check if this SQLDialect supports a JDBC
  DatabaseMetaData.getDatabaseMajorVersion(), DatabaseMetaData.getDatabaseMinorVersion(), patch
  version.
- getName: The name of this dialect as it appears in related class names.
- getNameLC: The name of this dialect as it appears in related package names.
- getNameUC: The name of this dialect as it appears in related enum values.
- thirdParty: Get access to third party representations of this SQLDialect.

Schema (class, org.jooq)
A schema. Standard SQL object identifiers come in 3 parts: [catalog].[schema].[object]. The schema
is an object that groups a set of objects, where objects can be Table, Sequence, Routine and many
other types of objects. If your RDBMS supports schemas, and jOOQ supports using schemas with your
RDBMS, then generated schemas references can be used to qualify objects Example: // Assuming import
static org.jooq.impl.DSL.*; using(configuration) .select(SCHEMA.ACTOR.FIRST_NAME,
SCHEMA.ACTOR.LAST_NAME) .from(SCHEMA.ACTOR) .fetch(); Compatibility: Database products like
SQLDialect.MYSQL and related dialects, such as SQLDialect.MARIADB use catalogs ("databases") instead
of schemas, and lack schema support. For historic reasons, jOOQ treats MySQL catalogs as schemas and
does not support any catalog qualifier in MySQL. Instances can be created using DSL.schema(Name) and
overloads.
Methods:
- getCatalog: The catalog of this schema.
- tableStream: Stream all tables contained in this schema.
- getTables: List all tables contained in this schema.
- getTable: Get a table by its name (case-sensitive) in this schema, or null if no such table
  exists.
- primaryKeyStream: Stream all primary keys contained in this schema.
- getPrimaryKeys: List all primary keys contained in this schema.
- uniqueKeyStream: Stream all unique keys (including primary keys) contained in this schema.
- getUniqueKeys: List all unique keys (including primary keys) contained in this schema.
- foreignKeyStream: Stream all foreign keys contained in this schema.
- getForeignKeys: List all foreign keys contained in this schema.
- indexStream: Stream all indexes contained in this schema.
- getIndexes: List all indexes contained in this schema.
- udtStream: Stream all UDTs contained in this schema.
- getUDTs: List all UDTs contained in this schema.
- getUDT: Get a UDT by its name (case-sensitive) in this schema, or null if no such UDT exists.
- domainStream: Stream all domains contained in this schema.
- getDomains: List all domains contained in this schema.
- getDomain: Get a domain by its name (case-sensitive) in this schema, or null if no such domain
  exists.
- sequenceStream: Stream all sequences contained in this schema.
- getSequences: List all sequences contained in this schema.
- getSequence: Get a sequence by its name (case-sensitive) in this schema, or null if no such
  sequence exists.

Select (class, org.jooq)
A SELECT statement. Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.select(ACTOR.FIRST_NAME, ACTOR.LAST_NAME) .from(ACTOR) .fetch(); Instances can be created using
DSL.select(SelectFieldOrAsterisk...), or DSLContext.selectQuery() and overloads.
Methods:
- union: Apply the UNION set operation. In SQL, a UNION is DISTINCT by default, meaning, duplicates
  are removed from the result set. So, this is the same as unionDistinct(Select). If duplicate
  removal isn't required, or already guaranteed by the data model, it is recommended to use
  unionAll(Select), instead.
- unionDistinct: Apply the UNION DISTINCT set operation. In SQL, a UNION is DISTINCT by default.
  However, it is often useful to make this explicit to express intent when distinct removal is
  really desired.
- unionAll: Apply the UNION ALL set operation.
- except: Apply the EXCEPT (or MINUS) set operation. In SQL, an EXCEPT is DISTINCT by default,
  meaning, duplicates are removed from the result set. So, this is the same as
  exceptDistinct(Select). If duplicate removal isn't required, or already guaranteed by the data
  model, it is recommended to use exceptAll(Select), instead, if the underlying RDBMS supports it.
- exceptDistinct: Apply the EXCEPT (or MINUS) set operation. In SQL, an EXCEPT is DISTINCT by
  default. However, it is often useful to make this explicit to express intent when distinct removal
  is really desired.
- exceptAll: Apply the EXCEPT ALL set operation.
- intersect: Apply the INTERSECT set operation. In SQL, an INTERSECT is DISTINCT by default,
  meaning, duplicates are removed from the result set. So, this is the same as
  intersectDistinct(Select). If duplicate removal isn't required, or already guaranteed by the data
  model, it is recommended to use intersectAll(Select), instead, if the underlying RDBMS supports
  it. Apply the INTERSECT set operation.
- intersectDistinct: Apply the INTERSECT set operation. In SQL, a INTERSECT is DISTINCT by default.
  However, it is often useful to make this explicit to express intent when distinct removal is
  really desired.
- intersectAll: Apply the INTERSECT ALL set operation.
- getSelect: All fields selected in this query
- $with: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $select: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $distinct: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $distinctOn: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $from: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $where: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $groupBy: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $groupByDistinct: Experimental query object model accessor method, see also QOM. Subject to change
  in future jOOQ versions, use at your own risk.
- $having: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $window: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $qualify: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $orderBy: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $limit: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $limitPercent: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $limitWithTies: Experimental query object model accessor method, see also QOM. Subject to change
  in future jOOQ versions, use at your own risk.
- $offset: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

SelectFinalStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- getQuery: Get the underlying Query that is being constructed.

SelectFromStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- from DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .fetch();: Add a FROM clause to the query.
- from: Add a FROM clause to the query.
- hint DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .fetch();: Add an Oracle-style hint to the preceding select
  clause. Example: DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .fetch(); You can also use this clause for any other
  database, that accepts hints or options at the same syntactic location, e.g. for MySQL's
  SQL_CALC_FOUND_ROWS option: create.select(field1, field2) .hint("SQL_CALC_FOUND_ROWS")
  .from(table1) .fetch(); The outcome of such a query is this: SELECT [hint] field1, field2 FROM
  table1 For SQL Server style table hints, see Ungültige Referenz Table#with(String)

SelectGroupByStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- groupBy: Add a GROUP BY clause to the query Calling this with an empty argument list will result
  in an empty GROUP BY () clause being rendered.
- groupByDistinct: Add a GROUP BY DISTINCT clause to the query This is mostly useful when combined
  with DSL.groupingSets(Field[]...) to remove duplicate grouping set results prior to aggregation
  and projection.

SelectHavingStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- having: Add a HAVING clause to the query, connecting them with each other with Operator.AND.

SelectLimitStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- limit: Add a LIMIT clause to the query If there is no LIMIT or TOP clause in your RDBMS, this may
  be emulated with a ROW_NUMBER() window function and nested SELECT statements. This is the same as
  calling limit(Number, Number) with offset = 0, or calling .limit(numberOfRows).offset(0)
- offset: Add a 0-based OFFSET clause to the query. Offsets are 0-based as they describe the number
  of rows to skip. If there is no LIMIT … OFFSET or TOP clause in your RDBMS, or if your RDBMS does
  not natively support offsets, this is emulated with a ROW_NUMBER() window function and nested
  SELECT statements.

SelectOrderByStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- orderBy: Add an ORDER BY clause to the query.

SelectQuery (class, org.jooq)
A SELECT statement (model API). This type is the model API representation of a Select statement,
which can be mutated after creation. The advantage of this API compared to the DSL API is a more
simple approach to writing dynamic SQL. Instances can be created using DSLContext.selectQuery() and
overloads.
Methods:
- addSelect DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .execute();: Add a list of select fields.
- addSelect: Add a list of select fields.
- setDistinct: Add "distinct" keyword to the select clause.
- addDistinctOn: Add a PostgreSQL-specific DISTINCT ON (fields…) clause. This also sets the distinct
  flag to true
- setInto: Add a T-SQL style INTO clause to the SELECT statement to create a new table from a SELECT
  statement.
- addFrom: Add tables to the table product.
- addJoin: Joins the existing table product to a new table using a condition, connecting them with
  each other with Operator.AND.
- addJoinUsing: Joins the existing table product to a new table with a USING clause. If this is not
  supported by your RDBMS, then jOOQ will try to emulate this behaviour using the information
  provided in this query.
- addJoinOnKey: Joins the existing table product to a new table using a foreign key.
- addGroupBy: Adds grouping fields. Calling this with an empty argument list will result in an empty
  GROUP BY () clause being rendered.
- setGroupByDistinct: Specifies the GROUP BY DISTINCT clause. This is mostly useful when combined
  with DSL.groupingSets(Field[]...) to remove duplicate grouping set results prior to aggregation
  and projection.
- addHaving: Adds a new condition to the having clause of the query, connecting it with each other
  with Operator.AND.
- addWindow: Adds new window definitions to the window clause of the query.
- addQualify: Adds a new condition to the qualify clause of the query, connecting it with each other
  with Operator.AND.
- addHint DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .execute();: Add an Oracle-style hint to the select clause.
  Example: DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .hint("/*+ALL_ROWS*/") .from(table1) .execute(); You can also use this clause for any other
  database, that accepts hints or options at the same syntactic location, e.g. for MySQL's
  SQL_CALC_FOUND_ROWS option: create.select(field1, field2) .hint("SQL_CALC_FOUND_ROWS")
  .from(table1) .fetch(); The outcome of such a query is this: SELECT [hint] field1, field2 FROM
  table1 For SQL Server style table hints, see Ungültige Referenz Table#with(String)
- addOption DSLContext create = DSL.using(configuration); create.select(field1, field2)
  .from(table1) .option("OPTION (OPTIMIZE FOR UNKNOWN)") .execute();: Add a SQL Server-style query
  hint to the select clause. Example: DSLContext create = DSL.using(configuration);
  create.select(field1, field2) .from(table1) .option("OPTION (OPTIMIZE FOR UNKNOWN)") .execute();
  You can also use this clause for any other database, that accepts hints or options at the same
  syntactic location, e.g. for DB2's isolation clause: create.select(field1, field2) .from(table1)
  .option("WITH RR USE AND KEEP EXCLUSIVE LOCKS") .execute(); The outcome of such a query is this:
  SELECT field1, field2 FROM table1 [option] For SQL Server style table hints, see Ungültige
  Referenz Table#with(String)
- addConditions: Beschreibung aus Schnittstelle kopiert: ConditionProvider
- addOrderBy: Adds ordering fields.
- addSeekAfter: Adds seeking fields.
- addSeekBefore: Adds seeking fields.
- addOffset: Add a 0-based OFFSET clause to the query. Offsets are 0-based as they describe the
  number of rows to skip. If there is no LIMIT … OFFSET or TOP clause in your RDBMS, or if your
  RDBMS does not natively support offsets, this is emulated with a ROW_NUMBER() window function and
  nested SELECT statements.
- addLimit: Limit the results of this select. This is the same as calling addLimit(Number, Number)
  with offset = 0
- setLimitPercent: Add the PERCENT clause to a LIMIT clause.
- setWithTies: Add the WITH TIES clause to a LIMIT clause.
- setForUpdate SQLDialect#SQLSERVER: Sets the "FOR UPDATE" lock mode onto the query. Native
  implementation This has been observed to be supported by any of these dialects: DB2 FOR UPDATE and
  similar clauses Derby's FOR UPDATE clause H2's FOR UPDATE clause HSQLDB's FOR UPDATE clause
  MySQL's InnoDB locking reads Oracle's PL/SQL FOR UPDATE clause Postgres FOR UPDATE / FOR SHARE
  Emulation Ungültige Referenz SQLDialect#SQLSERVER : jOOQ will try to lock the database record
  using WITH (ROWLOCK, UPDLOCK) hints. Not supported These dialects are known not to support the FOR
  UPDATE clause in regular SQL: SQLDialect.SQLITE
- setForNoKeyUpdate: Sets the "FOR NO KEY UPDATE" lock mode onto the query.
- setForUpdateOf SQLDialect#DB2: Some RDBMS allow for specifying the fields that should be locked by
  the FOR UPDATE clause, instead of the full row. This automatically sets the setForUpdate(boolean)
  flag, and unsets the setForShare(boolean) flag, if it was previously set. This has been observed
  to be natively supported by any of these dialects: DB2 Derby H2 HSQLDB Ingres Oracle Sybase Note,
  that Ungültige Referenz SQLDialect#DB2 has some stricter requirements regarding the updatability
  of fields. Refer to the DB2 documentation for further details
- setForUpdateOf: Some RDBMS allow for specifying the fields that should be locked by the FOR UPDATE
  clause, instead of the full row.
- setForUpdateWait: Some RDBMS allow for specifying the locking mode for the applied FOR UPDATE
  clause. In this case, the session will wait for some seconds, before aborting the lock acquirement
  if the lock is not available. This automatically sets the setForUpdate(boolean) flag, and unsets
  the setForShare(boolean) flag, if it was previously set. This has been observed to be supported by
  any of these dialects: Oracle
- setForUpdateNoWait: Some RDBMS allow for specifying the locking mode for the applied FOR UPDATE
  clause. In this case, the session will not wait before aborting the lock acquirement if the lock
  is not available. This automatically sets the setForUpdate(boolean) flag, and unsets the
  setForShare(boolean) flag, if it was previously set. This has been observed to be supported by any
  of these dialects: Oracle
- setForUpdateSkipLocked: Some RDBMS allow for specifying the locking mode for the applied FOR
  UPDATE clause. In this case, the session will skip all locked rows from the select statement,
  whose lock is not available. This automatically sets the setForUpdate(boolean) flag, and unsets
  the setForShare(boolean) flag, if it was previously set. This has been observed to be supported by
  any of these dialects: Oracle
- setForShare: Sets the "FOR SHARE" lock mode onto the query. This has been observed to be supported
  by any of these dialects: MySQL's InnoDB locking reads Postgres FOR UPDATE / FOR SHARE
- setForKeyShare: Sets the "FOR KEY SHARE" lock mode onto the query.
- setForLockModeOf SQLDialect#DB2: Some RDBMS allow for specifying the fields that should be locked
  by the FOR <lock_mode> clause, instead of the full row. In case no lock mode has been set yet, it
  will implicitly be set to UPDATE (i.e. setForUpdate(boolean)). Depending on the dialect and lock
  mode this flag may or may not be supported. Note, that Ungültige Referenz SQLDialect#DB2 has some
  stricter requirements regarding the updatability of fields. Refer to the DB2 documentation for
  further details
- setForLockModeOf: Some RDBMS allow for specifying the fields that should be locked by the FOR
  <lock_mode> clause, instead of the full row.
- setForLockModeWait: Some RDBMS allow for specifying the locking mode for the applied FOR
  <lock_mode> clause. In this case, the session will wait for some seconds, before aborting the lock
  acquirement if the lock is not available. In case no lock mode has been set yet, it will
  implicitly be set to UPDATE (i.e. setForUpdate(boolean)). Depending on the dialect and lock mode
  this flag may or may not be supported.
- setForLockModeNoWait: Some RDBMS allow for specifying the locking mode for the applied FOR
  <lock_mode> clause. In this case, the session will not wait before aborting the lock acquirement
  if the lock is not available. In case no lock mode has been set yet, it will implicitly be set to
  UPDATE (i.e. setForUpdate(boolean)). Depending on the dialect and lock mode this flag may or may
  not be supported.
- setForLockModeSkipLocked: Some RDBMS allow for specifying the locking mode for the applied FOR
  <lock_mode> clause. In this case, the session will skip all locked rows from the select statement,
  whose lock is not available. In case no lock mode has been set yet, it will implicitly be set to
  UPDATE (i.e. setForUpdate(boolean)). Depending on the dialect and lock mode this flag may or may
  not be supported.
- setWithCheckOption: Add a WITH CHECK OPTION clause to the end of the subquery.
- setWithReadOnly: Add a WITH READ ONLY clause to the end of the subquery.

SelectWhereStep (class, org.jooq)
This type is used for the Select's DSL API when selecting generic Record types. Example: -- get all
authors' first and last names, and the number -- of books they've written in German, if they have
written -- more than five books in German in the last three years -- (from 2011), and sort those
authors by last names -- limiting results to the second and third row SELECT T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME, COUNT(*) FROM T_AUTHOR JOIN T_BOOK ON T_AUTHOR.ID = T_BOOK.AUTHOR_ID WHERE
T_BOOK.LANGUAGE = 'DE' AND T_BOOK.PUBLISHED > '2008-01-01' GROUP BY T_AUTHOR.FIRST_NAME,
T_AUTHOR.LAST_NAME HAVING COUNT(*) > 5 ORDER BY T_AUTHOR.LAST_NAME ASC NULLS FIRST LIMIT 2 OFFSET 1
FOR UPDATE OF FIRST_NAME, LAST_NAME NO WAIT Its equivalent in jOOQ create.select(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME, create.count()) .from(T_AUTHOR)
.join(T_BOOK).on(TBook.AUTHOR_ID.equal(TAuthor.ID)) .where(TBook.LANGUAGE.equal("DE"))
.and(TBook.PUBLISHED.greaterThan(parseDate('2008-01-01'))) .groupBy(TAuthor.FIRST_NAME,
TAuthor.LAST_NAME) .having(create.count().greaterThan(5))
.orderBy(TAuthor.LAST_NAME.asc().nullsFirst()) .limit(2) .offset(1) .forUpdate()
.of(TAuthor.FIRST_NAME, TAuthor.LAST_NAME) .noWait(); Refer to the manual for more details
Referencing XYZ*Step types directly from client code It is usually not recommended to reference any
XYZ*Step types directly from client code, or assign them to local variables. When writing dynamic
SQL, creating a statement's components dynamically, and passing them to the DSL API statically is
usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- where: Add a WHERE clause to the query, connecting them with each other with Operator.AND.
- whereExists: Add a WHERE EXISTS clause to the query.
- whereNotExists: Add a WHERE NOT EXISTS clause to the query.

Sequence (class, org.jooq)
A sequence. Instances can be created using DSL.sequence(Name) and overloads.
Methods:
- getStartWith: Get the start value for this sequence or null, if no such value is specified.
- getIncrementBy: Get the increment for this sequence or null, if no such value is specified.
- getMinvalue: Get the minimum value for this sequence or null, if no such value is specified.
- getMaxvalue: Get the maximum value for this sequence or null, if no such value is specified.
- getCycle: Returns true if this sequence cycles to getMinvalue() when it reaches getMaxvalue().
- getCache: Get the number of sequence values to cache for this sequence or null, if no such value
  is specified.
- currval: An expression to get the current value of this sequence.
- nextval: An expression to increment the sequence and get the next value.
- nextvals: An expression to increment the sequence and get the next values. This is done using
  DSL.generateSeries(int, int).

Table (class, org.jooq)
A table. Like Field, a Table is a basic building block of any Query, as they all operate on at least
one table. There are many different types of tables, including: Generated table or view references
Plain SQL tables created with DSL.table(String) Table references created with DSL.table(Name)
Derived tables created with DSL.table(Select) Join expressions created e.g. with join(TableLike)
Common table expressions (CommonTableExpression) Unnested arrays referenced through
DSL.unnest(Field) and overloads Table valued functions as provided by the code generator Etc.
Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.select(ACTOR.FIRST_NAME, ACTOR.LAST_NAME) .from(ACTOR) // Table reference .fetch(); Instances can
be created using DSL.table(Name) and overloads. Using table references as field expressions Table
references can be used like Field in queries. This includes: A GroupField is an expression that is
used in a Select query's GROUP BY clause. A SelectField is an expression that is used in a Select
query's SELECT clause, or in a DML query's RETURNING clause, such as INSERT … RETURNING. Other types
of Table cannot be used this way, even if the type system cannot prevent this.
Methods:
- getTableType -- Using derived column lists to rename columns (e.g. Postgres) SELECT t.a, t.b FROM
  my_table t(a, b) -- Nesting table references within derived tables (e.g. SQL Server) SELECT t.a,
  t.b FROM ( SELECT * FROM my_table ) t(a, b): Get the table type.
- getTableType: Get the table type.
- getOptions: Get the table options.
- recordType: The record type produced by this table.
- getIdentity: Retrieve the table's IDENTITY information, if available. With SQL:2003, the concept
  of IDENTITY columns was introduced in most RDBMS. These are special kinds of columns that have
  auto-increment functionality when INSERT statements are performed. An IDENTITY column is usually
  part of the PRIMARY KEY or of a UNIQUE KEY in the table, although in some RDBMS, this is not
  required. There can only be at most one IDENTITY column. Note: Unfortunately, this is not
  supported in the Oracle dialect, where identities emulated by triggers cannot be formally
  detected.
- getPrimaryKey: Retrieve the table's primary key
- getRecordVersion: A "version" field holding record version information used for optimistic locking
  jOOQ supports optimistic locking in UpdatableRecord.store() and UpdatableRecord.delete() if
  Settings.isExecuteWithOptimisticLocking() is enabled. Optimistic locking is performed in a single
  UPDATE or DELETE statement if tables provide a "version" or "timestamp" field, or in two steps
  using an additional SELECT … FOR UPDATE statement otherwise. This method is overridden in
  generated subclasses if their corresponding tables have been configured accordingly. A table may
  have both a "version" and a "timestamp" field.
- getRecordTimestamp: A "timestamp" field holding record timestamp information used for optimistic
  locking jOOQ supports optimistic locking in UpdatableRecord.store() and UpdatableRecord.delete()
  if Settings.isExecuteWithOptimisticLocking() is enabled. Optimistic locking is performed in a
  single UPDATE or DELETE statement if tables provide a "version" or "timestamp" field, or in two
  steps using an additional SELECT … FOR UPDATE statement otherwise. This method is overridden in
  generated subclasses if their corresponding tables have been configured accordingly. A table may
  have both a "version" and a "timestamp" field.
- getIndexes: Retrieve all of the table's indexes.
- getKeys: Retrieve all of the table's primary and unique keys.
- getUniqueKeys: Retrieve all of the table's unique keys.
- getReferencesFrom: Get a list of FOREIGN KEY's of a specific table, referencing a this table. This
  will recurse into joined tables.
- getReferences: Get the list of FOREIGN KEY's of this table
- getReferencesTo: Get a list of FOREIGN KEY's of this table, referencing a specific table. This
  will recurse into joined tables.
- getChecks: Get a list of CHECK constraints of this table.
- asterisk: Create a qualified asterisk expression from this table (table.*) for use with SELECT.
  When using an asterisk, jOOQ will let the database server define the order of columns, as well as
  which columns are included in the result set. If using jOOQ with generated code, this may conflict
  with the column set and its ordering as defined at code generation time, meaning columns may be in
  a different order, there may be fewer or more columns than expected. It is usually better to list
  columns explicitly.
- as: Create an alias for this table. This method works both to alias the table as well as alias the
  table in its SelectField form via the SelectField.as(String) override. In order to alias only the
  projected table expression, use DSL.field(SelectField) to wrap this table into a Field first. A
  table alias renders itself differently, depending on Context.declareTables(). There are two
  rendering modes: Declaration: The table alias renders its aliased expression (this) along with the
  AS alias clause. This typically happens in FROM and INTO clauses. Reference: The table alias
  renders its alias identifier. This happens everywhere else. There is no rendering mode that
  reproduces the aliased expression as there is no way to formally decide when that mode would be
  more appropriate than the referencing of the alias! If the aliased expression is the preferred
  output, it can be extracted from the QOM API via QOM.TableAlias.$aliased(). Note that the case-
  sensitivity of the returned table depends on Settings.getRenderQuotedNames(). By default, table
  aliases are quoted, and thus case-sensitive in many SQL dialects!
- as -- Using derived column lists to rename columns (e.g. Postgres) SELECT t.a, t.b FROM my_table
  t(a, b) -- Nesting table references within derived tables (e.g. SQL Server) SELECT t.a, t.b FROM (
  SELECT * FROM my_table ) t(a, b): Create an alias for this table and its fields. Derived column
  lists for table references Note, not all databases support derived column lists for their table
  aliases. On the other hand, some databases do support derived column lists, but only for derived
  tables. jOOQ will try to turn table references into derived tables to make this syntax work. In
  other words, the following statements are equivalent: -- Using derived column lists to rename
  columns (e.g. Postgres) SELECT t.a, t.b FROM my_table t(a, b) -- Nesting table references within
  derived tables (e.g. SQL Server) SELECT t.a, t.b FROM ( SELECT * FROM my_table ) t(a, b) Derived
  column lists for derived tables Other databases may not support derived column lists at all, but
  they do support common table expressions. The following statements are equivalent: -- Using
  derived column lists to rename columns (e.g. Postgres) SELECT t.a, t.b FROM ( SELECT 1, 2 ) AS
  t(a, b) -- Using UNION ALL to produce column names (e.g. MySQL) SELECT t.a, t.b FROM ( SELECT null
  a, null b FROM DUAL WHERE 1 = 0 UNION ALL SELECT 1, 2 FROM DUAL ) t A table alias renders itself
  differently, depending on Context.declareTables(). There are two rendering modes: Declaration: The
  table alias renders its aliased expression (this) along with the AS alias clause. This typically
  happens in FROM and INTO clauses. Reference: The table alias renders its alias identifier. This
  happens everywhere else. There is no rendering mode that reproduces the aliased expression as
  there is no way to formally decide when that mode would be more appropriate than the referencing
  of the alias! If the aliased expression is the preferred output, it can be extracted from the QOM
  API via QOM.TableAlias.$aliased(). Note that the case-sensitivity of the returned table and
  columns depends on Settings.getRenderQuotedNames(). By default, table aliases are quoted, and thus
  case-sensitive in many SQL dialects!
- as MY_TABLE.as("t1", f ->"prefix_" + f.getName());: Create an alias for this table and its fields.
  This works like as(String, String...), except that field aliases are provided by a function. This
  is useful, for instance, to prefix all columns with a common prefix: MY_TABLE.as("t1", f
  ->"prefix_" + f.getName());
- as MY_TABLE.as("t1", (f, i) ->"column" + i);: Create an alias for this table and its fields. This
  works like as(String, String...), except that field aliases are provided by a function. This is
  useful, for instance, to prefix all columns with a common prefix: MY_TABLE.as("t1", (f, i)
  ->"column" + i);
- as MY_TABLE.as(MY_OTHER_TABLE, f ->MY_OTHER_TABLE.field(f));: Create an alias for this table and
  its fields. This works like as(Table, Field...), except that field aliases are provided by a
  function. This is useful, for instance, to prefix all columns with a common prefix:
  MY_TABLE.as(MY_OTHER_TABLE, f ->MY_OTHER_TABLE.field(f));
- where: Add a WHERE clause to the table, connecting them with each other with Operator.AND. The
  resulting table acts like a derived table that projects all of this table's columns and filters by
  the argument Condition. If syntactically reasonable, the derived table may be inlined to the query
  that selects from the resulting table.
- whereExists: Add a WHERE EXISTS clause to the table. The resulting table acts like a derived table
  that projects all of this table's columns and filters by the argument Condition. If syntactically
  reasonable, the derived table may be inlined to the query that selects from the resulting table.
- whereNotExists: Add a WHERE NOT EXISTS clause to the table. The resulting table acts like a
  derived table that projects all of this table's columns and filters by the argument Condition. If
  syntactically reasonable, the derived table may be inlined to the query that selects from the
  resulting table.
- join: Join a table to this table using a JoinType. Depending on the JoinType, a subsequent
  TableOnStep.on(Condition) or TableOnStep.using(Field...) clause is required. If it is required but
  omitted, a DSL.trueCondition(), i.e. 1 = 1 condition will be rendered
- innerJoin: INNER JOIN a table to this table.
- leftJoin: LEFT OUTER JOIN a table to this table. A synonym for leftOuterJoin(TableLike).
- leftOuterJoin: LEFT OUTER JOIN a table to this table.
- rightJoin: RIGHT OUTER JOIN a table to this table. A synonym for rightOuterJoin(TableLike).
- rightOuterJoin: RIGHT OUTER JOIN a table to this table.
- fullJoin: FULL OUTER JOIN a table to this table. A synonym for fullOuterJoin(TableLike).
- fullOuterJoin: FULL OUTER JOIN a table to this table.
- crossJoin A cross join B A join B on 1 = 1: CROSS JOIN a table to this table. If this syntax is
  unavailable, it is emulated with a regular INNER JOIN. The following two constructs are
  equivalent: A cross join B A join B on 1 = 1
- naturalJoin: NATURAL JOIN a table to this table. If this is not supported by your RDBMS, then jOOQ
  will try to emulate this behaviour using the information provided in this query.
- naturalLeftOuterJoin: NATURAL LEFT OUTER JOIN a table to this table. If this is not supported by
  your RDBMS, then jOOQ will try to emulate this behaviour using the information provided in this
  query.
- naturalRightOuterJoin: NATURAL RIGHT OUTER JOIN a table to this table. If this is not supported by
  your RDBMS, then jOOQ will try to emulate this behaviour using the information provided in this
  query.
- naturalFullOuterJoin: NATURAL FULL OUTER JOIN a table to this table. If this is not supported by
  your RDBMS, then jOOQ will try to emulate this behaviour using the information provided in this
  query.
- crossApply: CROSS APPLY a table to this table.
- outerApply: OUTER APPLY a table to this table.
- straightJoin: STRAIGHT_JOIN a table to this table.
- eq: The EQ operator.
- equal: The EQUAL operator, an alias for the EQ operator.
- ne: The NE operator.
- notEqual: The NOT_EQUAL operator, an alias for the NE operator.
- rowid -- Emulating this MySQL statement... DELETE FROM x ORDER BY x.y LIMIT 1 -- ... in other
  databases DELETE FROM x WHERE x.rowid IN ( SELECT x.rowid FROM x ORDER BY x.a LIMIT 1 ): The ROWID
  operator. Get a table.rowid reference from this table. A rowid value describes the physical
  location of a row on the disk, which can be used as a replacement for a primary key in some
  situations - especially within a query, e.g. to self-join a table: -- Emulating this MySQL
  statement... DELETE FROM x ORDER BY x.y LIMIT 1 -- ... in other databases DELETE FROM x WHERE
  x.rowid IN ( SELECT x.rowid FROM x ORDER BY x.a LIMIT 1 ) It is not recommended to use rowid
  values in client applications as actual row identifiers as the database system may move a row to a
  different physical location at any time, thus changing the rowid value. In general, use primary
  keys, instead.
- equals: Check whether this QueryPart can be considered equal to another QueryPart. In general,
  QueryPart equality is defined in terms of QueryPart.toString() equality. In other words, two query
  parts are considered equal if their rendered SQL (with inlined bind variables) is equal. This
  means that the two query parts do not necessarily have to be of the same type. Some QueryPart
  implementations may choose to override this behaviour for improved performance, as
  QueryPart.toString() is an expensive operation, if called many times. Watch out! This is
  Object.equals(Object), not a jOOQ DSL feature!
- useIndex create.select() .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();: Specify a MySQL style
  table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();
- useIndexForJoin create.select() .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();: Specify
  a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();
- useIndexForOrderBy create.select() .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();
- useIndexForGroupBy create.select() .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();
- ignoreIndex create.select() .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();: Specify a MySQL
  style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();
- ignoreIndexForJoin create.select() .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();
- ignoreIndexForOrderBy create.select() .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();
- ignoreIndexForGroupBy create.select() .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();
- forceIndex create.select() .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();: Specify a MySQL
  style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndex("MY_INDEX") .fetch();
- forceIndexForJoin create.select() .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForJoin("MY_INDEX") .fetch();
- forceIndexForOrderBy create.select() .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForOrderBy("MY_INDEX") .fetch();
- forceIndexForGroupBy create.select() .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();:
  Specify a MySQL style table hint for query optimisation. Example: create.select()
  .from(BOOK.as("b").useIndexForGroupBy("MY_INDEX") .fetch();
- withOrdinality DSL#rownum(): Add the WITH ORDINALITY clause. This clause can be emulated using
  derived tables and calculations of DSL.rowNumber() or Ungültige Referenz DSL#rownum() , where
  supported. The ordering stability of such a derived table is at the mercy of the optimiser
  implementation, and may break "unexpectedly," derived table ordering isn't required to be stable
  in most RDBMS. So, unless the ordinality can be assigned without any ambiguity (e.g. through
  native support or because the emulation is entirely implemented in jOOQ, client side), it is
  better not to rely on deterministic ordinalities, other than the fact that all numbers from 1 to N
  will be assigned uniquely.
- divideBy Assume the following cross join / cartesian product C = A × B Then it can be said that A
  = C ÷ B B = C ÷ A: Create a new TABLE reference from this table, applying relational division.
  Relational division is the inverse of a cross join operation. The following is an approximate
  definition of a relational division: Assume the following cross join / cartesian product C = A × B
  Then it can be said that A = C ÷ B B = C ÷ A With jOOQ, you can simplify using relational
  divisions by using the following syntax: C.divideBy(B).on(C.ID.equal(B.C_ID)).returning(C.TEXT)
  The above roughly translates to SELECT DISTINCT C.TEXT FROM C "c1" WHERE NOT EXISTS ( SELECT 1
  FROM B WHERE NOT EXISTS ( SELECT 1 FROM C "c2" WHERE "c2".TEXT = "c1".TEXT AND "c2".ID = B.C_ID )
  ) Or in plain text: Find those TEXT values in C whose ID's correspond to all ID's in B. Note that
  from the above SQL statement, it is immediately clear that proper indexing is of the essence. Be
  sure to have indexes on all columns referenced from the on(…) and returning(…) clauses. For more
  information about relational division and some nice, real-life examples, see http
  ://en.wikipedia.org/wiki/Relational_algebra#Division http://www.simple-talk.com/sql/t-sql-
  programming/divided-we-stand-the- sql-of-relational-division/ This has been observed to work with
  all dialects
- leftSemiJoin -- Using LEFT SEMI JOIN FROM A LEFT SEMI JOIN B ON A.ID = B.ID -- Using WHERE EXISTS
  FROM A WHERE EXISTS ( SELECT 1 FROM B WHERE A.ID = B.ID ): A synthetic LEFT SEMI JOIN clause that
  translates to an equivalent EXISTS predicate. The following two SQL snippets are semantically
  equivalent: -- Using LEFT SEMI JOIN FROM A LEFT SEMI JOIN B ON A.ID = B.ID -- Using WHERE EXISTS
  FROM A WHERE EXISTS ( SELECT 1 FROM B WHERE A.ID = B.ID ) Notice that according to Relational
  algebra's understanding of left semi join, the right hand side of the left semi join operator is
  not projected, i.e. it cannot be accessed from WHERE or SELECT or any other clause than ON.
- leftAntiJoin -- Using LEFT ANTI JOIN FROM A LEFT ANTI JOIN B ON A.ID = B.ID -- Using WHERE NOT
  EXISTS FROM A WHERE NOT EXISTS ( SELECT 1 FROM B WHERE A.ID = B.ID ): A synthetic LEFT ANTI JOIN
  clause that translates to an equivalent NOT EXISTS predicate. The following two SQL snippets are
  semantically equivalent: -- Using LEFT ANTI JOIN FROM A LEFT ANTI JOIN B ON A.ID = B.ID -- Using
  WHERE NOT EXISTS FROM A WHERE NOT EXISTS ( SELECT 1 FROM B WHERE A.ID = B.ID ) Notice that
  according to Relational algebra's understanding of left anti join, the right hand side of the left
  anti join operator is not projected, i.e. it cannot be accessed from WHERE or SELECT or any other
  clause than ON.
- from DSL.using(configuration) .fetch("select * from t") .stream() .map(MY_TABLE::into)
  .forEach(System.out::println);: The inverse operation of Record.into(Table). This method can be
  used in its method reference form conveniently on a generated table, for instance, when mapping
  records in a stream: DSL.using(configuration) .fetch("select * from t") .stream()
  .map(MY_TABLE::into) .forEach(System.out::println);

TableField (class, org.jooq)
A field contained in a table. Instances of this type cannot be created directly. They are available
from generated code.
Methods:
- getTable:

TableRecord (class, org.jooq)
A record originating from a single table
Methods:
- getTable: The table from which this record was read.
- original: Beschreibung aus Schnittstelle kopiert: Record
- insert: Store this record to the database using an INSERT statement. If you want to enforce re-
  insertion this record's values, regardless if the values in this record were Record.modified(),
  you can explicitly set the touched flags for all values with Record.touched(boolean) or for single
  values with Record.touched(Field, boolean), prior to insertion, if
  Settings.getRecordDirtyTracking() is set to RecordDirtyTracking.TOUCHED
- fetchParent: Fetch a parent record of this record, given a foreign key. This returns a parent
  record referenced by this record through a given foreign key, as if fetching from
  parent(ForeignKey). If no parent record was found, this returns null. A separate roundtrip is
  created by this operation. It is often much better to include parent records using ordinary JOIN
  mechanisms in a single query, or using nested records, see
  https://www.jooq.org/doc/latest/manual/sql-building/column-expressions/nested-records/.
- parent: Get a table expression representing the parent of this record, given a foreign key.

Transaction (class, org.jooq)
A custom transaction object.

TransactionContext (class, org.jooq)
A context object that is used to pass arguments to the various methods of TransactionProvider. This
type is a Scope with independent lifecycle and its own Scope.data() map.
Methods:
- transaction: A user-defined transaction object, possibly obtained from
  TransactionProvider.begin(TransactionContext).
- result: The result of a TransactionalCallable or ContextTransactionalCallable, if the transaction
  has completed successfully.
- cause: The exception that has caused the rollback.
- causeThrowable: The throwable that has caused the rollback.

TransactionProvider (class, org.jooq)
The TransactionProvider SPI can be used to implement custom transaction behaviour that is applied
when calling DSLContext.transactionResult(TransactionalCallable) or
DSLContext.transaction(TransactionalRunnable). A new Configuration copy is created from the calling
DSLContext for the scope of a single transactions. Implementors may freely add custom data to
Configuration.data(), in order to share information between begin(TransactionContext) and
commit(TransactionContext) or rollback(TransactionContext), as well as to share information with
nested transactions. Implementors may freely choose whether they support nested transactions. An
example implementation supporting nested transactions is DefaultTransactionProvider, which
implements such transactions using JDBC Savepoints.
Methods:
- begin: Begin a new transaction. This method begins a new transaction with a Configuration scoped
  for this transaction. The resulting Transaction object may be used by implementors to identify the
  transaction when commit(TransactionContext) or rollback(TransactionContext) is called.
- commit: Commit a transaction.
- rollback: Rollback a transaction.

Type (class, org.jooq)
An object representing a user defined type.

UniqueKey (class, org.jooq)
A UniqueKey is an object representing a UNIQUE KEY or a PRIMARY KEY. It can be referenced by a
ForeignKey. Instances of this type cannot be created directly. They are available from generated
code.
Methods:
- getReferences: A list of all ForeignKeys, referencing this UniqueKey
- isPrimary: Whether this is the table's primary key.

UpdatableRecord (class, org.jooq)
A common interface for records that can be stored back to the database again. Any Record can be
updatable, if it represents a record from a table or view - a TableRecord its underlying table or
view has a "main unique key", i.e. a primary key or at least one unique key The "main unique key" is
used by jOOQ to perform the various operations that can be performed on an UpdatableRecord: delete()
: Deleting the record refresh() : Refreshing the records attributes (or loading it for the first
time) store() : Storing the record to the database. This executes either an INSERT or an UPDATE
statement merge() : Merging a record to the database. This executes an INSERT … ON DUPLICATE KEY
UPDATE statement. UpdatableRecords are Attachable, which means that they hold an underlying
Configuration that they can be detached from. They can also be instantiated without any underlying
Configuration, in case of which they have to be attached first, in order to be refreshed, stored, or
deleted.
Methods:
- key SQLDialect#SQLSERVER: A Record copy holding values for the Table.getPrimaryKey(). The returned
  record consists exactly of those fields as returned by the table's primary key: Key.getFields().
  Generated subtypes may covariantly override this method to add more record type information. For
  instance, they may return Record1, Record2, ...
- key: A Record copy holding values for the Table.getPrimaryKey(). The returned record consists
  exactly of those fields as returned by the table's primary key: Key.getFields(). Generated
  subtypes may covariantly override this method to add more record type information. For instance,
  they may return Record1, Record2, ...
- store SQLDialect#SQLSERVER: Store this record back to the database. Depending on the state of the
  primary key's value, an insert() or an update() statement is executed. Statement type If this
  record was created by client code, an INSERT statement is executed If this record was loaded by
  jOOQ and the primary key value was touched, an INSERT statement is executed (unless
  Settings.isUpdatablePrimaryKeys() is set). jOOQ expects that primary key values will never change
  due to the principle of normalisation in RDBMS. So if client code changes primary key values, this
  is interpreted by jOOQ as client code wanting to duplicate this record. If this record was loaded
  by jOOQ, and the primary key value was not touched, an UPDATE statement is executed. In either
  statement type, only those fields are inserted/updated, which had been explicitly set by client
  code, in order to allow for DEFAULT values to be applied by the underlying RDBMS. If no fields
  were modified, neither an UPDATE nor an INSERT will be executed. Automatic value generation Use
  insert() or update() to explicitly force either statement type. IDENTITY columns If there is an
  IDENTITY column defined on the record's underlying table (see Table.getIdentity()), then the auto-
  generated IDENTITY value is refreshed automatically on INSERT's. Refreshing is done using
  Statement.getGeneratedKeys(), where this is supported by the JDBC driver. See also
  InsertQuery.getReturnedRecord() for more details VERSION and TIMESTAMP columns jOOQ can auto-
  generate "version" and "timestamp" values that can be used for optimistic locking. If this is an
  UpdatableRecord and if this record returns fields for either Table.getRecordVersion() or
  Table.getRecordTimestamp(), then these values are set onto the INSERT or UPDATE statement being
  executed. On execution success, the generated values are set to this record. Use the code-
  generation configuration to specify naming patterns for auto-generated "version" and "timestamp"
  columns. Should you want to circumvent jOOQ-generated updates to these columns, you can render an
  INSERT or UPDATE statement manually using the various DSLContext.insertInto(Table),
  DSLContext.update(Table) methods. Optimistic locking If an UPDATE statement is executed and
  Settings.isExecuteWithOptimisticLocking() is set to true, then this record will first be compared
  with the latest state in the database. There are two modes of operation for optimistic locking:
  With VERSION and/or TIMESTAMP columns configured This is the preferred way of using optimistic
  locking in jOOQ. If this is an UpdatableRecord and if this record returns fields for either
  Table.getRecordVersion() or Table.getRecordTimestamp(), then these values are compared to the
  corresponding value in the database in the WHERE clause of the executed DELETE statement. Without
  any specific column configurations In order to compare this record with the latest state, the
  database record will be locked pessimistically using a SELECT … FOR UPDATE statement. Not all
  databases support the FOR UPDATE clause natively. Namely, the following databases will show
  slightly different behaviour: Ungültige Referenz SQLDialect#SQLSERVER : jOOQ will try to lock the
  database record using WITH (ROWLOCK, UPDLOCK) hints. SQLDialect.SQLITE: No pessimistic locking is
  possible. Client code must assure that no race-conditions can occur between jOOQ's checking of
  database record state and the actual UPDATE See SelectQuery.setForUpdate(boolean) for more details
  Statement examples Possible statements are INSERT INTO [table] ([modified fields, including keys])
  VALUES ([modified values, including keys]) UPDATE [table] SET [modified fields = modified values,
  excluding keys] WHERE [key fields = key values] AND [version/timestamp fields = version/timestamp
  values] Statement execution enforcement If you want to control statement re-execution, regardless
  if the values in this record were Record.modified(), you can explicitly set the touched flags for
  all values with Record.touched(boolean) or for single values with Record.touched(Field, boolean),
  prior to storing, if Settings.getRecordDirtyTracking() is set to RecordDirtyTracking.TOUCHED.
  Consider also setting the flags Settings.getUpdateUnchangedRecords() and/or
  Settings.isInsertUnchangedRecords() appropriately to control if the record should be "touched"
  without any changes (UPDATE) or inserted with default values (INSERT). This is the same as calling
  record.store(record.fields()) Effects on this record After a successful store() operation, this
  record will have: Its Record.valuesRow() unchanged Its TableRecord.original() values set to the
  same values as Record.valuesRow(). Its Record.touched() flags set to false Its Record.modified()
  flags set to false
- store: Store parts of this record to the database.
- insert: Store this record back to the database using an INSERT statement. This is the same as
  store(), except that an INSERT statement (or no statement) will always be executed. If you want to
  enforce re-insertion this record's values, regardless if the values in this record were touched,
  you can explicitly set the touched flags for all values with Record.touched(boolean) or for single
  values with Record.touched(Field, boolean), prior to insertion, if
  Settings.getRecordDirtyTracking() is set to RecordDirtyTracking.TOUCHED This is the same as
  calling record.insert(record.fields()) Effects on this record After a successful insert()
  operation, this record will have: Its Record.valuesRow() unchanged Its TableRecord.original()
  values set to the same values as Record.valuesRow(). Its Record.touched() flags set to false Its
  Record.modified() flags set to false
- update: Store this record back to the database using an UPDATE statement. This is the same as
  store(), except that an UPDATE statement (or no statement) will always be executed. If you want to
  enforce statement execution, regardless if the values in this record were Record.modified(), you
  can explicitly set the touched flags for all values with Record.touched(boolean) or for single
  values with Record.touched(Field, boolean), prior to updating, if
  Settings.getRecordDirtyTracking() is set to RecordDirtyTracking.TOUCHED, or alternatively, use
  Settings.getUpdateUnchangedRecords(). This is the same as calling record.update(record.fields())
  Effects on this record After a successful update() operation, this record will have: Its
  Record.valuesRow() unchanged Its TableRecord.original() values set to the same values as
  Record.valuesRow(). Its Record.touched() flags set to false Its Record.modified() flags set to
  false
- merge: Store this record back to the database using a MERGE statement. Unlike store(), the
  statement produced by this operation does not depend on whether the record has been previously
  fetched from the database or created afresh. It implements the semantics of an INSERT … ON
  DUPLICATE KEY UPDATE statement, which will update the row regardless of which (unique) key value
  is already present. See InsertOnDuplicateStep.onDuplicateKeyUpdate(). When optimistic locking is
  active for this record, then this operation will execute insert() or update() explicitly,
  depending on whether the lock values are present already in the record. If you want to enforce
  statement execution, regardless if the values in this record were Record.modified(), you can
  explicitly set the touched flags for all values with Record.touched(boolean) or for single values
  with Record.touched(Field, boolean), prior to merging, if Settings.getRecordDirtyTracking() is set
  to RecordDirtyTracking.TOUCHED. This is the same as calling record.merge(record.fields()) Effects
  on this record After a successful merge() operation, this record will have: Its Record.valuesRow()
  unchanged Its TableRecord.original() values set to the same values as Record.valuesRow(). Its
  Record.touched() flags set to false Its Record.modified() flags set to false
- delete SQLDialect#SQLSERVER: Deletes this record from the database, based on the value of the
  primary key or main unique key. Optimistic locking If a DELETE statement is executed and
  Settings.isExecuteWithOptimisticLocking() is set to true, then this record will first be compared
  with the latest state in the database. There are two modes of operation for optimistic locking:
  With VERSION and/or TIMESTAMP columns configured This is the preferred way of using optimistic
  locking in jOOQ. If this is an UpdatableRecord and if this record returns fields for either
  Table.getRecordVersion() or Table.getRecordTimestamp(), then these values are compared to the
  corresponding value in the database in the WHERE clause of the executed DELETE statement. Without
  any specific column configurations In order to compare this record with the latest state, the
  database record will be locked pessimistically using a SELECT … FOR UPDATE statement. Not all
  databases support the FOR UPDATE clause natively. Namely, the following databases will show
  slightly different behaviour: Ungültige Referenz SQLDialect#SQLSERVER : jOOQ will try to lock the
  database record using WITH (ROWLOCK, UPDLOCK) hints. SQLDialect.SQLITE: No pessimistic locking is
  possible. Client code must assure that no race-conditions can occur between jOOQ's checking of
  database record state and the actual DELETE See SelectQuery.setForUpdate(boolean) for more details
  Effects on this record After a successful delete() operation, this record will have: Its
  Record.valuesRow() unchanged Its TableRecord.original() values reset to null Its Record.touched()
  flags set to true Its Record.modified() flags set to true Statement examples The executed
  statement is DELETE FROM [table] WHERE [key fields = key values] AND [version/timestamp fields =
  version/timestamp values] This is in fact the same as calling
  delete(getTable().getPrimaryKey().getFieldsArray())
- refresh: Refresh this record from the database. A successful refresh results in the following:
  Record.valuesRow() will have been restored to the respective values from the database
  TableRecord.original() will match this record Record.touched() will be false Record.modified()
  will be false Refreshing can trigger any of the following actions: Executing a new SELECT
  statement, if this is an UpdatableRecord. Failing, otherwise This is the same as calling
  record.refresh(record.fields())
- copy: Duplicate this record (in memory) and reset all fields from the primary key or main unique
  key, such that a subsequent call to store() will result in an INSERT statement. Effects on this
  record After a copy() operation, the resulting record will have: Its Record.valuesRow() just like
  the source record Its TableRecord.original() values set null. Its Record.touched() flags set to
  true Its Record.modified() flags set to false
- fetchChild: Fetch a child record of this record, given a foreign key. This returns a child record
  referencing this record through a given foreign key, as if fetching from children(ForeignKey).. If
  no child record was found, this returns null. A separate roundtrip is created by this operation.
  It is often much better to include parent records using ordinary JOIN mechanisms in a single
  query, or using nested records, or the MULTISET or MULTISET_AGG operators, see
  https://www.jooq.org/doc/latest/manual/sql-building/column-expressions/nested-records/, or the
  https://www.jooq.org/doc/latest/manual/sql-building/column-expressions/multiset-value-
  constructor/.
- fetchChildren: Fetch child records of this record, given a foreign key. This returns child records
  referencing this record through a given foreign key, as if fetching from children(ForeignKey). A
  separate roundtrip is created by this operation. It is often much better to include parent records
  using ordinary JOIN mechanisms in a single query, or using nested records, or the MULTISET or
  MULTISET_AGG operators, see https://www.jooq.org/doc/latest/manual/sql-building/column-
  expressions/nested-records/, or the https://www.jooq.org/doc/latest/manual/sql-building/column-
  expressions/multiset-value-constructor/.
- children: Get a table expression representing the children of this record, given a foreign key.

Update (class, org.jooq)
An UPDATE statement. Example: // Assuming import static org.jooq.impl.DSL.*; using(configuration)
.update(CUSTOMER) .set(CUSTOMER.STATUS, "Gold") .where(CUSTOMER.ID.eq(1)) .execute(); Instances can
be created using DSL.update(Table), or DSLContext.updateQuery(Table) and overloads.

UpdateFinalStep (class, org.jooq)
This type is used for the Update's DSL API. Example: DSLContext create = DSL.using(configuration);
create.update(table) .set(field1, value1) .set(field2, value2) .where(field1.greaterThan(100))
.execute(); Referencing XYZ*Step types directly from client code It is usually not recommended to
reference any XYZ*Step types directly from client code, or assign them to local variables. When
writing dynamic SQL, creating a statement's components dynamically, and passing them to the DSL API
statically is usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases

UpdateQuery (class, org.jooq)
An UPDATE statement (model API). This type is the model API representation of a Update statement,
which can be mutated after creation. The advantage of this API compared to the DSL API is a more
simple approach to writing dynamic SQL. Instances can be created using DSLContext.updateQuery(Table)
and overloads.
Methods:
- addValues: Specify a multi-column set clause for the UPDATE statement.
- addFrom: Add tables to the table product.
- addConditions: Beschreibung aus Schnittstelle kopiert: ConditionProvider
- addOrderBy: Adds ordering fields.
- addLimit: Limit the results of this select.
- setReturning: Configure the INSERT or UPDATE statement to return all fields in R. This feature
  works with UPDATE statements for a subset of SQL dialects
- getReturnedRecord: The record holding returned values as specified by any of the
  StoreQuery.setReturning() methods. If the insert statement returns several records, this is the
  same as calling getReturnedRecords().get(0) This implemented differently for every dialect:
  Firebird and Postgres have native support for INSERT … RETURNING and UPDATE … RETURNING clauses
  HSQLDB, Oracle, and DB2 JDBC drivers allow for retrieving any table column as "generated key" in
  one statement Derby, H2, Ingres, MySQL, SQL Server only allow for retrieving IDENTITY column
  values as "generated key". If other fields are requested, a second statement is issued. Client
  code must assure transactional integrity between the two statements. Sybase and SQLite allow for
  retrieving IDENTITY values as @@identity or last_inserted_rowid() values. Those values are fetched
  in a separate SELECT statement. If other fields are requested, a second statement is issued.
  Client code must assure transactional integrity between the two statements. This feature works
  with UPDATE statements for a subset of SQL dialects
- getReturnedRecords: The records holding returned values as specified by any of the
  StoreQuery.setReturning() methods. This implemented differently for every dialect: Firebird and
  Postgres have native support for INSERT … RETURNING and UPDATE … RETURNING clauses HSQLDB, Oracle,
  and DB2 JDBC drivers allow for retrieving any table column as "generated key" in one statement
  Derby, H2, Ingres, MySQL, SQL Server only allow for retrieving IDENTITY column values as
  "generated key". If other fields are requested, a second statement is issued. Client code must
  assure transactional integrity between the two statements. Sybase and SQLite allow for retrieving
  IDENTITY values as @@identity or last_inserted_rowid() values. Those values are fetched in a
  separate SELECT statement. If other fields are requested, a second statement is issued. Client
  code must assure transactional integrity between the two statements. [#5070] Due to an early API
  design flaw, this method historically returns the type R, not a more generic type Record. This
  means that only actual columns in R can be returned. For a more generic set of column expressions,
  use StoreQuery.getResult() instead. This feature works with UPDATE statements for a subset of SQL
  dialects

UpdateSetStep (class, org.jooq)
This type is used for the Update's DSL API. Example: DSLContext create = DSL.using(configuration);
create.update(table) .set(field1, value1) .set(field2, value2) .where(field1.greaterThan(100))
.execute(); Referencing XYZ*Step types directly from client code It is usually not recommended to
reference any XYZ*Step types directly from client code, or assign them to local variables. When
writing dynamic SQL, creating a statement's components dynamically, and passing them to the DSL API
statically is usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- set: Set a value for a field in the UPDATE statement.
- setNull: Set a null value for a field in the UPDATE statement. This method is convenience for
  calling set(Field, Object), without the necessity of casting the Java null literal to (T).

UpdateWhereStep (class, org.jooq)
This type is used for the Update's DSL API. Example: DSLContext create = DSL.using(configuration);
create.update(table) .set(field1, value1) .set(field2, value2) .where(field1.greaterThan(100))
.execute(); Referencing XYZ*Step types directly from client code It is usually not recommended to
reference any XYZ*Step types directly from client code, or assign them to local variables. When
writing dynamic SQL, creating a statement's components dynamically, and passing them to the DSL API
statically is usually a better choice. See the manual's section about dynamic SQL for details:
https://www.jooq.org/doc/latest/manual/sql-building/dynamic-sql. Drawbacks of referencing the
XYZ*Step types directly: They're operating on mutable implementations (as of jOOQ 3.x) They're less
composable and not easy to get right when dynamic SQL gets complex They're less readable They might
have binary incompatible changes between minor releases
Methods:
- where: Add conditions to the query, connecting them with each other with Operator.AND.
- whereExists: Add an EXISTS clause to the query
- whereNotExists: Add a NOT EXISTS clause to the query

WindowDefinition (class, org.jooq)
A window definition. Window definitions can be declared in the WINDOW clause (see
SelectWindowStep.window(WindowDefinition...) referenced from the OVER clause (see
WindowOverStep.over(WindowDefinition) The WINDOW clause is only natively supported by Ungültige
Referenz SQLDialect#AURORA_POSTGRES SQLDialect.H2 SQLDialect.MYSQL SQLDialect.POSTGRES
SQLDialect.SQLITE Ungültige Referenz SQLDialect#SYBASE If your database supports window functions,
but not the WINDOW clause, jOOQ will inline window definitions into their respective window
functions. Instances can be created using Name.as(WindowSpecification) and overloads.
Methods:
- $name: Experimental query object model accessor method, see also QOM. Subject to change in future
  jOOQ versions, use at your own risk.
- $windowSpecification: Experimental query object model accessor method, see also QOM. Subject to
  change in future jOOQ versions, use at your own risk.

WindowSpecification (class, org.jooq)
A window specification. Window specifications are the syntactic clauses that can be passed to both
window definitions in WINDOW clauses, as well as to the OVER clause of window functions. This makes
window specifications highly reusable across several queries. Example: WindowSpecification spec =
DSL.partitionBy(BOOK.AUTHOR_ID) .orderBy(BOOK.ID) .rowsBetweenUnboundedPreceding() .andCurrentRow();
Instances can be created using DSL.partitionBy(GroupField...), DSL.orderBy(OrderField...), and
overloads as well as rows / range / groups related methods in DSL.
Methods:
- $windowDefinition: Experimental query object model accessor method, see also QOM. Subject to
  change in future jOOQ versions, use at your own risk.
- $partitionBy: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $orderBy: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $frameUnits: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $frameStart: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $frameEnd: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.
- $exclude: Experimental query object model accessor method, see also QOM. Subject to change in
  future jOOQ versions, use at your own risk.

WithStep (class, org.jooq)
This type is part of the jOOQ DSL to create Select, Insert, Update, Delete, Merge statements
prefixed with a WITH clause and with CommonTableExpressions. Example: DSL.with("table", "col1",
"col2") .as( select(one(), two()) ) .select() .from("table") Referencing XYZ*Step types directly
from client code It is usually not recommended to reference any XYZ*Step types directly from client
code, or assign them to local variables. When writing dynamic SQL, creating a statement's components
dynamically, and passing them to the DSL API statically is usually a better choice. See the manual's
section about dynamic SQL for details: https://www.jooq.org/doc/latest/manual/sql-building/dynamic-
sql. Drawbacks of referencing the XYZ*Step types directly: They're operating on mutable
implementations (as of jOOQ 3.x) They're less composable and not easy to get right when dynamic SQL
gets complex They're less readable They might have binary incompatible changes between minor
releases
Methods:
- with SELECT table.col1, table.col2 FROM table: Add another common table expression to the WITH
  clause.
- with: Add another common table expression to the WITH clause.
- selectFrom SELECT table.col1, table.col2 FROM table: Create a new DSL select statement, projecting
  the known columns from a table. This will project the known columns from the argument table
  querying Fields.fields(). If no known columns are available (e.g. because the table has been
  created using DSL.table(String)), then SELECT * is projected. Example: SELECT table.col1,
  table.col2 FROM table
- selectFrom SELECT * FROM table: Create a new DSL select statement, projecting *. Without knowing
  any columns from the argument table (see selectFrom(TableLike)), this will project SELECT *.
  Example: SELECT * FROM table
- select DSLContext create = DSL.using(configuration); create.select(fields) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This creates an attached, renderable and executable SELECT statement
  from this DSLContext. If you don't need to render or execute this SELECT statement (e.g. because
  you want to create a subselect), consider using the static DSL.select(Collection) instead.
  Example: DSLContext create = DSL.using(configuration); create.select(fields) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select DSLContext create = DSL.using(configuration); create.select(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2)
  .execute();: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.select(SelectFieldOrAsterisk...) instead. Example: DSLContext create =
  DSL.using(configuration); create.select(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2)
  .execute();
- select using(configuration) .with(name("t").fields(field1).as(subselect)) .select(field1)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  select(SelectFieldOrAsterisk...), except that it declares additional record-level typesafety,
  which is needed by Field.in(Select), Field.equal(Select) and other predicate building methods
  taking subselect arguments. This creates an attached, renderable and executable SELECT statement
  from this DSLContext. If you don't need to render or execute this SELECT statement (e.g. because
  you want to create a subselect), consider using the static DSL.select(SelectField) instead.
  Example: using(configuration) .with(name("t").fields(field1).as(subselect)) .select(field1)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .with(name("t").fields(field1, field2).as(subselect)) .select(field1,
  field2) .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This is the same as
  select(SelectFieldOrAsterisk...), except that it declares additional record-level typesafety,
  which is needed by Row2.in(Select), Row2.equal(Select) and other predicate building methods taking
  subselect arguments. This creates an attached, renderable and executable SELECT statement from
  this DSLContext. If you don't need to render or execute this SELECT statement (e.g. because you
  want to create a subselect), consider using the static DSL.select(SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(field1, field2).as(subselect))
  .select(field1, field2) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(field1, field2, field3).as(subselect))
  .select(field1, field2, field3) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as select(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row3.in(Select), Row3.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.select(SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(field1,
  field2, field3).as(subselect)) .select(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(field1, field2, field3, field4).as(subselect))
  .select(field1, field2, field3, field4) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as select(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row4.in(Select), Row4.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.select(SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(field1, field2, field3, field4).as(subselect)) .select(field1, field2,
  field3, field4) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(field1, field2, field3, field4,
  field5).as(subselect)) .select(field1, field2, field3, field4, field5) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row5.in(Select),
  Row5.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(field1, field2, field3, field4,
  field5).as(subselect)) .select(field1, field2, field3, field4, field5) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f5, f6).as(subselect))
  .select(field1, field2, field3, .., field5, field6) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row6.in(Select),
  Row6.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f5,
  f6).as(subselect)) .select(field1, field2, field3, .., field5, field6) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f6, f7).as(subselect))
  .select(field1, field2, field3, .., field6, field7) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row7.in(Select),
  Row7.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f6, f7).as(subselect)) .select(field1, field2, field3, .., field6, field7) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f7, f8).as(subselect))
  .select(field1, field2, field3, .., field7, field8) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row8.in(Select),
  Row8.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f7, f8).as(subselect)) .select(field1, field2, field3, ..,
  field7, field8) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f8, f9).as(subselect))
  .select(field1, field2, field3, .., field8, field9) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row9.in(Select),
  Row9.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f8, f9).as(subselect)) .select(field1, field2, field3, ..,
  field8, field9) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f9, f10).as(subselect))
  .select(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row10.in(Select),
  Row10.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f9, f10).as(subselect))
  .select(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f10, f11).as(subselect))
  .select(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row11.in(Select),
  Row11.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f10, f11).as(subselect))
  .select(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f11, f12).as(subselect))
  .select(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row12.in(Select),
  Row12.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f11,
  f12).as(subselect)) .select(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f12, f13).as(subselect))
  .select(field1, field2, field3, .., field12, field13) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row13.in(Select),
  Row13.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f12,
  f13).as(subselect)) .select(field1, field2, field3, .., field12, field13) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f13, f14).as(subselect))
  .select(field1, field2, field3, .., field13, field14) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row14.in(Select),
  Row14.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f13, f14).as(subselect)) .select(field1, field2, field3, .., field13, field14)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f14, f15).as(subselect))
  .select(field1, field2, field3, .., field14, field15) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row15.in(Select),
  Row15.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f14, f15).as(subselect)) .select(field1, field2, field3,
  .., field14, field15) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f15, f16).as(subselect))
  .select(field1, field2, field3, .., field15, field16) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row16.in(Select),
  Row16.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f15, f16).as(subselect)) .select(field1, field2, field3,
  .., field15, field16) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f16, f17).as(subselect))
  .select(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row17.in(Select),
  Row17.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f16, f17).as(subselect))
  .select(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f17, f18).as(subselect))
  .select(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row18.in(Select),
  Row18.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f17, f18).as(subselect))
  .select(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f18, f19).as(subselect))
  .select(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row19.in(Select),
  Row19.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f18,
  f19).as(subselect)) .select(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f19, f20).as(subselect))
  .select(field1, field2, field3, .., field19, field20) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row20.in(Select),
  Row20.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f19,
  f20).as(subselect)) .select(field1, field2, field3, .., field19, field20) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f20, f21).as(subselect))
  .select(field1, field2, field3, .., field20, field21) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row21.in(Select),
  Row21.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f20, f21).as(subselect)) .select(field1, field2, field3, .., field20, field21)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- select using(configuration) .with(name("t").fields(f1, f2, f3, .., f21, f22).as(subselect))
  .select(field1, field2, field3, .., field21, field22) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as select(SelectFieldOrAsterisk...), except that it
  declares additional record-level typesafety, which is needed by Row22.in(Select),
  Row22.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.select(SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f21, f22).as(subselect)) .select(field1, field2, field3,
  .., field21, field22) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct DSLContext create = DSL.using(configuration); create.selectDistinct(fields)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectDistinct(Collection) instead. Example: DSLContext create = DSL.using(configuration);
  create.selectDistinct(fields) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct DSLContext create = DSL.using(configuration); create.selectDistinct(field1, field2)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);: Create a new DSL select statement. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectDistinct(SelectFieldOrAsterisk...) instead. Example: DSLContext create =
  DSL.using(configuration); create.selectDistinct(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(field1).as(subselect))
  .selectDistinct(field1) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Field.in(Select), Field.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField)
  instead. Example: using(configuration) .with(name("t").fields(field1).as(subselect))
  .selectDistinct(field1) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(field1, field2).as(subselect))
  .selectDistinct(field1, field2) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row2.in(Select), Row2.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(field1,
  field2).as(subselect)) .selectDistinct(field1, field2) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(field1, field2, field3).as(subselect))
  .selectDistinct(field1, field2, field3) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);: Create a new DSL select statement. This is the
  same as selectDistinct(SelectFieldOrAsterisk...), except that it declares additional record-level
  typesafety, which is needed by Row3.in(Select), Row3.equal(Select) and other predicate building
  methods taking subselect arguments. This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectDistinct(SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(field1,
  field2, field3).as(subselect)) .selectDistinct(field1, field2, field3) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(field1, field2, field3,
  field4).as(subselect)) .selectDistinct(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row4.in(Select),
  Row4.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField) instead.
  Example: using(configuration) .with(name("t").fields(field1, field2, field3,
  field4).as(subselect)) .selectDistinct(field1, field2, field3, field4) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(field1, field2, field3, field4,
  field5).as(subselect)) .selectDistinct(field1, field2, field3, field4, field5) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row5.in(Select),
  Row5.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(field1, field2, field3,
  field4, field5).as(subselect)) .selectDistinct(field1, field2, field3, field4, field5)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f5, f6).as(subselect))
  .selectDistinct(field1, field2, field3, .., field5, field6) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row6.in(Select),
  Row6.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f5, f6).as(subselect)) .selectDistinct(field1, field2, field3, .., field5, field6)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f6, f7).as(subselect))
  .selectDistinct(field1, field2, field3, .., field6, field7) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row7.in(Select),
  Row7.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f6, f7).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field6, field7) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f7, f8).as(subselect))
  .selectDistinct(field1, field2, field3, .., field7, field8) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row8.in(Select),
  Row8.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f7, f8).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field7, field8) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f8, f9).as(subselect))
  .selectDistinct(field1, field2, field3, .., field8, field9) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row9.in(Select),
  Row9.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f8, f9).as(subselect))
  .selectDistinct(field1, field2, field3, .., field8, field9) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f9, f10).as(subselect))
  .selectDistinct(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row10.in(Select),
  Row10.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f9, f10).as(subselect))
  .selectDistinct(field1, field2, field3, .., field9, field10) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f10,
  f11).as(subselect)) .selectDistinct(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row11.in(Select),
  Row11.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f10,
  f11).as(subselect)) .selectDistinct(field1, field2, field3, .., field10, field11) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f11,
  f12).as(subselect)) .selectDistinct(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row12.in(Select),
  Row12.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f11,
  f12).as(subselect)) .selectDistinct(field1, field2, field3, .., field11, field12) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f12,
  f13).as(subselect)) .selectDistinct(field1, field2, field3, .., field12, field13) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row13.in(Select),
  Row13.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f12, f13).as(subselect)) .selectDistinct(field1, field2, field3, .., field12, field13)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f13,
  f14).as(subselect)) .selectDistinct(field1, field2, field3, .., field13, field14) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row14.in(Select),
  Row14.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f13, f14).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field13, field14) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f14,
  f15).as(subselect)) .selectDistinct(field1, field2, field3, .., field14, field15) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row15.in(Select),
  Row15.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f14, f15).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field14, field15) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f15,
  f16).as(subselect)) .selectDistinct(field1, field2, field3, .., field15, field16) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row16.in(Select),
  Row16.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f15, f16).as(subselect))
  .selectDistinct(field1, field2, field3, .., field15, field16) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f16,
  f17).as(subselect)) .selectDistinct(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row17.in(Select),
  Row17.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField) instead. Example:
  using(configuration) .with(name("t").fields(f1, f2, f3, .., f16, f17).as(subselect))
  .selectDistinct(field1, field2, field3, .., field16, field17) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f17,
  f18).as(subselect)) .selectDistinct(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row18.in(Select),
  Row18.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField)
  instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f17,
  f18).as(subselect)) .selectDistinct(field1, field2, field3, .., field17, field18) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f18,
  f19).as(subselect)) .selectDistinct(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row19.in(Select),
  Row19.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f18,
  f19).as(subselect)) .selectDistinct(field1, field2, field3, .., field18, field19) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f19,
  f20).as(subselect)) .selectDistinct(field1, field2, field3, .., field19, field20) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row20.in(Select),
  Row20.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField) instead. Example: using(configuration) .with(name("t").fields(f1, f2,
  f3, .., f19, f20).as(subselect)) .selectDistinct(field1, field2, field3, .., field19, field20)
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f20,
  f21).as(subselect)) .selectDistinct(field1, field2, field3, .., field20, field21) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row21.in(Select),
  Row21.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f20, f21).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field20, field21) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectDistinct using(configuration) .with(name("t").fields(f1, f2, f3, .., f21,
  f22).as(subselect)) .selectDistinct(field1, field2, field3, .., field21, field22) .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement. This is the same as selectDistinct(SelectFieldOrAsterisk...), except
  that it declares additional record-level typesafety, which is needed by Row22.in(Select),
  Row22.equal(Select) and other predicate building methods taking subselect arguments. This creates
  an attached, renderable and executable SELECT statement from this DSLContext. If you don't need to
  render or execute this SELECT statement (e.g. because you want to create a subselect), consider
  using the static DSL.selectDistinct(SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField, SelectField, SelectField, SelectField,
  SelectField, SelectField, SelectField, SelectField) instead. Example: using(configuration)
  .with(name("t").fields(f1, f2, f3, .., f21, f22).as(subselect)) .selectDistinct(field1, field2,
  field3, .., field21, field22) .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectZero DSLContext create = DSL.using(configuration); create.selectZero() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for a constant 0 literal. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectZero() instead. Example: DSLContext create = DSL.using(configuration);
  create.selectZero() .from(table1) .join(table2).on(field1.equal(field2))
  .where(field1.greaterThan(100)) .orderBy(field2);
- selectOne DSLContext create = DSL.using(configuration); create.selectOne() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for a constant 1 literal. This creates an attached, renderable and
  executable SELECT statement from this DSLContext. If you don't need to render or execute this
  SELECT statement (e.g. because you want to create a subselect), consider using the static
  DSL.selectOne() instead. Example: DSLContext create = DSL.using(configuration); create.selectOne()
  .from(table1) .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100))
  .orderBy(field2);
- selectCount DSLContext create = DSL.using(configuration); create.selectCount() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);: Create a
  new DSL select statement for COUNT(*). This creates an attached, renderable and executable SELECT
  statement from this DSLContext. If you don't need to render or execute this SELECT statement (e.g.
  because you want to create a subselect), consider using the static DSL.selectCount() instead.
  Example: DSLContext create = DSL.using(configuration); create.selectCount() .from(table1)
  .join(table2).on(field1.equal(field2)) .where(field1.greaterThan(100)) .orderBy(field2);
- insertInto DSLContext create = DSL.using(configuration); create.insertInto(table) .set(field1,
  value1) .set(field2, value2) .newRecord() .set(field1, value3) .set(field2, value4)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. This type of insert may feel more convenient to some users, as it uses the
  UPDATE statement's SET a = b syntax. Example: DSLContext create = DSL.using(configuration);
  create.insertInto(table) .set(field1, value1) .set(field2, value2) .newRecord() .set(field1,
  value3) .set(field2, value4) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();
- insertInto using(configuration) .with(name("t").fields(field1).as(subselect)) .insertInto(table,
  field1) .values(field1) .values(field1) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2,
  value2) .execute();: Create a new DSL insert statement. Example: using(configuration)
  .with(name("t").fields(field1).as(subselect)) .insertInto(table, field1) .values(field1)
  .values(field1) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(field1, field2).as(subselect))
  .insertInto(table, field1, field2) .values(field1, field2) .values(field1, field2)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(field1,
  field2).as(subselect)) .insertInto(table, field1, field2) .values(field1, field2) .values(field1,
  field2) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(field1, field2, field3).as(subselect))
  .insertInto(table, field1, field2, field3) .values(field1, field2, field3) .values(field1, field2,
  field3) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a
  new DSL insert statement. Example: using(configuration) .with(name("t").fields(field1, field2,
  field3).as(subselect)) .insertInto(table, field1, field2, field3) .values(field1, field2, field3)
  .values(field1, field2, field3) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();
- insertInto using(configuration) .with(name("t").fields(field1, field2, field3,
  field4).as(subselect)) .insertInto(table, field1, field2, field3, field4) .values(field1, field2,
  field3, field4) .values(field1, field2, field3, field4) .onDuplicateKeyUpdate() .set(field1,
  value1) .set(field2, value2) .execute();: Create a new DSL insert statement. Example:
  using(configuration) .with(name("t").fields(field1, field2, field3, field4).as(subselect))
  .insertInto(table, field1, field2, field3, field4) .values(field1, field2, field3, field4)
  .values(field1, field2, field3, field4) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2,
  value2) .execute();
- insertInto using(configuration) .with(name("t").fields(field1, field2, field3, field4,
  field5).as(subselect)) .insertInto(table, field1, field2, field3, field4, field5) .values(field1,
  field2, field3, field4, field5) .values(field1, field2, field3, field4, field5)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(field1, field2, field3,
  field4, field5).as(subselect)) .insertInto(table, field1, field2, field3, field4, field5)
  .values(field1, field2, field3, field4, field5) .values(field1, field2, field3, field4, field5)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f5, f6).as(subselect))
  .insertInto(table, field1, field2, field3, .., field5, field6) .values(valueA1, valueA2, valueA3,
  .., valueA5, valueA6) .values(valueB1, valueB2, valueB3, .., valueB5, valueB6)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f5,
  f6).as(subselect)) .insertInto(table, field1, field2, field3, .., field5, field6) .values(valueA1,
  valueA2, valueA3, .., valueA5, valueA6) .values(valueB1, valueB2, valueB3, .., valueB5, valueB6)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f6, f7).as(subselect))
  .insertInto(table, field1, field2, field3, .., field6, field7) .values(valueA1, valueA2, valueA3,
  .., valueA6, valueA7) .values(valueB1, valueB2, valueB3, .., valueB6, valueB7)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f6,
  f7).as(subselect)) .insertInto(table, field1, field2, field3, .., field6, field7) .values(valueA1,
  valueA2, valueA3, .., valueA6, valueA7) .values(valueB1, valueB2, valueB3, .., valueB6, valueB7)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f7, f8).as(subselect))
  .insertInto(table, field1, field2, field3, .., field7, field8) .values(valueA1, valueA2, valueA3,
  .., valueA7, valueA8) .values(valueB1, valueB2, valueB3, .., valueB7, valueB8)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f7,
  f8).as(subselect)) .insertInto(table, field1, field2, field3, .., field7, field8) .values(valueA1,
  valueA2, valueA3, .., valueA7, valueA8) .values(valueB1, valueB2, valueB3, .., valueB7, valueB8)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f8, f9).as(subselect))
  .insertInto(table, field1, field2, field3, .., field8, field9) .values(valueA1, valueA2, valueA3,
  .., valueA8, valueA9) .values(valueB1, valueB2, valueB3, .., valueB8, valueB9)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f8,
  f9).as(subselect)) .insertInto(table, field1, field2, field3, .., field8, field9) .values(valueA1,
  valueA2, valueA3, .., valueA8, valueA9) .values(valueB1, valueB2, valueB3, .., valueB8, valueB9)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f9, f10).as(subselect))
  .insertInto(table, field1, field2, field3, .., field9, field10) .values(valueA1, valueA2, valueA3,
  .., valueA9, valueA10) .values(valueB1, valueB2, valueB3, .., valueB9, valueB10)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f9,
  f10).as(subselect)) .insertInto(table, field1, field2, field3, .., field9, field10)
  .values(valueA1, valueA2, valueA3, .., valueA9, valueA10) .values(valueB1, valueB2, valueB3, ..,
  valueB9, valueB10) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f10, f11).as(subselect))
  .insertInto(table, field1, field2, field3, .., field10, field11) .values(valueA1, valueA2,
  valueA3, .., valueA10, valueA11) .values(valueB1, valueB2, valueB3, .., valueB10, valueB11)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f10,
  f11).as(subselect)) .insertInto(table, field1, field2, field3, .., field10, field11)
  .values(valueA1, valueA2, valueA3, .., valueA10, valueA11) .values(valueB1, valueB2, valueB3, ..,
  valueB10, valueB11) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f11, f12).as(subselect))
  .insertInto(table, field1, field2, field3, .., field11, field12) .values(valueA1, valueA2,
  valueA3, .., valueA11, valueA12) .values(valueB1, valueB2, valueB3, .., valueB11, valueB12)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f11,
  f12).as(subselect)) .insertInto(table, field1, field2, field3, .., field11, field12)
  .values(valueA1, valueA2, valueA3, .., valueA11, valueA12) .values(valueB1, valueB2, valueB3, ..,
  valueB11, valueB12) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f12, f13).as(subselect))
  .insertInto(table, field1, field2, field3, .., field12, field13) .values(valueA1, valueA2,
  valueA3, .., valueA12, valueA13) .values(valueB1, valueB2, valueB3, .., valueB12, valueB13)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f12,
  f13).as(subselect)) .insertInto(table, field1, field2, field3, .., field12, field13)
  .values(valueA1, valueA2, valueA3, .., valueA12, valueA13) .values(valueB1, valueB2, valueB3, ..,
  valueB12, valueB13) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f13, f14).as(subselect))
  .insertInto(table, field1, field2, field3, .., field13, field14) .values(valueA1, valueA2,
  valueA3, .., valueA13, valueA14) .values(valueB1, valueB2, valueB3, .., valueB13, valueB14)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f13,
  f14).as(subselect)) .insertInto(table, field1, field2, field3, .., field13, field14)
  .values(valueA1, valueA2, valueA3, .., valueA13, valueA14) .values(valueB1, valueB2, valueB3, ..,
  valueB13, valueB14) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f14, f15).as(subselect))
  .insertInto(table, field1, field2, field3, .., field14, field15) .values(valueA1, valueA2,
  valueA3, .., valueA14, valueA15) .values(valueB1, valueB2, valueB3, .., valueB14, valueB15)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f14,
  f15).as(subselect)) .insertInto(table, field1, field2, field3, .., field14, field15)
  .values(valueA1, valueA2, valueA3, .., valueA14, valueA15) .values(valueB1, valueB2, valueB3, ..,
  valueB14, valueB15) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f15, f16).as(subselect))
  .insertInto(table, field1, field2, field3, .., field15, field16) .values(valueA1, valueA2,
  valueA3, .., valueA15, valueA16) .values(valueB1, valueB2, valueB3, .., valueB15, valueB16)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f15,
  f16).as(subselect)) .insertInto(table, field1, field2, field3, .., field15, field16)
  .values(valueA1, valueA2, valueA3, .., valueA15, valueA16) .values(valueB1, valueB2, valueB3, ..,
  valueB15, valueB16) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f16, f17).as(subselect))
  .insertInto(table, field1, field2, field3, .., field16, field17) .values(valueA1, valueA2,
  valueA3, .., valueA16, valueA17) .values(valueB1, valueB2, valueB3, .., valueB16, valueB17)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f16,
  f17).as(subselect)) .insertInto(table, field1, field2, field3, .., field16, field17)
  .values(valueA1, valueA2, valueA3, .., valueA16, valueA17) .values(valueB1, valueB2, valueB3, ..,
  valueB16, valueB17) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f17, f18).as(subselect))
  .insertInto(table, field1, field2, field3, .., field17, field18) .values(valueA1, valueA2,
  valueA3, .., valueA17, valueA18) .values(valueB1, valueB2, valueB3, .., valueB17, valueB18)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f17,
  f18).as(subselect)) .insertInto(table, field1, field2, field3, .., field17, field18)
  .values(valueA1, valueA2, valueA3, .., valueA17, valueA18) .values(valueB1, valueB2, valueB3, ..,
  valueB17, valueB18) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f18, f19).as(subselect))
  .insertInto(table, field1, field2, field3, .., field18, field19) .values(valueA1, valueA2,
  valueA3, .., valueA18, valueA19) .values(valueB1, valueB2, valueB3, .., valueB18, valueB19)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f18,
  f19).as(subselect)) .insertInto(table, field1, field2, field3, .., field18, field19)
  .values(valueA1, valueA2, valueA3, .., valueA18, valueA19) .values(valueB1, valueB2, valueB3, ..,
  valueB18, valueB19) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f19, f20).as(subselect))
  .insertInto(table, field1, field2, field3, .., field19, field20) .values(valueA1, valueA2,
  valueA3, .., valueA19, valueA20) .values(valueB1, valueB2, valueB3, .., valueB19, valueB20)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f19,
  f20).as(subselect)) .insertInto(table, field1, field2, field3, .., field19, field20)
  .values(valueA1, valueA2, valueA3, .., valueA19, valueA20) .values(valueB1, valueB2, valueB3, ..,
  valueB19, valueB20) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f20, f21).as(subselect))
  .insertInto(table, field1, field2, field3, .., field20, field21) .values(valueA1, valueA2,
  valueA3, .., valueA20, valueA21) .values(valueB1, valueB2, valueB3, .., valueB20, valueB21)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f20,
  f21).as(subselect)) .insertInto(table, field1, field2, field3, .., field20, field21)
  .values(valueA1, valueA2, valueA3, .., valueA20, valueA21) .values(valueB1, valueB2, valueB3, ..,
  valueB20, valueB21) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto using(configuration) .with(name("t").fields(f1, f2, f3, .., f21, f22).as(subselect))
  .insertInto(table, field1, field2, field3, .., field21, field22) .values(valueA1, valueA2,
  valueA3, .., valueA21, valueA22) .values(valueB1, valueB2, valueB3, .., valueB21, valueB22)
  .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();: Create a new DSL
  insert statement. Example: using(configuration) .with(name("t").fields(f1, f2, f3, .., f21,
  f22).as(subselect)) .insertInto(table, field1, field2, field3, .., field21, field22)
  .values(valueA1, valueA2, valueA3, .., valueA21, valueA22) .values(valueB1, valueB2, valueB3, ..,
  valueB21, valueB22) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2) .execute();
- insertInto DSLContext create = DSL.using(configuration); create.insertInto(table, field1, field2)
  .values(value1, value2) .values(value3, value4) .onDuplicateKeyUpdate() .set(field1, value1)
  .set(field2, value2) .execute();: Create a new DSL insert statement. Example: DSLContext create =
  DSL.using(configuration); create.insertInto(table, field1, field2) .values(value1, value2)
  .values(value3, value4) .onDuplicateKeyUpdate() .set(field1, value1) .set(field2, value2)
  .execute();
- update DSLContext create = DSL.using(configuration); create.update(table) .set(field1, value1)
  .set(field2, value2) .where(field1.greaterThan(100)) .execute();: Create a new DSL update
  statement. Example: DSLContext create = DSL.using(configuration); create.update(table)
  .set(field1, value1) .set(field2, value2) .where(field1.greaterThan(100)) .execute(); Note that
  some databases support table expressions more complex than simple table references. In MySQL, for
  instance, you can write create.update(t1.join(t2).on(t1.id.eq(t2.id))) .set(t1.value, value1)
  .set(t2.value, value2) .where(t1.id.eq(10)) .execute();
- mergeInto DSLContext create = DSL.using(configuration); create.mergeInto(table) .using(select)
  .on(condition) .whenMatchedThenUpdate() .set(field1, value1) .set(field2, value2)
  .whenNotMatchedThenInsert(field1, field2) .values(value1, value2) .execute();: Create a new DSL
  SQL standard MERGE statement. This statement is available from DSL syntax only. It is known to be
  supported in some way by any of these dialects: dialect support type documentation DB2 SQL:2008
  standard and major enhancements
  http://publib.boulder.ibm.com/infocenter/db2luw/v9/index.jsp?topic=/com.
  ibm.db2.udb.admin.doc/doc/r0010873.htm HSQLDB SQL:2008 standard
  http://hsqldb.org/doc/2.0/guide/dataaccess-chapt.html#N129BA Oracle SQL:2008 standard and minor
  enhancements http://download.oracle.com/docs/cd/B28359_01/server.111/b28286/ statements_9016.htm
  SQL Server Similar to SQL:2008 standard with some major enhancements http://msdn.microsoft.com/de-
  de/library/bb510625.aspx Sybase Similar to SQL:2008 standard with some major enhancements
  http://dcx.sybase.com/1100/en/dbreference_en11/merge-statement.html Example: DSLContext create =
  DSL.using(configuration); create.mergeInto(table) .using(select) .on(condition)
  .whenMatchedThenUpdate() .set(field1, value1) .set(field2, value2)
  .whenNotMatchedThenInsert(field1, field2) .values(value1, value2) .execute();
- mergeInto: Create a new DSL merge statement (H2-specific syntax). This statement is available from
  DSL syntax only. It is known to be supported in some way by any of these dialects: H2 H2 natively
  supports this special syntax https://www.h2database.com/html/commands.html#merge_into DB2, HSQLDB,
  Oracle, SQL Server, Sybase SQL Anywhere These databases can emulate the H2-specific MERGE
  statement using a standard SQL MERGE statement, without restrictions See mergeInto(Table) for the
  standard MERGE statement
- delete DSLContext create = DSL.using(configuration); create.delete(table)
  .where(field1.greaterThan(100)) .execute();: Create a new DSL delete statement. Example:
  DSLContext create = DSL.using(configuration); create.delete(table) .where(field1.greaterThan(100))
  .execute(); Some but not all databases support aliased tables in delete statements.

XML (class, org.jooq)
An XML wrapper type for XML data obtained from the database. The wrapper represents XML data() in
serialised string form. A CAST(NULL AS XML) value is represented by a null reference of type XML,
not as data() == null. This is consistent with jOOQ's general way of returning NULL from Result and
Record methods.
Methods:
- data: Beschreibung aus Schnittstelle kopiert: Data
- valueOf: Create a new XML instance from string data input.
- xml: Create a new XML instance from string data input. This is the same as valueOf(String), but it
  can be static imported.
- xmlOrNull: Create a new XML instance from string data input, or null if the input is null.
- hashCode:
- equals:
- toString:

XMLFormat (class, org.jooq)
An XML formatting type, which can be used to configure XML imports / exports. The type is immutable,
meaning calls to setters like header(boolean) do not modify the original reference, but return a new
one instead.
Methods:
- DEFAULT_FOR_RESULTS:
- DEFAULT_FOR_RECORDS:
- XMLFormat:
- mutable: Whether this configuration object is mutable.
- xmlns: The new value for the xmlns flag, defaulting to true.
- format: The new value for the formatting flag, defaulting to false.
- newline: The new newline character, defaulting to \n.
- globalIndent: The new global indentation size applied on all levels, defaulting to 0.
- indent: The new indentation size per level value, defaulting to 2.
- indentString: Convenience method to get an indentation string at a given level.
- header: The new header value, defaulting to true. This flag governs whether the /result/fields
  element should be generated on export. This flag is ignored on Formattable.formatXML(XMLFormat)
  and similar methods.
- recordFormat: The record format to be applied, defaulting to
  XMLFormat.RecordFormat.VALUE_ELEMENTS_WITH_FIELD_ATTRIBUTE.
- quoteNested: Whether nested XML content should be quoted like a string, or nested into XML
  formatted output.

ExecuteWithoutWhere (enum, org.jooq.conf)
Java class for ExecuteWithoutWhere. The following schema fragment specifies the expected content
contained within this class. <simpleType name="ExecuteWithoutWhere"> <restriction
base="{http://www.w3.org/2001/XMLSchema}string"> <enumeration value="IGNORE"/> <enumeration
value="LOG_DEBUG"/> <enumeration value="LOG_INFO"/> <enumeration value="LOG_WARN"/> <enumeration
value="THROW"/> </restriction> </simpleType>
Methods:
- IGNORE: UPDATE and DELETE statements are allowed to lack a WHERE clause
- LOG_DEBUG: UPDATE and DELETE statements are allowed to lack a WHERE clause, but this is logged as
  DEBUG level
- LOG_INFO: UPDATE and DELETE statements are allowed to lack a WHERE clause, but this is logged as
  INFO level
- LOG_WARN: UPDATE and DELETE statements are allowed to lack a WHERE clause, but this is logged as
  WARN level
- THROW: UPDATE and DELETE statements are not allowed to lack a WHERE clause
- values: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge ihrer Deklaration
  zurück.
- valueOf: Gibt die Enum-Konstante dieser Klasse mit dem angegebenen Namen zurück. Die Zeichenfolge
  muss exakt mit einer ID übereinstimmen, mit der eine Enum-Konstante in dieser Klasse deklariert
  wird. (Zusätzliche Leerzeichen sind nicht zulässig.)
- value:
- fromValue:

ExecuteWithoutWhere (enum, org.jooq.conf)
[#6771] Specifies whether DELETE statements are allowed to be executed lacking a WHERE clause.

RenderFormatting (class, org.jooq.conf)
All sorts of formatting flags / settings.
Methods:
- newline:
- indentation:
- printMargin:
- RenderFormatting:
- getNewline: The character to be used for line breaks.
- setNewline: The character to be used for line breaks.
- getIndentation: The characters to be used for indentation.
- setIndentation: The characters to be used for indentation.
- getPrintMargin: The print margin after which (some) formatted elements will break lines.
- setPrintMargin: The print margin after which (some) formatted elements will break lines.
- withNewline: The character to be used for line breaks.
- withIndentation: The characters to be used for indentation.
- withPrintMargin: The print margin after which (some) formatted elements will break lines.
- appendTo:
- toString:
- equals:
- hashCode:
- clone:

RenderFormatting (class, org.jooq.conf)
Create an instance of RenderFormatting

RenderKeywordCase (enum, org.jooq.conf)
Java class for RenderKeywordCase. The following schema fragment specifies the expected content
contained within this class. <simpleType name="RenderKeywordCase"> <restriction
base="{http://www.w3.org/2001/XMLSchema}string"> <enumeration value="AS_IS"/> <enumeration
value="LOWER"/> <enumeration value="UPPER"/> <enumeration value="PASCAL"/> </restriction>
</simpleType>
Methods:
- AS_IS: Keywords are rendered "as is", i.e. mostly in lower case. For instance: select .. from ..
  where ..
- LOWER: Keywords are rendered in lower case. For instance: select .. from .. where ..
- UPPER: Keywords are rendered in upper case. For instance: SELECT .. FROM .. WHERE ..
- PASCAL: Keywords are rendered in Pascal Case. For instance: Select .. From .. Where ..
- values: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge ihrer Deklaration
  zurück.
- valueOf: Gibt die Enum-Konstante dieser Klasse mit dem angegebenen Namen zurück. Die Zeichenfolge
  muss exakt mit einer ID übereinstimmen, mit der eine Enum-Konstante in dieser Klasse deklariert
  wird. (Zusätzliche Leerzeichen sind nicht zulässig.)
- value:
- fromValue:

RenderKeywordCase (enum, org.jooq.conf)
Whether the case of Keyword references should be modified in any way.

RenderNameCase (enum, org.jooq.conf)
Java class for RenderNameCase. The following schema fragment specifies the expected content
contained within this class. <simpleType name="RenderNameCase"> <restriction
base="{http://www.w3.org/2001/XMLSchema}string"> <enumeration value="AS_IS"/> <enumeration
value="LOWER"/> <enumeration value="LOWER_IF_UNQUOTED"/> <enumeration value="UPPER"/> <enumeration
value="UPPER_IF_UNQUOTED"/> </restriction> </simpleType>
Methods:
- AS_IS: Render object names, as defined in the database. For instance: schema.TABLE
- LOWER: Force rendering object names in lower case. For instance: schema."table"
- LOWER_IF_UNQUOTED: Force rendering object names in lower case, if unquoted. For instance
  schema."TABLE"
- UPPER: Force rendering object names in upper case. For instance: SCHEMA."TABLE"
- UPPER_IF_UNQUOTED: Force rendering object names in upper case, if unquoted. For instance
  SCHEMA."table"
- values: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge ihrer Deklaration
  zurück.
- valueOf: Gibt die Enum-Konstante dieser Klasse mit dem angegebenen Namen zurück. Die Zeichenfolge
  muss exakt mit einer ID übereinstimmen, mit der eine Enum-Konstante in dieser Klasse deklariert
  wird. (Zusätzliche Leerzeichen sind nicht zulässig.)
- value:
- fromValue:

RenderNameCase (enum, org.jooq.conf)
Whether the case of Name references should be modified in any way.

Settings (class, org.jooq.conf)
Settings that influence the way jOOQ renders SQL code.
Methods:
- forceIntegerTypesOnZeroScaleDecimals:
- renderCatalog:
- renderSchema:
- renderTable:
- renderMapping:
- renderQuotedNames:
- renderNameCase:
- renderNameStyle:
- renderNamedParamPrefix:
- renderKeywordCase:
- renderKeywordStyle:
- renderLocale:
- renderFormatted:
- renderFormatting:
- renderNullifEmptyStringForBindValues:
- renderAutoAliasedDerivedTableExpressions:
- renderOptionalAssociativityParentheses:
- renderOptionalAsKeywordForTableAliases:
- renderOptionalAsKeywordForFieldAliases:
- renderOptionalInnerKeyword:
- renderOptionalOuterKeyword:
- renderImplicitWindowRange:
- renderScalarSubqueriesForStoredFunctions:
- renderImplicitJoinType:
- renderImplicitJoinToManyType:
- renderDefaultNullability:
- renderCoalesceToEmptyStringInConcat:
- renderOrderByRownumberForEmulatedPagination:
- renderOutputForSQLServerReturningClause:
- renderGroupConcatMaxLenSessionVariable:
- renderParenthesisAroundSetOperationQueries:
- renderVariablesInDerivedTablesForEmulations:
- renderRowConditionForSeekClause:
- renderRedundantConditionForSeekClause:
- renderPlainSQLTemplatesAsRaw:
- renderDollarQuotedStringToken:
- namePathSeparator:
- bindOffsetDateTimeType:
- bindOffsetTimeType:
- fetchTrimmedCharValues:
- fetchTriggerValuesAfterSQLServerOutput:
- fetchTriggerValuesAfterReturning:
- fetchIntermediateResult:
- diagnosticsDuplicateStatements:
- diagnosticsDuplicateStatementsUsingTransformPatterns:
- diagnosticsMissingWasNullCall:
- diagnosticsRepeatedStatements:
- diagnosticsConsecutiveAggregation:
- diagnosticsConcatenationInPredicate:
- diagnosticsPossiblyWrongExpression:
- diagnosticsTooManyColumnsFetched:
- diagnosticsTooManyRowsFetched:
- diagnosticsUnnecessaryWasNullCall:
- diagnosticsPatterns:
- diagnosticsTrivialCondition:
- diagnosticsNullCondition:
- transformPatterns:
- transformPatternsLogging:
- transformPatternsUnnecessaryDistinct:
- transformPatternsUnnecessaryScalarSubquery:
- transformPatternsUnnecessaryInnerJoin:
- transformPatternsUnnecessaryGroupByExpressions:
- transformPatternsUnnecessaryOrderByExpressions:
- transformPatternsUnnecessaryExistsSubqueryClauses:
- transformPatternsCountConstant:
- transformPatternsTrim:
- transformPatternsNotAnd:
- transformPatternsNotOr:
- transformPatternsNotNot:
- transformPatternsNotComparison:
- transformPatternsNotNotDistinct:
- transformPatternsDistinctFromNull:
- transformPatternsNormaliseAssociativeOps:
- transformPatternsNormaliseInListSingleElementToComparison:
- transformPatternsNormaliseFieldCompareValue:
- transformPatternsNormaliseCoalesceToNvl:
- transformPatternsOrEqToIn:
- transformPatternsAndNeToNotIn:
- transformPatternsMergeOrComparison:
- transformPatternsMergeAndComparison:
- transformPatternsMergeInLists:
- transformPatternsMergeRangePredicates:
- transformPatternsMergeBetweenSymmetricPredicates:
- transformPatternsCaseSearchedToCaseSimple:
- transformPatternsCaseElseNull:
- transformPatternsUnreachableCaseClauses:
- transformPatternsUnreachableDecodeClauses:
- transformPatternsCaseDistinctToDecode:
- transformPatternsCaseMergeWhenWhen:
- transformPatternsCaseMergeWhenElse:
- transformPatternsCaseToCaseAbbreviation:
- transformPatternsSimplifyCaseAbbreviation:
- transformPatternsFlattenCaseAbbreviation:
- transformPatternsFlattenDecode:
- transformPatternsFlattenCase:
- transformPatternsTrivialCaseAbbreviation:
- transformPatternsTrivialPredicates:
- transformPatternsTrivialBitwiseOperations:
- transformPatternsBitSet:
- transformPatternsBitGet:
- transformPatternsScalarSubqueryCountAsteriskGtZero:
- transformPatternsScalarSubqueryCountExpressionGtZero:
- transformPatternsEmptyScalarSubquery:
- transformPatternsNegNeg:
- transformPatternsBitNotBitNot:
- transformPatternsBitNotBitNand:
- transformPatternsBitNotBitNor:
- transformPatternsBitNotBitXNor:
- transformPatternsNullOnNullInput:
- transformPatternsIdempotentFunctionRepetition:
- transformPatternsArithmeticComparisons:
- transformPatternsArithmeticExpressions:
- transformPatternsTrigonometricFunctions:
- transformPatternsLogarithmicFunctions:
- transformPatternsHyperbolicFunctions:
- transformPatternsInverseHyperbolicFunctions:
- transformInlineBindValuesForFieldComparisons:
- transformAnsiJoinToTableLists:
- transformInConditionSubqueryWithLimitToDerivedTable:
- transformQualify:
- transformTableListsToAnsiJoin:
- transformRownum:
- transformUnneededArithmeticExpressions:
- transformGroupByColumnIndex:
- transformInlineCTE:
- backslashEscaping:
- paramType:
- paramCastMode:
- statementType:
- inlineThreshold:
- transactionListenerStartInvocationOrder:
- transactionListenerEndInvocationOrder:
- migrationListenerStartInvocationOrder:
- migrationListenerEndInvocationOrder:
- visitListenerStartInvocationOrder:
- visitListenerEndInvocationOrder:
- recordListenerStartInvocationOrder:
- recordListenerEndInvocationOrder:
- executeListenerStartInvocationOrder:
- executeListenerEndInvocationOrder:
- executeLogging:
- executeLoggingSQLExceptions:
- diagnosticsLogging:
- diagnosticsConnection:
- updateRecordVersion:
- updateRecordTimestamp:
- executeWithOptimisticLocking:
- executeWithOptimisticLockingExcludeUnversioned:
- attachRecords:
- insertUnchangedRecords:
- updateUnchangedRecords:
- recordDirtyTracking:
- updatablePrimaryKeys:
- reflectionCaching:
- cacheRecordMappers:
- cacheParsingConnection:
- cacheParsingConnectionLRUCacheSize:
- cacheRecordMappersLRUCacheSize:
- reflectionCacheLRUCacheSize:
- cachePreparedStatementInLoader:
- throwExceptions:
- fetchWarnings:
- fetchServerOutputSize:
- returnIdentityOnUpdatableRecord:
- returnDefaultOnUpdatableRecord:
- returnComputedOnUpdatableRecord:
- returnAllOnUpdatableRecord:
- returnRecordToPojo:
- mapJPAAnnotations:
- mapRecordComponentParameterNames:
- mapConstructorPropertiesParameterNames:
- mapConstructorParameterNames:
- mapConstructorParameterNamesInKotlin:
- queryPoolable:
- queryTimeout:
- maxRows:
- fetchSize:
- batchSize:
- debugInfoOnStackTrace:
- inListPadding:
- inListPadBase:
- delimiter:
- emulateOnDuplicateKeyUpdateOnPrimaryKeyOnly:
- emulateMultiset:
- emulateNestedRecordProjectionsUsingMultisetEmulation:
- emulateComputedColumns:
- computedOnClientVirtual:
- computedOnClientStored:
- executeUpdateWithoutWhere:
- executeDeleteWithoutWhere:
- interpreterDialect:
- interpreterNameLookupCaseSensitivity:
- interpreterLocale:
- interpreterDelayForeignKeyDeclarations:
- metaIncludeSystemIndexes:
- metaIncludeSystemSequences:
- migrationHistorySchema:
- migrationHistorySchemaCreateSchemaIfNotExists:
- migrationDefaultSchema:
- migrationSchemataCreateSchemaIfNotExists:
- migrationDefaultContentType:
- migrationAllowUndo:
- migrationAllowInvalidCommits:
- migrationRevertUntracked:
- migrationAutoBaseline:
- migrationAutoVerification:
- migrationIgnoreDefaultTimestampPrecisionDiffs:
- migrationIgnoreUnnamedConstraintDiffs:
- migrationIgnoreImplicitPrimaryKeyNotNullConstraints:
- locale:
- parseDialect:
- parseLocale:
- parseDateFormat:
- parseTimestampFormat:
- parseNamedParamPrefix:
- parseNameCase:
- parseWithMetaLookups:
- parseAppendMissingTableReferences:
- parseSetCommands:
- parseUnsupportedSyntax:
- parseUnknownFunctions:
- parseIgnoreCommercialOnlyFeatures:
- parseIgnoreComments:
- parseIgnoreCommentStart:
- parseIgnoreCommentStop:
- parseRetainCommentsBetweenQueries:
- parseMetaDefaultExpressions:
- parseMetaViewSources:
- readonlyTableRecordInsert:
- readonlyUpdatableRecordUpdate:
- readonlyInsert:
- readonlyUpdate:
- applyWorkaroundFor7962:
- warnOnStaticTypeRegistryAccess:
- interpreterSearchPath:
- migrationSchemata:
- parseSearchPath:
- Settings:
- isForceIntegerTypesOnZeroScaleDecimals Name: Historically, zero-scale decimal types are generated
  as their most appropriate, corresponding integer type (e.g. NUMBER(2, 0) and less: Byte). The same
  behaviour is replicated in the Meta API. This flag allows for turning off this feature.
- isForceIntegerTypesOnZeroScaleDecimals: Historically, zero-scale decimal types are generated as
  their most appropriate, corresponding integer type (e.g. NUMBER(2, 0) and less: Byte). The same
  behaviour is replicated in the Meta API. This flag allows for turning off this feature.
- setForceIntegerTypesOnZeroScaleDecimals: Historically, zero-scale decimal types are generated as
  their most appropriate, corresponding integer type (e.g. NUMBER(2, 0) and less: Byte). The same
  behaviour is replicated in the Meta API. This flag allows for turning off this feature.
- isRenderCatalog: Whether any catalog name should be rendered at all. Use this for single-catalog
  environments, or when all objects are made available using synonyms
- setRenderCatalog: Whether any catalog name should be rendered at all. Use this for single-catalog
  environments, or when all objects are made available using synonyms
- isRenderSchema: Whether any schema name should be rendered at all. Setting this to false also
  implicitly sets "renderCatalog" to false. Use this for single-schema environments, or when all
  objects are made available using synonyms
- setRenderSchema: Whether any schema name should be rendered at all. Setting this to false also
  implicitly sets "renderCatalog" to false. Use this for single-schema environments, or when all
  objects are made available using synonyms
- getRenderTable: Whether any table name qualification should be rendered at all on columns. Setting
  when tables aren't rendered, then implicitly, schemas and catalogs aren't rendered either. The
  following values are available: RenderTable.ALWAYS: The default, which should always be preferred.
  Columns are always qualified with their tables, where possible. RenderTable.WHEN_MULTIPLE_TABLES:
  The simplest option to reduce generated query verbosity, avoiding table qualification only in
  queries with a single table in the FROM clause. RenderTable.WHEN_AMBIGUOUS_COLUMNS: A much more
  expensive to compute option that checks the FROM clause for ambiguous column names, in case of
  which columns are qualified. RenderTable.NEVER: Always turn off table qualification. Use this when
  verbosity of rendered SQL is a problem.
- setRenderTable: Whether any table name qualification should be rendered at all on columns. Setting
  when tables aren't rendered, then implicitly, schemas and catalogs aren't rendered either. The
  following values are available: RenderTable.ALWAYS: The default, which should always be preferred.
  Columns are always qualified with their tables, where possible. RenderTable.WHEN_MULTIPLE_TABLES:
  The simplest option to reduce generated query verbosity, avoiding table qualification only in
  queries with a single table in the FROM clause. RenderTable.WHEN_AMBIGUOUS_COLUMNS: A much more
  expensive to compute option that checks the FROM clause for ambiguous column names, in case of
  which columns are qualified. RenderTable.NEVER: Always turn off table qualification. Use this when
  verbosity of rendered SQL is a problem.
- getRenderMapping: Configure render mapping for runtime schema / table rewriting in generated SQL.
- setRenderMapping: Configure render mapping for runtime schema / table rewriting in generated SQL.
- getRenderQuotedNames: Whether rendered schema, table, column names, etc should be quoted. This
  only affects names created through DSL.name(String) methods (including those that are implicitly
  created through this method), not DSL.quotedName(String) or DSL.unquotedName(String), whose
  behaviour cannot be overridden. This setting does not affect any plain SQL usage.
- setRenderQuotedNames: Whether rendered schema, table, column names, etc should be quoted. This
  only affects names created through DSL.name(String) methods (including those that are implicitly
  created through this method), not DSL.quotedName(String) or DSL.unquotedName(String), whose
  behaviour cannot be overridden. This setting does not affect any plain SQL usage.
- getRenderNameCase: Whether the case of Name references should be modified in any way. Names are
  modified irrespective of the getRenderQuotedNames() setting. This setting does not affect any
  plain SQL usage.
- setRenderNameCase: Whether the case of Name references should be modified in any way. Names are
  modified irrespective of the getRenderQuotedNames() setting. This setting does not affect any
  plain SQL usage.
- getRenderNameStyle: Whether rendered schema, table, column names, etc should be quoted in rendered
  SQL, or transformed in any other way. This is set to "QUOTED" by default for backwards-
  compatibility.
- setRenderNameStyle: Whether rendered schema, table, column names, etc should be quoted in rendered
  SQL, or transformed in any other way. This is set to "QUOTED" by default for backwards-
  compatibility.
- getRenderNamedParamPrefix: The prefix to use for named parameters in generated SQL. Named
  parameter syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name, when generating SQL.
  "Named indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- setRenderNamedParamPrefix: The prefix to use for named parameters in generated SQL. Named
  parameter syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name, when generating SQL.
  "Named indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- getRenderKeywordCase: Whether the case of Keyword references should be modified in any way.
- setRenderKeywordCase: Whether the case of Keyword references should be modified in any way.
- getRenderKeywordStyle: Whether the case of Keyword references should be modified in any way.
- setRenderKeywordStyle: Whether the case of Keyword references should be modified in any way.
- getRenderLocale: The Locale to be used with any render locale dependent logic (as e.g.
  transforming names to lower / uppper case), defaulting to getLocale().
- setRenderLocale: The Locale to be used with any render locale dependent logic (as e.g.
  transforming names to lower / uppper case), defaulting to getLocale().
- isRenderFormatted: Whether rendered SQL should be pretty-printed.
- setRenderFormatted: Whether rendered SQL should be pretty-printed.
- getRenderFormatting: All sorts of formatting flags / settings.
- setRenderFormatting: All sorts of formatting flags / settings.
- isRenderNullifEmptyStringForBindValues: Whether to wrap String typed bind values with NULLIF(?,
  '') for Oracle compatibility. This feature is available in the commercial distribution only.
- setRenderNullifEmptyStringForBindValues: Whether to wrap String typed bind values with NULLIF(?,
  '') for Oracle compatibility. This feature is available in the commercial distribution only.
- getRenderAutoAliasedDerivedTableExpressions: Whether to auto-alias expressions in derived tables.
  This feature is available in the commercial distribution only.
- setRenderAutoAliasedDerivedTableExpressions: Whether to auto-alias expressions in derived tables.
  This feature is available in the commercial distribution only.
- getRenderOptionalAssociativityParentheses: Whether to render optional parentheses to make
  associativity explicit, e.g. ((a + b) + c) instead of (a + b + c).
- setRenderOptionalAssociativityParentheses: Whether to render optional parentheses to make
  associativity explicit, e.g. ((a + b) + c) instead of (a + b + c).
- getRenderOptionalAsKeywordForTableAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect. This is ignored if the keyword is not supported
  (e.g. in Oracle)
- setRenderOptionalAsKeywordForTableAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect. This is ignored if the keyword is not supported
  (e.g. in Oracle)
- getRenderOptionalAsKeywordForFieldAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect.
- setRenderOptionalAsKeywordForFieldAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect.
- getRenderOptionalInnerKeyword: Whether to render the optional INNER keyword in INNER JOIN, if it
  is optional in the output dialect.
- setRenderOptionalInnerKeyword: Whether to render the optional INNER keyword in INNER JOIN, if it
  is optional in the output dialect.
- getRenderOptionalOuterKeyword: Whether to render the optional OUTER keyword in OUTER JOIN, if it
  is optional in the output dialect.
- setRenderOptionalOuterKeyword: Whether to render the optional OUTER keyword in OUTER JOIN, if it
  is optional in the output dialect.
- getRenderImplicitWindowRange: Whether to render an explicit window RANGE clause when an implicit
  clause is applied.
- setRenderImplicitWindowRange: Whether to render an explicit window RANGE clause when an implicit
  clause is applied.
- isRenderScalarSubqueriesForStoredFunctions: Whether stored function calls should be wrapped in
  scalar subqueries. Oracle 11g (and potentially, other databases too) implements scalar subquery
  caching. With this flag set to true, users can automatically profit from this feature in all SQL
  statements.
- setRenderScalarSubqueriesForStoredFunctions: Whether stored function calls should be wrapped in
  scalar subqueries. Oracle 11g (and potentially, other databases too) implements scalar subquery
  caching. With this flag set to true, users can automatically profit from this feature in all SQL
  statements.
- getRenderImplicitJoinType: The join type to be generated by implicit joins for to-one paths in
  Select queries. The DEFAULT is dependent on the nullability of the foreign key (LEFT_JOIN for
  nullable foreign keys and INNER_JOIN for non-nullable foreign keys). In DML statements, it is
  always SCALAR_SUBQUERY, unless DML joins are supported.
- setRenderImplicitJoinType: The join type to be generated by implicit joins for to-one paths in
  Select queries. The DEFAULT is dependent on the nullability of the foreign key (LEFT_JOIN for
  nullable foreign keys and INNER_JOIN for non-nullable foreign keys). In DML statements, it is
  always SCALAR_SUBQUERY, unless DML joins are supported.
- getRenderImplicitJoinToManyType: The join type to be generated by implicit joins for to-many paths
  in Select queries. The DEFAULT is SCALAR_SUBQUERY if the join path is implicit only, i.e. absent
  from the FROM clause, to prevent accidental cartesian products, or LEFT_JOIN if declared
  explicitly in the FROM clause. In DML statements, it is always SCALAR_SUBQUERY, unless DML joins
  are supported.
- setRenderImplicitJoinToManyType: The join type to be generated by implicit joins for to-many paths
  in Select queries. The DEFAULT is SCALAR_SUBQUERY if the join path is implicit only, i.e. absent
  from the FROM clause, to prevent accidental cartesian products, or LEFT_JOIN if declared
  explicitly in the FROM clause. In DML statements, it is always SCALAR_SUBQUERY, unless DML joins
  are supported.
- getRenderDefaultNullability: Whether the Nullability.DEFAULT nullablity should be rendered in
  generated DDL, and how it should be rendered.
- setRenderDefaultNullability: Whether the Nullability.DEFAULT nullablity should be rendered in
  generated DDL, and how it should be rendered.
- isRenderCoalesceToEmptyStringInConcat: Whether string concatenation operands should be coalesced
  to empty strings. Some dialects treat NULL values as empty strings when concatenating strings
  (e.g. Oracle). For compatibility reasons, this flag allows for replicating this behaviour also
  elsewhere. This feature is available in the commercial distribution only.
- setRenderCoalesceToEmptyStringInConcat: Whether string concatenation operands should be coalesced
  to empty strings. Some dialects treat NULL values as empty strings when concatenating strings
  (e.g. Oracle). For compatibility reasons, this flag allows for replicating this behaviour also
  elsewhere. This feature is available in the commercial distribution only.
- isRenderOrderByRownumberForEmulatedPagination: Whether an additional ORDER BY rn clause should be
  rendered on emulated paginated queries. Older databases did not support OFFSET .. FETCH
  pagination, so jOOQ emulates it using derived tables and ROWNUM (Oracle 11g and older) or
  ROW_NUMBER() (e.g. DB2, SQL Server, etc.) filtering. While these subqueries are ordered, the
  ordering is not guaranteed to be stable in the outer most queries. It may be stable (and e.g. in
  Oracle, it mostly is, if queries are not parallel, or joined to other queries, etc.), so the
  excess ORDER BY clause may add some additional performance overhead. This setting forces jOOQ to
  not generate the additional ORDER BY clause. For details, see
  https://github.com/jOOQ/jOOQ/issues/7609.
- setRenderOrderByRownumberForEmulatedPagination: Whether an additional ORDER BY rn clause should be
  rendered on emulated paginated queries. Older databases did not support OFFSET .. FETCH
  pagination, so jOOQ emulates it using derived tables and ROWNUM (Oracle 11g and older) or
  ROW_NUMBER() (e.g. DB2, SQL Server, etc.) filtering. While these subqueries are ordered, the
  ordering is not guaranteed to be stable in the outer most queries. It may be stable (and e.g. in
  Oracle, it mostly is, if queries are not parallel, or joined to other queries, etc.), so the
  excess ORDER BY clause may add some additional performance overhead. This setting forces jOOQ to
  not generate the additional ORDER BY clause. For details, see
  https://github.com/jOOQ/jOOQ/issues/7609.
- isRenderOutputForSQLServerReturningClause: Whether the jOOQ RETURNING clause should map to SQL
  Server's OUTPUT clause. SQL Server supports an OUTPUT clause in most DML statements, whose
  behaviour is almost identical to RETURNING in Firebird, Oracle, PostgreSQL. Users who want to
  prevent jOOQ from rendering this OUTPUT clause can deactivate this flag to revert to jOOQ calling
  java.sql.Statement#getGeneratedKeys() instead, which is only supported for single row inserts.
  This OUTPUT clause does not support fetching trigger generated values. In order to fetch trigger
  generated values, fetchTriggerValuesAfterReturning needs to be enabled as well. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- setRenderOutputForSQLServerReturningClause: Whether the jOOQ RETURNING clause should map to SQL
  Server's OUTPUT clause. SQL Server supports an OUTPUT clause in most DML statements, whose
  behaviour is almost identical to RETURNING in Firebird, Oracle, PostgreSQL. Users who want to
  prevent jOOQ from rendering this OUTPUT clause can deactivate this flag to revert to jOOQ calling
  java.sql.Statement#getGeneratedKeys() instead, which is only supported for single row inserts.
  This OUTPUT clause does not support fetching trigger generated values. In order to fetch trigger
  generated values, fetchTriggerValuesAfterReturning needs to be enabled as well. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- isRenderGroupConcatMaxLenSessionVariable: Whether the jOOQ GROUP_CONCAT function should be
  overflow-protected by setting the @@group_concat_max_len session variable in MySQL style database
  systems. MySQL truncates GROUP_CONCAT results after a certain length, which may be way too small
  for jOOQ's usage, especially when using the MULTISET emulation. By default, jOOQ sets a session
  variable to the highest possible value prior to executing a query containing GROUP_CONCAT. This
  flag can be used to opt out of this. For details, see https://github.com/jOOQ/jOOQ/issues/12092.
- setRenderGroupConcatMaxLenSessionVariable: Whether the jOOQ GROUP_CONCAT function should be
  overflow-protected by setting the @@group_concat_max_len session variable in MySQL style database
  systems. MySQL truncates GROUP_CONCAT results after a certain length, which may be way too small
  for jOOQ's usage, especially when using the MULTISET emulation. By default, jOOQ sets a session
  variable to the highest possible value prior to executing a query containing GROUP_CONCAT. This
  flag can be used to opt out of this. For details, see https://github.com/jOOQ/jOOQ/issues/12092.
- isRenderParenthesisAroundSetOperationQueries: Whether queries combined with set operators (e.g.
  UNION and UNION ALL) should always be surrounded by a parenthesis pair. By default (i.e. when this
  setting is set to false jOOQ will only render parenthesis pairs around queries combined with set
  operators when required. This is for example the case when set operators are nested, when non-
  associative operators like EXCEPT are used, or when the queries are rendered as derived tables.
  When this setting is set to true the queries combined with set operators will always be surrounded
  by a parenthesis pair. For details, see https://github.com/jOOQ/jOOQ/issues/3676 and
  https://github.com/jOOQ/jOOQ/issues/9751.
- setRenderParenthesisAroundSetOperationQueries: Whether queries combined with set operators (e.g.
  UNION and UNION ALL) should always be surrounded by a parenthesis pair. By default (i.e. when this
  setting is set to false jOOQ will only render parenthesis pairs around queries combined with set
  operators when required. This is for example the case when set operators are nested, when non-
  associative operators like EXCEPT are used, or when the queries are rendered as derived tables.
  When this setting is set to true the queries combined with set operators will always be surrounded
  by a parenthesis pair. For details, see https://github.com/jOOQ/jOOQ/issues/3676 and
  https://github.com/jOOQ/jOOQ/issues/9751.
- isRenderVariablesInDerivedTablesForEmulations: Whether emulations that require repeating
  expressions should render variables for those expressions in derived tables. For details, see
  https://github.com/jOOQ/jOOQ/issues/14065.
- setRenderVariablesInDerivedTablesForEmulations: Whether emulations that require repeating
  expressions should render variables for those expressions in derived tables. For details, see
  https://github.com/jOOQ/jOOQ/issues/14065.
- isRenderRowConditionForSeekClause: Whether a (a, b) Ungültige Eingabe: "<" (:a, :b) row predicate
  should be rendered for the SEEK clause. Some RDBMS may support (a, b) Ungültige Eingabe: "<" (:a,
  :b) row predicate syntax, which is very convenient for SEEK clause implementations, but fail to
  optimise this predicate as could be expected. This flag allows for expanding the predicate to the
  much more verbose, but equivalent (a Ungültige Eingabe: "<" :a) OR (a = :a AND b Ungültige
  Eingabe: "<" :b). Dialects without native support for row predicates aren't affected by this flag.
- setRenderRowConditionForSeekClause: Whether a (a, b) Ungültige Eingabe: "<" (:a, :b) row predicate
  should be rendered for the SEEK clause. Some RDBMS may support (a, b) Ungültige Eingabe: "<" (:a,
  :b) row predicate syntax, which is very convenient for SEEK clause implementations, but fail to
  optimise this predicate as could be expected. This flag allows for expanding the predicate to the
  much more verbose, but equivalent (a Ungültige Eingabe: "<" :a) OR (a = :a AND b Ungültige
  Eingabe: "<" :b). Dialects without native support for row predicates aren't affected by this flag.
- isRenderRedundantConditionForSeekClause: Whether a redundant (a Ungültige Eingabe: "<"= :a)
  predicate should be rendered for a (a, b) Ungültige Eingabe: "<" (:a, :b) predicate for the SEEK
  clause. Some RDBMS may not be able to properly optimise (a, b) Ungültige Eingabe: "<" ('a', 'b')
  or (a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<" 'b'), and choose an
  appropriate index. By adding an additional redundant predicate, jOOQ may help the optimiser, e.g.
  (a Ungültige Eingabe: "<"= :a) AND (a, b) Ungültige Eingabe: "<" ('a', 'b') or (a Ungültige
  Eingabe: "<"= :a) AND ((a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<"
  'b'))
- setRenderRedundantConditionForSeekClause: Whether a redundant (a Ungültige Eingabe: "<"= :a)
  predicate should be rendered for a (a, b) Ungültige Eingabe: "<" (:a, :b) predicate for the SEEK
  clause. Some RDBMS may not be able to properly optimise (a, b) Ungültige Eingabe: "<" ('a', 'b')
  or (a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<" 'b'), and choose an
  appropriate index. By adding an additional redundant predicate, jOOQ may help the optimiser, e.g.
  (a Ungültige Eingabe: "<"= :a) AND (a, b) Ungültige Eingabe: "<" ('a', 'b') or (a Ungültige
  Eingabe: "<"= :a) AND ((a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<"
  'b'))
- isRenderPlainSQLTemplatesAsRaw: Whether plain SQL templates (SQL) are rendered as raw string
  content.
- setRenderPlainSQLTemplatesAsRaw: Whether plain SQL templates (SQL) are rendered as raw string
  content.
- getRenderDollarQuotedStringToken: The token to place between the $$ signs of a PostgreSQL dollar
  quoted string generated by jOOQ.
- setRenderDollarQuotedStringToken: The token to place between the $$ signs of a PostgreSQL dollar
  quoted string generated by jOOQ.
- getNamePathSeparator Name: The character(s) to be used as a separator in paths encoded in a
  Ungültige Referenz Name A few hierarchical mapping features work with paths encoded in names
  (specifically field aliases), such as the reflective mapping of nested values when aliasing fields
  as: SELECT a.first_name AS "book.author.firstName" a.last_name AS "book.author.lastName" FROM ...
  Not all dialects support "." in identifiers. This setting allows for specifying an alternative
  String to use as separator, e.g. "__".
- setNamePathSeparator Name: The character(s) to be used as a separator in paths encoded in a
  Ungültige Referenz Name A few hierarchical mapping features work with paths encoded in names
  (specifically field aliases), such as the reflective mapping of nested values when aliasing fields
  as: SELECT a.first_name AS "book.author.firstName" a.last_name AS "book.author.lastName" FROM ...
  Not all dialects support "." in identifiers. This setting allows for specifying an alternative
  String to use as separator, e.g. "__".
- isBindOffsetDateTimeType: Whether the java.time (JSR 310) type OffsetDateTime should be bound
  natively to JDBC. Historically, jOOQ encoded the java.time types as strings to offer better
  compatibility with older JDBC drivers. By now, most drivers should support the java.time types.
  Using them may produce better performance both on the server and on the client side. This flag
  allows for reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types
  natively. For details, see https://github.com/jOOQ/jOOQ/issues/9902.
- setBindOffsetDateTimeType: Whether the java.time (JSR 310) type OffsetDateTime should be bound
  natively to JDBC. Historically, jOOQ encoded the java.time types as strings to offer better
  compatibility with older JDBC drivers. By now, most drivers should support the java.time types.
  Using them may produce better performance both on the server and on the client side. This flag
  allows for reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types
  natively. For details, see https://github.com/jOOQ/jOOQ/issues/9902.
- isBindOffsetTimeType: Whether the java.time (JSR 310) type OffsetTime should be bound natively to
  JDBC. Historically, jOOQ encoded the java.time types as strings to offer better compatibility with
  older JDBC drivers. By now, most drivers should support the java.time types. Using them may
  produce better performance both on the server and on the client side. This flag allows for
  reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types natively. For
  details, see https://github.com/jOOQ/jOOQ/issues/9902.
- setBindOffsetTimeType: Whether the java.time (JSR 310) type OffsetTime should be bound natively to
  JDBC. Historically, jOOQ encoded the java.time types as strings to offer better compatibility with
  older JDBC drivers. By now, most drivers should support the java.time types. Using them may
  produce better performance both on the server and on the client side. This flag allows for
  reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types natively. For
  details, see https://github.com/jOOQ/jOOQ/issues/9902.
- isFetchTrimmedCharValues: Whether right trim fetched CHAR typed strings from JDBC ResultSet. By
  default, jOOQ's internal String data type Binding fetched strings as returned by JDBC. With this
  flag enabled, jOOQ will always right-trim CHAR typed strings, which can be useful in database
  products that will often use this historic fixed length string type, especially in dictionary
  views.
- setFetchTrimmedCharValues: Whether right trim fetched CHAR typed strings from JDBC ResultSet. By
  default, jOOQ's internal String data type Binding fetched strings as returned by JDBC. With this
  flag enabled, jOOQ will always right-trim CHAR typed strings, which can be useful in database
  products that will often use this historic fixed length string type, especially in dictionary
  views.
- isFetchTriggerValuesAfterSQLServerOutput: Fetch trigger values after SQL Server OUTPUT clause. SQL
  Server OUTPUT statements do not support fetching trigger generated values. This is a limitation of
  the renderOutputForSQLServerReturningClause. An additional MERGE statement can run a second query
  if (and only if) the primary key has been included in the OUTPUT clause. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- setFetchTriggerValuesAfterSQLServerOutput: Fetch trigger values after SQL Server OUTPUT clause.
  SQL Server OUTPUT statements do not support fetching trigger generated values. This is a
  limitation of the renderOutputForSQLServerReturningClause. An additional MERGE statement can run a
  second query if (and only if) the primary key has been included in the OUTPUT clause. For details,
  see https://github.com/jOOQ/jOOQ/issues/4498.
- getFetchTriggerValuesAfterReturning: Fetch trigger values after a RETURNING clause in dialects
  that don't have native support for this. SQL Server OUTPUT clauses do not support fetching trigger
  generated values. Neither do SQLite RETURNING clauses. An additional MERGE statement can run a
  second query if (and only if) the primary key has been included in the OUTPUT clause. Trigger meta
  data is only available in jOOQ's commercial editions. If setting this flag to WHEN_NEEDED in the
  jOOQ Open Source Edition, jOOQ will assume triggers are present. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- setFetchTriggerValuesAfterReturning: Fetch trigger values after a RETURNING clause in dialects
  that don't have native support for this. SQL Server OUTPUT clauses do not support fetching trigger
  generated values. Neither do SQLite RETURNING clauses. An additional MERGE statement can run a
  second query if (and only if) the primary key has been included in the OUTPUT clause. Trigger meta
  data is only available in jOOQ's commercial editions. If setting this flag to WHEN_NEEDED in the
  jOOQ Open Source Edition, jOOQ will assume triggers are present. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- getFetchIntermediateResult: Whether to fetch data into intermediate Result instances. By default,
  a ResultQuery produces no intermediate Result instances if they are not explicitly requested by
  the caller, e.g. by calling ResultQuery.fetch(), or in the presence of ExecuteListener instances,
  which may require access to ExecuteContext.result(). This default behaviour helps avoid
  unnecessary allocations of possibly large data structures. Using this flag, fetching of
  intermediate results can be turned off even when execute listeners are present, or turned on even
  if they're absent.
- setFetchIntermediateResult: Whether to fetch data into intermediate Result instances. By default,
  a ResultQuery produces no intermediate Result instances if they are not explicitly requested by
  the caller, e.g. by calling ResultQuery.fetch(), or in the presence of ExecuteListener instances,
  which may require access to ExecuteContext.result(). This default behaviour helps avoid
  unnecessary allocations of possibly large data structures. Using this flag, fetching of
  intermediate results can be turned off even when execute listeners are present, or turned on even
  if they're absent.
- isDiagnosticsDuplicateStatements: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsDuplicateStatements: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsDuplicateStatementsUsingTransformPatterns: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic with the
  transformPatterns feature activated. When transforming patterns, many more complex, duplicate SQL
  statements can be recognised than if simply parsing and re-rendering the statement. This flag
  turns on all transformation patterns, independently of their individual settings. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default. This feature is available in the commercial distribution
  only.
- setDiagnosticsDuplicateStatementsUsingTransformPatterns: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic with the
  transformPatterns feature activated. When transforming patterns, many more complex, duplicate SQL
  statements can be recognised than if simply parsing and re-rendering the statement. This flag
  turns on all transformation patterns, independently of their individual settings. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default. This feature is available in the commercial distribution
  only.
- isDiagnosticsMissingWasNullCall: Whether to run the
  DiagnosticsListener.missingWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsMissingWasNullCall: Whether to run the
  DiagnosticsListener.missingWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsRepeatedStatements: Whether to run the
  DiagnosticsListener.repeatedStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsRepeatedStatements: Whether to run the
  DiagnosticsListener.repeatedStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsConsecutiveAggregation
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- setDiagnosticsConsecutiveAggregation
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- isDiagnosticsConcatenationInPredicate
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- setDiagnosticsConcatenationInPredicate
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- isDiagnosticsPossiblyWrongExpression
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- setDiagnosticsPossiblyWrongExpression
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- isDiagnosticsTooManyColumnsFetched: Whether to run the
  DiagnosticsListener.tooManyColumnsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsTooManyColumnsFetched: Whether to run the
  DiagnosticsListener.tooManyColumnsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsTooManyRowsFetched: Whether to run the
  DiagnosticsListener.tooManyRowsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsTooManyRowsFetched: Whether to run the
  DiagnosticsListener.tooManyRowsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsUnnecessaryWasNullCall: Whether to run the
  DiagnosticsListener.unnecessaryWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics
  are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- setDiagnosticsUnnecessaryWasNullCall: Whether to run the
  DiagnosticsListener.unnecessaryWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics
  are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- isDiagnosticsPatterns: Whether to run the various pattern transformation diagnostics.
  transformPatterns allows for applying numerous pattern transformations, which can be turned on
  separately when running diagnostics. This flag overrides the transformPatterns flag in the
  diagnostics context. Individual pattern flags still allow to enable / disable the pattern for
  diagnostics. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- setDiagnosticsPatterns: Whether to run the various pattern transformation diagnostics.
  transformPatterns allows for applying numerous pattern transformations, which can be turned on
  separately when running diagnostics. This flag overrides the transformPatterns flag in the
  diagnostics context. Individual pattern flags still allow to enable / disable the pattern for
  diagnostics. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- isDiagnosticsTrivialCondition
  org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- setDiagnosticsTrivialCondition
  org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- isDiagnosticsNullCondition
  org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- setDiagnosticsNullCondition
  org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- isTransformPatterns: Transform various syntax patterns to better versions, if possible. This flag
  enables the pattern transformation feature, which consists of several sub-flags that are all
  prefixed with "transformPatterns", e.g. transformPatternsTrim. While the sub-flags default to
  being enabled, and can be disabled on an individual basis, the global feature itself is disabled
  by default. This feature is available in the commercial distribution only.
- setTransformPatterns: Transform various syntax patterns to better versions, if possible. This flag
  enables the pattern transformation feature, which consists of several sub-flags that are all
  prefixed with "transformPatterns", e.g. transformPatternsTrim. While the sub-flags default to
  being enabled, and can be disabled on an individual basis, the global feature itself is disabled
  by default. This feature is available in the commercial distribution only.
- isTransformPatternsLogging: Activate debug logging of the transformPatterns feature.
- setTransformPatternsLogging: Activate debug logging of the transformPatterns feature.
- isTransformPatternsUnnecessaryDistinct: Transform SELECT DISTINCT a, b FROM t GROUP BY a, b to
  SELECT a, b FROM t GROUP BY a, b. The GROUP BY clause already removes duplicates, so if the
  DISTINCT clause contains at least all the columns from GROUP BY then it can be removed. To enable
  this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsUnnecessaryDistinct: Transform SELECT DISTINCT a, b FROM t GROUP BY a, b to
  SELECT a, b FROM t GROUP BY a, b. The GROUP BY clause already removes duplicates, so if the
  DISTINCT clause contains at least all the columns from GROUP BY then it can be removed. To enable
  this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsUnnecessaryScalarSubquery: Transform SELECT (SELECT 1) to SELECT 1. Scalar
  subqueries that don't have any content other than a SELECT clause are unnecessary and can be
  removed. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- setTransformPatternsUnnecessaryScalarSubquery: Transform SELECT (SELECT 1) to SELECT 1. Scalar
  subqueries that don't have any content other than a SELECT clause are unnecessary and can be
  removed. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- isTransformPatternsUnnecessaryInnerJoin: Transform SELECT * FROM t INNER JOIN u ON TRUE to SELECT
  * FROM t CROSS JOIN u. Some INNER JOIN expressions can be proven to be unnecessary. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsUnnecessaryInnerJoin: Transform SELECT * FROM t INNER JOIN u ON TRUE to SELECT
  * FROM t CROSS JOIN u. Some INNER JOIN expressions can be proven to be unnecessary. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsUnnecessaryGroupByExpressions: Transform SELECT a, b FROM t GROUP BY a, a, b to
  SELECT a, b FROM t GROUP BY a, b. Duplicate GROUP BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsUnnecessaryGroupByExpressions: Transform SELECT a, b FROM t GROUP BY a, a, b
  to SELECT a, b FROM t GROUP BY a, b. Duplicate GROUP BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsUnnecessaryOrderByExpressions: Transform SELECT a, b FROM t ORDER BY a, a, b to
  SELECT a, b FROM t ORDER BY a, b. Duplicate ORDER BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsUnnecessaryOrderByExpressions: Transform SELECT a, b FROM t ORDER BY a, a, b
  to SELECT a, b FROM t ORDER BY a, b. Duplicate ORDER BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsUnnecessaryExistsSubqueryClauses: Transform [ NOT ] EXISTS (SELECT DISTINCT a,
  b FROM t ORDER BY c LIMIT d) to [ NOT ] EXISTS (SELECT 1 FROM t). In EXISTS subqueries, quite a
  few SELECT clauses are meaningless, and can thus be removed. These include: SELECT (any projection
  can be ignored) DISTINCT ORDER BY LIMIT (except LIMIT 0, in case of which
  transformPatternsTrivialPredicates applies). To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsUnnecessaryExistsSubqueryClauses: Transform [ NOT ] EXISTS (SELECT DISTINCT a,
  b FROM t ORDER BY c LIMIT d) to [ NOT ] EXISTS (SELECT 1 FROM t). In EXISTS subqueries, quite a
  few SELECT clauses are meaningless, and can thus be removed. These include: SELECT (any projection
  can be ignored) DISTINCT ORDER BY LIMIT (except LIMIT 0, in case of which
  transformPatternsTrivialPredicates applies). To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- isTransformPatternsCountConstant: Transform COUNT(1) or any other COUNT(const) to COUNT(*). There
  is no benefit to counting a constant expression. In fact, in some RDBMS, it might even be slightly
  slower, at least in benchmarks. To enable this feature, transformPatterns must be enabled as well.
  This feature is available in the commercial distribution only.
- setTransformPatternsCountConstant: Transform COUNT(1) or any other COUNT(const) to COUNT(*). There
  is no benefit to counting a constant expression. In fact, in some RDBMS, it might even be slightly
  slower, at least in benchmarks. To enable this feature, transformPatterns must be enabled as well.
  This feature is available in the commercial distribution only.
- isTransformPatternsTrim: Transform LTRIM(RTRIM(x)) or RTRIM(LTRIM(x)) to TRIM(x). Historically, a
  few dialects did not implement TRIM(x) or TRIM(BOTH FROM x), so users worked around this by
  wrapping LTRIM() and RTRIM() with each other. Maintaining this is usually undesirable, so this
  transformation helps remove the unwanted wrapping. To enable this feature, transformPatterns must
  be enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsTrim: Transform LTRIM(RTRIM(x)) or RTRIM(LTRIM(x)) to TRIM(x). Historically, a
  few dialects did not implement TRIM(x) or TRIM(BOTH FROM x), so users worked around this by
  wrapping LTRIM() and RTRIM() with each other. Maintaining this is usually undesirable, so this
  transformation helps remove the unwanted wrapping. To enable this feature, transformPatterns must
  be enabled as well. This feature is available in the commercial distribution only.
- isTransformPatternsNotAnd: Transform NOT(p AND q) to NOT(p) OR NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsNotAnd: Transform NOT(p AND q) to NOT(p) OR NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- isTransformPatternsNotOr: Transform NOT(p OR q) to NOT(p) AND NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsNotOr: Transform NOT(p OR q) to NOT(p) AND NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- isTransformPatternsNotNot: Transform NOT(NOT(x)) to x. This transformation removes a redundant
  logic negation. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- setTransformPatternsNotNot: Transform NOT(NOT(x)) to x. This transformation removes a redundant
  logic negation. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- isTransformPatternsNotComparison: Transform NOT (a != b) to a = b, and similar comparisons. This
  transformation removes a redundant logical negation from the DISTINCT predicate. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsNotComparison: Transform NOT (a != b) to a = b, and similar comparisons. This
  transformation removes a redundant logical negation from the DISTINCT predicate. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsNotNotDistinct: Transform NOT (a IS NOT DISTINCT FROM b) to a IS DISTINCT FROM
  b. This transformation removes a redundant logical negation from the DISTINCT predicate. To enable
  this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsNotNotDistinct: Transform NOT (a IS NOT DISTINCT FROM b) to a IS DISTINCT FROM
  b. This transformation removes a redundant logical negation from the DISTINCT predicate. To enable
  this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsDistinctFromNull: Transform a IS [ NOT ] DISTINCT FROM NULL to a IS [ NOT ]
  NULL. This simplifies the much more verbose DISTINCT predicate. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsDistinctFromNull: Transform a IS [ NOT ] DISTINCT FROM NULL to a IS [ NOT ]
  NULL. This simplifies the much more verbose DISTINCT predicate. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsNormaliseAssociativeOps: Transform (a + b) + (c + d) to ((a + b) + c) + d. This
  transformation turns trees into lists, which greatly simplifies other tree traversal
  transformations. Some of those other transformations currently rely on this flag to be active. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsNormaliseAssociativeOps: Transform (a + b) + (c + d) to ((a + b) + c) + d.
  This transformation turns trees into lists, which greatly simplifies other tree traversal
  transformations. Some of those other transformations currently rely on this flag to be active. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsNormaliseInListSingleElementToComparison: Transform x IN (a) to x = a and x NOT
  IN (a) to x != a. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- setTransformPatternsNormaliseInListSingleElementToComparison: Transform x IN (a) to x = a and x
  NOT IN (a) to x != a. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsNormaliseFieldCompareValue TableField: Transform 1 = a to a = 1. This
  transformation inverses Ungültige Referenz TableField [op] Ungültige Referenz
  org.jooq.impl.QOM.Val comparisons, if they're not in that order. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsNormaliseFieldCompareValue TableField: Transform 1 = a to a = 1. This
  transformation inverses Ungültige Referenz TableField [op] Ungültige Referenz
  org.jooq.impl.QOM.Val comparisons, if they're not in that order. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsNormaliseCoalesceToNvl: Transform 2 argument COALESCE(a, b) to NVL(a, b). To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsNormaliseCoalesceToNvl: Transform 2 argument COALESCE(a, b) to NVL(a, b). To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsOrEqToIn: Transform x = c1 OR x = c2 to x IN (c1, c2). This transformation
  simplifies verbose OR predicates into simpler IN predicates. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsOrEqToIn: Transform x = c1 OR x = c2 to x IN (c1, c2). This transformation
  simplifies verbose OR predicates into simpler IN predicates. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsAndNeToNotIn: Transform x != c1 AND x != c2 to x NOT IN (c1, c2). This
  transformation simplifies verbose AND predicates into simpler NOT IN predicates. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsAndNeToNotIn: Transform x != c1 AND x != c2 to x NOT IN (c1, c2). This
  transformation simplifies verbose AND predicates into simpler NOT IN predicates. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsMergeOrComparison: Transform x = a OR x > a to x >= a. This transformation
  merges multiple OR connected comparisons to a single comparison using a simpler operator. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsMergeOrComparison: Transform x = a OR x > a to x >= a. This transformation
  merges multiple OR connected comparisons to a single comparison using a simpler operator. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsMergeAndComparison: Transform x >= a AND x Ungültige Eingabe: "<"= a to x = a.
  This transformation merges multiple AND connected comparisons to a single comparison using a
  simpler operator. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- setTransformPatternsMergeAndComparison: Transform x >= a AND x Ungültige Eingabe: "<"= a to x = a.
  This transformation merges multiple AND connected comparisons to a single comparison using a
  simpler operator. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- isTransformPatternsMergeInLists: Transform x IN (a, b, c) AND x IN (b, c, d) to x IN (b, c). This
  transformation merges multiple OR connected comparisons to a single comparison using a simpler
  operator. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- setTransformPatternsMergeInLists: Transform x IN (a, b, c) AND x IN (b, c, d) to x IN (b, c). This
  transformation merges multiple OR connected comparisons to a single comparison using a simpler
  operator. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- isTransformPatternsMergeRangePredicates: Transform x >= a AND x Ungültige Eingabe: "<"= b to x
  BETWEEN a AND b. This transformation merges multiple AND connected range predicates to a single
  comparison using BETWEEN. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- setTransformPatternsMergeRangePredicates: Transform x >= a AND x Ungültige Eingabe: "<"= b to x
  BETWEEN a AND b. This transformation merges multiple AND connected range predicates to a single
  comparison using BETWEEN. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsMergeBetweenSymmetricPredicates: Transform x BETWEEN a AND b OR x BETWEEN b AND
  a to x BETWEEN SYMMETRIC a AND b. This transformation merges multiple OR connected BETWEEN
  predicates to a single comparison using BETWEEN SYMMETRIC. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsMergeBetweenSymmetricPredicates: Transform x BETWEEN a AND b OR x BETWEEN b
  AND a to x BETWEEN SYMMETRIC a AND b. This transformation merges multiple OR connected BETWEEN
  predicates to a single comparison using BETWEEN SYMMETRIC. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsCaseSearchedToCaseSimple: Transform a searched CASE WHEN x = .. WHEN x = .. to
  a simple CASE x WHEN … WHEN … expression. When a searched CASE expression always compares the same
  column to a value, then it can be simplified, possibly unlocking further transformations that are
  available only to the simple CASE expression. This feature is available in the commercial
  distribution only.
- setTransformPatternsCaseSearchedToCaseSimple: Transform a searched CASE WHEN x = .. WHEN x = .. to
  a simple CASE x WHEN … WHEN … expression. When a searched CASE expression always compares the same
  column to a value, then it can be simplified, possibly unlocking further transformations that are
  available only to the simple CASE expression. This feature is available in the commercial
  distribution only.
- isTransformPatternsCaseElseNull: Transform CASE … ELSE NULL removing the ELSE clause. CASE WHEN x
  THEN y ELSE NULL END is equivalent to CASE WHEN x THEN y END. This feature is available in the
  commercial distribution only.
- setTransformPatternsCaseElseNull: Transform CASE … ELSE NULL removing the ELSE clause. CASE WHEN x
  THEN y ELSE NULL END is equivalent to CASE WHEN x THEN y END. This feature is available in the
  commercial distribution only.
- isTransformPatternsUnreachableCaseClauses: Transform CASE by removing unreachable clauses. Case
  clauses can be proven to be unreachable, and thus removed: CASE WHEN p THEN 1 WHEN TRUE THEN 2
  WHEN q … ELSE … END is equivalent to CASE WHEN p THEN 1 ELSE 2 END CASE WHEN p THEN 1 WHEN FALSE
  THEN 2 WHEN q .. ELSE .. END is equivalent to CASE WHEN p THEN 1 WHEN q … ELSE … END This feature
  is available in the commercial distribution only.
- setTransformPatternsUnreachableCaseClauses: Transform CASE by removing unreachable clauses. Case
  clauses can be proven to be unreachable, and thus removed: CASE WHEN p THEN 1 WHEN TRUE THEN 2
  WHEN q … ELSE … END is equivalent to CASE WHEN p THEN 1 ELSE 2 END CASE WHEN p THEN 1 WHEN FALSE
  THEN 2 WHEN q .. ELSE .. END is equivalent to CASE WHEN p THEN 1 WHEN q … ELSE … END This feature
  is available in the commercial distribution only.
- isTransformPatternsUnreachableDecodeClauses: Transform DECODE by removing unreachable clauses.
  DECODE clauses can be proven to be unreachable, and thus removed: DECODE(a, b, 1, c, 2, b, 3) is
  equivalent to DECODE(a, b, 1, c, 2) DECODE(a, b, 1, c, 2, b, 3, 4) is equivalent to DECODE(a, b,
  1, c, 2, 4) This feature is available in the commercial distribution only.
- setTransformPatternsUnreachableDecodeClauses: Transform DECODE by removing unreachable clauses.
  DECODE clauses can be proven to be unreachable, and thus removed: DECODE(a, b, 1, c, 2, b, 3) is
  equivalent to DECODE(a, b, 1, c, 2) DECODE(a, b, 1, c, 2, b, 3, 4) is equivalent to DECODE(a, b,
  1, c, 2, 4) This feature is available in the commercial distribution only.
- isTransformPatternsCaseDistinctToDecode: Transform CASE WHEN a IS NOT DISTINCT FROM b … to an
  equivalent DECODE function. When all WHEN clauses of a CASE expression use the DISTINCT predicate,
  then the CASE expression can be transformed into a DECODE function call: CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 END is equivalent to DECODE(a, b, 1) CASE WHEN a IS NOT DISTINCT FROM b
  THEN 1 ELSE 2 END is equivalent to DECODE(a, b, 1, 2) CASE WHEN a IS NOT DISTINCT FROM b THEN 1
  WHEN a IS NOT DISTINCT FROM c THEN 2 END is equivalent to DECODE(a, b, 1, c, 2) CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 WHEN a IS NOT DISTINCT FROM c THEN 2 ELSE 3 END is equivalent to DECODE(a,
  b, 1, c, 2, 3) This feature is available in the commercial distribution only.
- setTransformPatternsCaseDistinctToDecode: Transform CASE WHEN a IS NOT DISTINCT FROM b … to an
  equivalent DECODE function. When all WHEN clauses of a CASE expression use the DISTINCT predicate,
  then the CASE expression can be transformed into a DECODE function call: CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 END is equivalent to DECODE(a, b, 1) CASE WHEN a IS NOT DISTINCT FROM b
  THEN 1 ELSE 2 END is equivalent to DECODE(a, b, 1, 2) CASE WHEN a IS NOT DISTINCT FROM b THEN 1
  WHEN a IS NOT DISTINCT FROM c THEN 2 END is equivalent to DECODE(a, b, 1, c, 2) CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 WHEN a IS NOT DISTINCT FROM c THEN 2 ELSE 3 END is equivalent to DECODE(a,
  b, 1, c, 2, 3) This feature is available in the commercial distribution only.
- isTransformPatternsCaseMergeWhenWhen: Transform CASE WHEN a THEN x WHEN b THEN x END to CASE WHEN
  a OR b THEN x END. Two consecutive WHEN clauses can be merged, if their respective THEN clause is
  identical. This feature is available in the commercial distribution only.
- setTransformPatternsCaseMergeWhenWhen: Transform CASE WHEN a THEN x WHEN b THEN x END to CASE WHEN
  a OR b THEN x END. Two consecutive WHEN clauses can be merged, if their respective THEN clause is
  identical. This feature is available in the commercial distribution only.
- isTransformPatternsCaseMergeWhenElse: Transform CASE WHEN a THEN x WHEN b THEN y ELSE y END to
  CASE WHEN a THEN x ELSE y END. The ultimate WHEN clause can be merged with the ELSE, if their
  respective result is identical. If the WHEN clause is the only WHEN clause, then the entire CASE
  expression can be replaced by the ELSE clause content. This feature is available in the commercial
  distribution only.
- setTransformPatternsCaseMergeWhenElse: Transform CASE WHEN a THEN x WHEN b THEN y ELSE y END to
  CASE WHEN a THEN x ELSE y END. The ultimate WHEN clause can be merged with the ELSE, if their
  respective result is identical. If the WHEN clause is the only WHEN clause, then the entire CASE
  expression can be replaced by the ELSE clause content. This feature is available in the commercial
  distribution only.
- isTransformPatternsCaseToCaseAbbreviation: Transform CASE expressions to their respective
  abbreviations. Some CASE expressions have a shorter abbreviated form, such as COALESCE() or
  NULLIF(). This feature is available in the commercial distribution only.
- setTransformPatternsCaseToCaseAbbreviation: Transform CASE expressions to their respective
  abbreviations. Some CASE expressions have a shorter abbreviated form, such as COALESCE() or
  NULLIF(). This feature is available in the commercial distribution only.
- isTransformPatternsSimplifyCaseAbbreviation: Transform complex predicates into simpler CASE
  abbreviations. Some predicates can be simplified into case abbreviations, such as, for example a
  IS NULL OR COALESCE(a = b, FALSE) to NULLIF(a, b) IS NULL a IS NOT NULL AND COALESCE(a != b, TRUE)
  to NULLIF(a, b) IS NOT NULL This feature is available in the commercial distribution only.
- setTransformPatternsSimplifyCaseAbbreviation: Transform complex predicates into simpler CASE
  abbreviations. Some predicates can be simplified into case abbreviations, such as, for example a
  IS NULL OR COALESCE(a = b, FALSE) to NULLIF(a, b) IS NULL a IS NOT NULL AND COALESCE(a != b, TRUE)
  to NULLIF(a, b) IS NOT NULL This feature is available in the commercial distribution only.
- isTransformPatternsFlattenCaseAbbreviation: Flatten nested CASE abbreviations such as NVL or CASE.
  Nested CASE abbreviations can be flattened, as such: NVL(NVL(a, b), c) to COALESCE(a, b, c)
  COALESCE(a, ..., COALESCE(b, ..., c), ..., d) to COALESCE(a, …, b, …, c, ..., d) This feature is
  available in the commercial distribution only.
- setTransformPatternsFlattenCaseAbbreviation: Flatten nested CASE abbreviations such as NVL or
  CASE. Nested CASE abbreviations can be flattened, as such: NVL(NVL(a, b), c) to COALESCE(a, b, c)
  COALESCE(a, ..., COALESCE(b, ..., c), ..., d) to COALESCE(a, …, b, …, c, ..., d) This feature is
  available in the commercial distribution only.
- isTransformPatternsFlattenDecode: Flatten nested DECODE functions. Nested DECODE functions can be
  flattened, as such: DECODE(a, b, c, DECODE(a, d, e)) to DECODE(a, b, c, d, e) This feature is
  available in the commercial distribution only.
- setTransformPatternsFlattenDecode: Flatten nested DECODE functions. Nested DECODE functions can be
  flattened, as such: DECODE(a, b, c, DECODE(a, d, e)) to DECODE(a, b, c, d, e) This feature is
  available in the commercial distribution only.
- isTransformPatternsFlattenCase: Transform CASE … ELSE CASE … by flattening the nested CASE. CASE
  WHEN a THEN b ELSE CASE WHEN c THEN d END END is equivalent to CASE WHEN a THEN b WHEN c THEN d
  END. This feature is available in the commercial distribution only.
- setTransformPatternsFlattenCase: Transform CASE … ELSE CASE … by flattening the nested CASE. CASE
  WHEN a THEN b ELSE CASE WHEN c THEN d END END is equivalent to CASE WHEN a THEN b WHEN c THEN d
  END. This feature is available in the commercial distribution only.
- isTransformPatternsTrivialCaseAbbreviation: Transform trivial case abbreviations like NVL(NULL, a)
  to a. This transformation removes any trivial case abbreviations, such as NVL(), COALESCE(),
  NULLIF(), etc. This feature is available in the commercial distribution only.
- setTransformPatternsTrivialCaseAbbreviation: Transform trivial case abbreviations like NVL(NULL,
  a) to a. This transformation removes any trivial case abbreviations, such as NVL(), COALESCE(),
  NULLIF(), etc. This feature is available in the commercial distribution only.
- isTransformPatternsTrivialPredicates: Transform trivial predicates like 1 = 1 to TRUE. This
  transformation removes any trivial predicates. This feature is available in the commercial
  distribution only.
- setTransformPatternsTrivialPredicates: Transform trivial predicates like 1 = 1 to TRUE. This
  transformation removes any trivial predicates. This feature is available in the commercial
  distribution only.
- isTransformPatternsTrivialBitwiseOperations: Transform trivial bitwise comparisons like BIT_OR(a,
  0) to a. This transformation removes any trivial predicates. This feature is available in the
  commercial distribution only.
- setTransformPatternsTrivialBitwiseOperations: Transform trivial bitwise comparisons like BIT_OR(a,
  0) to a. This transformation removes any trivial predicates. This feature is available in the
  commercial distribution only.
- isTransformPatternsBitSet: Transform bitwise operations to an equivalent BIT_SET(a, b) or
  BIT_SET(a, b, c) expression. This feature is available in the commercial distribution only.
- setTransformPatternsBitSet: Transform bitwise operations to an equivalent BIT_SET(a, b) or
  BIT_SET(a, b, c) expression. This feature is available in the commercial distribution only.
- isTransformPatternsBitGet: Transform bitwise operations to an equivalent BIT_GET(a, b) expression.
  This feature is available in the commercial distribution only.
- setTransformPatternsBitGet: Transform bitwise operations to an equivalent BIT_GET(a, b)
  expression. This feature is available in the commercial distribution only.
- isTransformPatternsScalarSubqueryCountAsteriskGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(*) …) > 0 to equivalent EXISTS (SELECT 1 …). Scalar
  subqueries that count rows and whose count is compared to 0 can be transformed into equivalent,
  but likely cheaper to execute EXISTS queries. This feature is available in the commercial
  distribution only.
- setTransformPatternsScalarSubqueryCountAsteriskGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(*) …) > 0 to equivalent EXISTS (SELECT 1 …). Scalar
  subqueries that count rows and whose count is compared to 0 can be transformed into equivalent,
  but likely cheaper to execute EXISTS queries. This feature is available in the commercial
  distribution only.
- isTransformPatternsScalarSubqueryCountExpressionGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(expr) …) > 0 to equivalent EXISTS (SELECT 1 … WHERE expr IS
  NOT NULL). Scalar subqueries that count non-null expressions and whose count is compared to 0 can
  be transformed into equivalent, but likely cheaper to execute EXISTS queries. This feature is
  available in the commercial distribution only.
- setTransformPatternsScalarSubqueryCountExpressionGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(expr) …) > 0 to equivalent EXISTS (SELECT 1 … WHERE expr IS
  NOT NULL). Scalar subqueries that count non-null expressions and whose count is compared to 0 can
  be transformed into equivalent, but likely cheaper to execute EXISTS queries. This feature is
  available in the commercial distribution only.
- isTransformPatternsEmptyScalarSubquery: Transform empty scalar subqueries like (SELECT 1 WHERE
  FALSE) to NULL. Scalar subqueries that are guaranteed to produce no results can be replaced by a
  NULL value. This feature is available in the commercial distribution only.
- setTransformPatternsEmptyScalarSubquery: Transform empty scalar subqueries like (SELECT 1 WHERE
  FALSE) to NULL. Scalar subqueries that are guaranteed to produce no results can be replaced by a
  NULL value. This feature is available in the commercial distribution only.
- isTransformPatternsNegNeg: Transform -(-(x)) to x This transformation removes a redundant
  arithmetic negation. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- setTransformPatternsNegNeg: Transform -(-(x)) to x This transformation removes a redundant
  arithmetic negation. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsBitNotBitNot: Transform ~(~(x)) to x. This transformation removes a redundant
  bitwise negation. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- setTransformPatternsBitNotBitNot: Transform ~(~(x)) to x. This transformation removes a redundant
  bitwise negation. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- isTransformPatternsBitNotBitNand: Transform ~(bitnand(x, y)) to bitand(x, y) and ~(bitand(x, y) to
  bitnand(x, y). This transformation removes a redundant bitwise negation. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsBitNotBitNand: Transform ~(bitnand(x, y)) to bitand(x, y) and ~(bitand(x, y)
  to bitnand(x, y). This transformation removes a redundant bitwise negation. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsBitNotBitNor: Transform ~(bitnor(x, y)) to bitor(x, y) and ~(bitor(x, y) to
  bitnor(x, y). This transformation removes a redundant bitwise negation. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsBitNotBitNor: Transform ~(bitnor(x, y)) to bitor(x, y) and ~(bitor(x, y) to
  bitnor(x, y). This transformation removes a redundant bitwise negation. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsBitNotBitXNor: Transform ~(bitxnor(x, y)) to bitxor(x, y) and ~(bitxor(x, y) to
  bitxnor(x, y). This transformation removes a redundant bitwise negation. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- setTransformPatternsBitNotBitXNor: Transform ~(bitxnor(x, y)) to bitxor(x, y) and ~(bitxor(x, y)
  to bitxnor(x, y). This transformation removes a redundant bitwise negation. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsNullOnNullInput: Any {org.jooq.impl.QOM.UReturnsNullOnNullInput} function or
  expression with NULL arguments can be replaced by NULL. There are many built-in SQL functions and
  operators with a RETURNS NULL ON NULL INPUT property, e.g. ABS(NULL) MOD(NULL, 1) NULL + 1 To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- setTransformPatternsNullOnNullInput: Any {org.jooq.impl.QOM.UReturnsNullOnNullInput} function or
  expression with NULL arguments can be replaced by NULL. There are many built-in SQL functions and
  operators with a RETURNS NULL ON NULL INPUT property, e.g. ABS(NULL) MOD(NULL, 1) NULL + 1 To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- isTransformPatternsIdempotentFunctionRepetition: Transform all repetitions of idempotent
  functions, such as UPPER(UPPER(s)) to UPPER(s). Idempotent functions that are covered so far,
  include: LTRIM(LTRIM(s)) to LTRIM(s) LTRIM(TRIM(s)) to TRIM(s) RTRIM(RTRIM(s)) to RTRIM(s)
  RTRIM(TRIM(s)) to TRIM(s) TRIM(LTRIM(s)) to TRIM(s) TRIM(RTRIM(s)) to TRIM(s) UPPER(UPPER(s)) to
  UPPER(s) LOWER(LOWER(s)) to LOWER(s) To enable this feature, transformPatterns must be enabled as
  well. This feature is available in the commercial distribution only.
- setTransformPatternsIdempotentFunctionRepetition: Transform all repetitions of idempotent
  functions, such as UPPER(UPPER(s)) to UPPER(s). Idempotent functions that are covered so far,
  include: LTRIM(LTRIM(s)) to LTRIM(s) LTRIM(TRIM(s)) to TRIM(s) RTRIM(RTRIM(s)) to RTRIM(s)
  RTRIM(TRIM(s)) to TRIM(s) TRIM(LTRIM(s)) to TRIM(s) TRIM(RTRIM(s)) to TRIM(s) UPPER(UPPER(s)) to
  UPPER(s) LOWER(LOWER(s)) to LOWER(s) To enable this feature, transformPatterns must be enabled as
  well. This feature is available in the commercial distribution only.
- isTransformPatternsArithmeticComparisons: Transform a + 1 = 2 to a = 2 - 1, and other
  transformations. It is usually best to compare single columns with constants or expressions to
  encourage index usage. While function based indexes are possible in some RDBMS, ordinary indexes
  are more reusable and should be preferred. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsArithmeticComparisons: Transform a + 1 = 2 to a = 2 - 1, and other
  transformations. It is usually best to compare single columns with constants or expressions to
  encourage index usage. While function based indexes are possible in some RDBMS, ordinary indexes
  are more reusable and should be preferred. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- isTransformPatternsArithmeticExpressions: Transform 1 / y * x to x / y, and other transformations.
  This transformation simplifies arithmetic expressions. To enable this feature, transformPatterns
  must be enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsArithmeticExpressions: Transform 1 / y * x to x / y, and other
  transformations. This transformation simplifies arithmetic expressions. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- isTransformPatternsTrigonometricFunctions: Transform SIN(x) / COS(x) to TAN(x), and other
  transformations. This transformation turns expanded trignonometric function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- setTransformPatternsTrigonometricFunctions: Transform SIN(x) / COS(x) to TAN(x), and other
  transformations. This transformation turns expanded trignonometric function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsLogarithmicFunctions: Transform LN(value) / LN(base) to LOG(base, value), and
  other transformations. This transformation turns expanded logarithmic function definitions into
  their shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- setTransformPatternsLogarithmicFunctions: Transform LN(value) / LN(base) to LOG(base, value), and
  other transformations. This transformation turns expanded logarithmic function definitions into
  their shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsHyperbolicFunctions: Transform (EXP(x) - EXP(-x)) / 2 to SINH(x), and other
  transformations. This transformation turns expanded hyperbolic function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- setTransformPatternsHyperbolicFunctions: Transform (EXP(x) - EXP(-x)) / 2 to SINH(x), and other
  transformations. This transformation turns expanded hyperbolic function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- isTransformPatternsInverseHyperbolicFunctions: Transform LN(x + SQRT(SQUARE(x) + 1)) to ASINH(x),
  and other transformations. This transformation turns expanded inverse hyperbolic function
  definitions into their shorter equivalents. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- setTransformPatternsInverseHyperbolicFunctions: Transform LN(x + SQRT(SQUARE(x) + 1)) to ASINH(x),
  and other transformations. This transformation turns expanded inverse hyperbolic function
  definitions into their shorter equivalents. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- isTransformInlineBindValuesForFieldComparisons: Transform QOM.CompareCondition and a few other
  types of condition to inline their bind values, in case they match Historically, prior to ANSI
  join syntax, joins were implemented by listing tables in the FROM clause and providing join
  predicates in the WHERE clause, possibly using vendor specific operators like (+) (Oracle, DB2) or
  *= (SQL Server) for outer join support. For backwards compatibility with older RDBMS versions,
  ANSI joins in jOOQ code may be converted to equivalent table lists in generated SQL using this
  flag. This flag has a limited implementation that supports inner joins (in most cases) and outer
  joins (only for simple comparison predicates). This feature is available in the commercial
  distribution only.
- setTransformInlineBindValuesForFieldComparisons: Transform QOM.CompareCondition and a few other
  types of condition to inline their bind values, in case they match Historically, prior to ANSI
  join syntax, joins were implemented by listing tables in the FROM clause and providing join
  predicates in the WHERE clause, possibly using vendor specific operators like (+) (Oracle, DB2) or
  *= (SQL Server) for outer join support. For backwards compatibility with older RDBMS versions,
  ANSI joins in jOOQ code may be converted to equivalent table lists in generated SQL using this
  flag. This flag has a limited implementation that supports inner joins (in most cases) and outer
  joins (only for simple comparison predicates). This feature is available in the commercial
  distribution only.
- isTransformAnsiJoinToTableLists: Transform ANSI join to table lists if possible. Historically,
  prior to ANSI join syntax, joins were implemented by listing tables in the FROM clause and
  providing join predicates in the WHERE clause, possibly using vendor specific operators like (+)
  (Oracle, DB2) or *= (SQL Server) for outer join support. For backwards compatibility with older
  RDBMS versions, ANSI joins in jOOQ code may be converted to equivalent table lists in generated
  SQL using this flag. This flag has a limited implementation that supports inner joins (in most
  cases) and outer joins (only for simple comparison predicates). This feature is available in the
  commercial distribution only.
- setTransformAnsiJoinToTableLists: Transform ANSI join to table lists if possible. Historically,
  prior to ANSI join syntax, joins were implemented by listing tables in the FROM clause and
  providing join predicates in the WHERE clause, possibly using vendor specific operators like (+)
  (Oracle, DB2) or *= (SQL Server) for outer join support. For backwards compatibility with older
  RDBMS versions, ANSI joins in jOOQ code may be converted to equivalent table lists in generated
  SQL using this flag. This flag has a limited implementation that supports inner joins (in most
  cases) and outer joins (only for simple comparison predicates). This feature is available in the
  commercial distribution only.
- getTransformInConditionSubqueryWithLimitToDerivedTable: Transform a subquery from an IN condition
  with LIMIT to an equivalent derived table. This transformation works around a known MySQL
  limitation "ERROR 1235 (42000): This version of MySQL doesn't yet support 'LIMIT Ungültige
  Eingabe: "&" IN/ALL/ANY/SOME subquery'" This feature is available in the commercial distribution
  only.
- setTransformInConditionSubqueryWithLimitToDerivedTable: Transform a subquery from an IN condition
  with LIMIT to an equivalent derived table. This transformation works around a known MySQL
  limitation "ERROR 1235 (42000): This version of MySQL doesn't yet support 'LIMIT Ungültige
  Eingabe: "&" IN/ALL/ANY/SOME subquery'" This feature is available in the commercial distribution
  only.
- getTransformQualify: Transform the QUALIFY clause to an equivalent derived table to filter on
  window functions. This feature is available in the commercial distribution only.
- setTransformQualify: Transform the QUALIFY clause to an equivalent derived table to filter on
  window functions. This feature is available in the commercial distribution only.
- isTransformTableListsToAnsiJoin: Transform table lists to ANSI join if possible. (Very)
  historically, prior to ANSI join syntax, joins were implemented by listing tables in the FROM
  clause and providing join predicates in the WHERE clause, possibly using vendor specific operators
  like (+) (Oracle, DB2) or *= (SQL Server) for outer join support. Migrating such join syntax is
  tedious. The jOOQ parser can parse the old syntax and this flag enables the transformation to ANSI
  join syntax. This feature is available in the commercial distribution only.
- setTransformTableListsToAnsiJoin: Transform table lists to ANSI join if possible. (Very)
  historically, prior to ANSI join syntax, joins were implemented by listing tables in the FROM
  clause and providing join predicates in the WHERE clause, possibly using vendor specific operators
  like (+) (Oracle, DB2) or *= (SQL Server) for outer join support. Migrating such join syntax is
  tedious. The jOOQ parser can parse the old syntax and this flag enables the transformation to ANSI
  join syntax. This feature is available in the commercial distribution only.
- getTransformRownum: Transform ROWNUM expressions to corresponding LIMIT clauses or ROW_NUMBER()
  expressions. In Oracle 11g and less, ROWNUM filtering was the most popular way to paginate. This
  pseudo column is not supported in other RDBMS, and should be replaced in Oracle 12c by the FETCH
  clause or ROW_NUMBER() OVER () filtering. This transformation allows for replacing such a filter
  by equivalent SQL, if possible. This feature is available in the commercial distribution only.
- setTransformRownum: Transform ROWNUM expressions to corresponding LIMIT clauses or ROW_NUMBER()
  expressions. In Oracle 11g and less, ROWNUM filtering was the most popular way to paginate. This
  pseudo column is not supported in other RDBMS, and should be replaced in Oracle 12c by the FETCH
  clause or ROW_NUMBER() OVER () filtering. This transformation allows for replacing such a filter
  by equivalent SQL, if possible. This feature is available in the commercial distribution only.
- getTransformUnneededArithmeticExpressions: Transform arithmetic expressions on literals and bind
  variables. Arithmetic expressions may be implemented by the user, or arise from emulations from
  within jOOQ. Expressions on literals and bind variables could be evaluated in the client prior to
  generating SQL. This feature is available in the commercial distribution only.
- setTransformUnneededArithmeticExpressions: Transform arithmetic expressions on literals and bind
  variables. Arithmetic expressions may be implemented by the user, or arise from emulations from
  within jOOQ. Expressions on literals and bind variables could be evaluated in the client prior to
  generating SQL. This feature is available in the commercial distribution only.
- getTransformGroupByColumnIndex: Transform GROUP BY [column index] clauses by substituting the
  column index. Not all dialects support grouping by column index, which is a convenient but also a
  bit confusing feature of some dialects. jOOQ can transform the syntax into an equivalent syntax
  where the referenced SELECT expression is duplicated into the GROUP BY clause. This feature is
  available in the commercial distribution only.
- setTransformGroupByColumnIndex: Transform GROUP BY [column index] clauses by substituting the
  column index. Not all dialects support grouping by column index, which is a convenient but also a
  bit confusing feature of some dialects. jOOQ can transform the syntax into an equivalent syntax
  where the referenced SELECT expression is duplicated into the GROUP BY clause. This feature is
  available in the commercial distribution only.
- getTransformInlineCTE: Transform Common Table Expressions (CTE) by inlining their WITH clause
  definition to wherever they're referenced. Non-recursive CTE are just syntax sugar for inline
  views (derived tables). When they're not supported natively, jOOQ can simply inline their
  definition to wherever they're referenced. This feature is available in the commercial
  distribution only.
- setTransformInlineCTE: Transform Common Table Expressions (CTE) by inlining their WITH clause
  definition to wherever they're referenced. Non-recursive CTE are just syntax sugar for inline
  views (derived tables). When they're not supported natively, jOOQ can simply inline their
  definition to wherever they're referenced. This feature is available in the commercial
  distribution only.
- getBackslashEscaping: Whether string literals should be escaped with backslash.
- setBackslashEscaping: Whether string literals should be escaped with backslash.
- getParamType: Specify how bind variables are to be rendered. Possibilities include: - question
  marks - named parameters - named or inlined parameters - inlined parameters This value is
  overridden by statementType == STATIC_STATEMENT, in case of which, this defaults to INLINED
- setParamType: Specify how bind variables are to be rendered. Possibilities include: - question
  marks - named parameters - named or inlined parameters - inlined parameters This value is
  overridden by statementType == STATIC_STATEMENT, in case of which, this defaults to INLINED
- getParamCastMode: Whether rendered bind values should be cast to their respective type.
- setParamCastMode: Whether rendered bind values should be cast to their respective type.
- getStatementType: The type of statement that is to be executed.
- setStatementType: The type of statement that is to be executed.
- getInlineThreshold org.jooq.SQLDialect#ACCESS: The maximum number of allowed bind variables before
  inlining all values where 0 uses the dialect defaults: Ungültige Referenz
  org.jooq.SQLDialect#ACCESS : 768 Ungültige Referenz org.jooq.SQLDialect#ASE : 2000 Ungültige
  Referenz org.jooq.SQLDialect#DATABRICKS : 256 Ungültige Referenz org.jooq.SQLDialect#INGRES : 1024
  Ungültige Referenz org.jooq.SQLDialect#ORACLE : 32767 SQLDialect.POSTGRES : 32767
  SQLDialect.SQLITE : 999 Ungültige Referenz org.jooq.SQLDialect#SQLSERVER : 2100 Ungültige Referenz
  org.jooq.SQLDialect#TERADATA : 2536
- setInlineThreshold org.jooq.SQLDialect#ACCESS: The maximum number of allowed bind variables before
  inlining all values where 0 uses the dialect defaults: Ungültige Referenz
  org.jooq.SQLDialect#ACCESS : 768 Ungültige Referenz org.jooq.SQLDialect#ASE : 2000 Ungültige
  Referenz org.jooq.SQLDialect#DATABRICKS : 256 Ungültige Referenz org.jooq.SQLDialect#INGRES : 1024
  Ungültige Referenz org.jooq.SQLDialect#ORACLE : 32767 SQLDialect.POSTGRES : 32767
  SQLDialect.SQLITE : 999 Ungültige Referenz org.jooq.SQLDialect#SQLSERVER : 2100 Ungültige Referenz
  org.jooq.SQLDialect#TERADATA : 2536
- getTransactionListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered TransactionListeners.
- setTransactionListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered TransactionListeners.
- getTransactionListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered TransactionListeners.
- setTransactionListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered TransactionListeners.
- getMigrationListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered MigrationListeners.
- setMigrationListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered MigrationListeners.
- getMigrationListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered MigrationListeners.
- setMigrationListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered MigrationListeners.
- getVisitListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered VisitListeners.
- setVisitListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered VisitListeners.
- getVisitListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  VisitListeners.
- setVisitListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  VisitListeners.
- getRecordListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered RecordListeners.
- setRecordListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered RecordListeners.
- getRecordListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  RecordListeners.
- setRecordListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  RecordListeners.
- getExecuteListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered ExecuteListeners.
- setExecuteListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered ExecuteListeners.
- getExecuteListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  ExecuteListeners.
- setExecuteListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  ExecuteListeners.
- isExecuteLogging: When set to true, this will add jOOQ's default LoggerListener for debug logging.
  This is meant for use in development only.
- setExecuteLogging: When set to true, this will add jOOQ's default LoggerListener for debug
  logging. This is meant for use in development only.
- isExecuteLoggingSQLExceptions: [#14420] Whether constraint violations and other SQLException
  should produce additional log information about the column name and data causing the problem.
  Unlike executeLogging, this is meant for use in production as well as development. This feature is
  available only in commercial distributions.
- setExecuteLoggingSQLExceptions: [#14420] Whether constraint violations and other SQLException
  should produce additional log information about the column name and data causing the problem.
  Unlike executeLogging, this is meant for use in production as well as development. This feature is
  available only in commercial distributions.
- isDiagnosticsLogging: When set to true, this will add jOOQ's default logging DiagnosticsListeners.
- setDiagnosticsLogging: When set to true, this will add jOOQ's default logging
  DiagnosticsListeners.
- getDiagnosticsConnection: Whether to activate the DiagnosticsConnection, explicit by DEFAULT,
  implicit if ON, or turned OFF entirely.
- setDiagnosticsConnection: Whether to activate the DiagnosticsConnection, explicit by DEFAULT,
  implicit if ON, or turned OFF entirely.
- isUpdateRecordVersion: Whether store(), insert(), and update() methods should update the record
  version prior to the operation, for use with executeWithOptimisticLocking.
- setUpdateRecordVersion: Whether store(), insert(), and update() methods should update the record
  version prior to the operation, for use with executeWithOptimisticLocking.
- isUpdateRecordTimestamp: Whether store(), insert(), and update() methods should update the record
  timestamp prior to the operation, for use with executeWithOptimisticLocking.
- setUpdateRecordTimestamp: Whether store(), insert(), and update() methods should update the record
  timestamp prior to the operation, for use with executeWithOptimisticLocking.
- isExecuteWithOptimisticLocking: Whether store() and delete() methods should be executed with
  optimistic locking.
- setExecuteWithOptimisticLocking: Whether store() and delete() methods should be executed with
  optimistic locking.
- isExecuteWithOptimisticLockingExcludeUnversioned: Whether store() and delete() methods should be
  executed with optimistic locking also on "unversioned" tables, i.e. on tables that do not have a
  version and/or timestamp column. This flag has no effect when "executeWithOptimisticLocking" is
  turned off.
- setExecuteWithOptimisticLockingExcludeUnversioned: Whether store() and delete() methods should be
  executed with optimistic locking also on "unversioned" tables, i.e. on tables that do not have a
  version and/or timestamp column. This flag has no effect when "executeWithOptimisticLocking" is
  turned off.
- isAttachRecords: Whether fetched records should be attached to the fetching configuration.
- setAttachRecords: Whether fetched records should be attached to the fetching configuration.
- isInsertUnchangedRecords: Whether TableRecord.insert() calls should be executed if the record is
  unchanged. This also affects the INSERT part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- setInsertUnchangedRecords: Whether TableRecord.insert() calls should be executed if the record is
  unchanged. This also affects the INSERT part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- getUpdateUnchangedRecords: Whether UpdatableRecord.update() calls should be executed if the record
  is unchanged. This also affects the UPDATE part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- setUpdateUnchangedRecords: Whether UpdatableRecord.update() calls should be executed if the record
  is unchanged. This also affects the UPDATE part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- getRecordDirtyTracking: Whether UpdatableRecord.store() and related calls should be based on
  Record.touched() or Record.modified() semantics. This also affects copying records into explicit
  statements.
- setRecordDirtyTracking: Whether UpdatableRecord.store() and related calls should be based on
  Record.touched() or Record.modified() semantics. This also affects copying records into explicit
  statements.
- isUpdatablePrimaryKeys: Whether primary key values are deemed to be "updatable" in jOOQ. Setting
  this to "true" will allow for updating primary key values through UpdatableRecord.store() and
  UpdatableRecord.update().
- setUpdatablePrimaryKeys: Whether primary key values are deemed to be "updatable" in jOOQ. Setting
  this to "true" will allow for updating primary key values through UpdatableRecord.store() and
  UpdatableRecord.update().
- isReflectionCaching: Whether reflection information should be cached in the configuration.
- setReflectionCaching: Whether reflection information should be cached in the configuration.
- isCacheRecordMappers: Whether record mappers should be cached in the configuration.
- setCacheRecordMappers: Whether record mappers should be cached in the configuration.
- isCacheParsingConnection: Whether parsing connection translations should be cached in the
  configuration.
- setCacheParsingConnection: Whether parsing connection translations should be cached in the
  configuration.
- getCacheParsingConnectionLRUCacheSize: The default value of the ParsingConnection cache's LRU
  cache size.
- setCacheParsingConnectionLRUCacheSize: The default value of the ParsingConnection cache's LRU
  cache size.
- getCacheRecordMappersLRUCacheSize: The default value of the RecordMapper cache's LRU cache size.
- setCacheRecordMappersLRUCacheSize: The default value of the RecordMapper cache's LRU cache size.
- getReflectionCacheLRUCacheSize: The default value of the reflection cache's LRU cache size.
- setReflectionCacheLRUCacheSize: The default value of the reflection cache's LRU cache size.
- isCachePreparedStatementInLoader: Whether JDBC PreparedStatement instances should be cached in
  loader API.
- setCachePreparedStatementInLoader: Whether JDBC PreparedStatement instances should be cached in
  loader API.
- getThrowExceptions: A strategy defining how exceptions from the database / JDBC driver should be
  propagated
- setThrowExceptions: A strategy defining how exceptions from the database / JDBC driver should be
  propagated
- isFetchWarnings: Whether warnings should be fetched after each query execution.
- setFetchWarnings: Whether warnings should be fetched after each query execution.
- getFetchServerOutputSize: Whether server output should be fetched after each query execution.
- setFetchServerOutputSize: Whether server output should be fetched after each query execution.
- isReturnIdentityOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  the identity column.
- setReturnIdentityOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  the identity column.
- isReturnDefaultOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.defaulted().
- setReturnDefaultOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.defaulted().
- isReturnComputedOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.computed().
- setReturnComputedOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.computed().
- isReturnAllOnUpdatableRecord: Whether calls to store(), insert() and update() should return all
  columns, not just identity columns. Do note that only few databases support this feature. It is
  supported only in case the INSERT's or UPDATE's RETURNING clause is fully supported, also for non-
  IDENTITY columns.
- setReturnAllOnUpdatableRecord: Whether calls to store(), insert() and update() should return all
  columns, not just identity columns. Do note that only few databases support this feature. It is
  supported only in case the INSERT's or UPDATE's RETURNING clause is fully supported, also for non-
  IDENTITY columns.
- isReturnRecordToPojo: Whether calls to store(), insert(), update(), and delete() that are called
  on an UpdatableRecord that is created from a POJO (e.g. in a DAO) should return all Record values
  to the POJO, including IDENTITY values, and if returnAllOnUpdatableRecord is active, also other
  values.
- setReturnRecordToPojo: Whether calls to store(), insert(), update(), and delete() that are called
  on an UpdatableRecord that is created from a POJO (e.g. in a DAO) should return all Record values
  to the POJO, including IDENTITY values, and if returnAllOnUpdatableRecord is active, also other
  values.
- isMapJPAAnnotations: Whether JPA annotations should be considered by the DefaultRecordMapper,
  assuming the jOOQ-jpa-extensions is on the classpath.
- setMapJPAAnnotations: Whether JPA annotations should be considered by the DefaultRecordMapper,
  assuming the jOOQ-jpa-extensions is on the classpath.
- isMapRecordComponentParameterNames: Whether constructor parameter names obtained from the Record
  component names should be considered by the DefaultRecordMapper.
- setMapRecordComponentParameterNames: Whether constructor parameter names obtained from the Record
  component names should be considered by the DefaultRecordMapper.
- isMapConstructorPropertiesParameterNames: Whether constructor parameter names obtained from the
  ConstructorPropertiesProvider SPI (default implementation in the jOOQ-beans-extensions module)
  should be considered by the DefaultRecordMapper.
- setMapConstructorPropertiesParameterNames: Whether constructor parameter names obtained from the
  ConstructorPropertiesProvider SPI (default implementation in the jOOQ-beans-extensions module)
  should be considered by the DefaultRecordMapper.
- isMapConstructorParameterNames: Whether constructor parameter names obtained via reflection in
  Java 8+ should be considered by the DefaultRecordMapper. This flag has no effect in Java 6 or 7.
- setMapConstructorParameterNames: Whether constructor parameter names obtained via reflection in
  Java 8+ should be considered by the DefaultRecordMapper. This flag has no effect in Java 6 or 7.
- isMapConstructorParameterNamesInKotlin: Whether constructor parameter names obtained via
  reflection in Kotlin should be considered by the DefaultRecordMapper. This flag has no effect in
  Java.
- setMapConstructorParameterNamesInKotlin: Whether constructor parameter names obtained via
  reflection in Kotlin should be considered by the DefaultRecordMapper. This flag has no effect in
  Java.
- getQueryPoolable: The default JDBC poolable property that should be applied to all jOOQ queries,
  for which no specific poolable flag was specified.
- setQueryPoolable: The default JDBC poolable property that should be applied to all jOOQ queries,
  for which no specific poolable flag was specified.
- getQueryTimeout: The default JDBC queryTimeout property that should be applied to all jOOQ
  queries, for which no specific queryTimeout was specified.
- setQueryTimeout: The default JDBC queryTimeout property that should be applied to all jOOQ
  queries, for which no specific queryTimeout was specified.
- getMaxRows: The default JDBC maxRows property that should be applied to all jOOQ queries, for
  which no specific maxRows value was specified.
- setMaxRows: The default JDBC maxRows property that should be applied to all jOOQ queries, for
  which no specific maxRows value was specified.
- getFetchSize: The default JDBC fetchSize property that should be applied to all jOOQ queries, for
  which no specific fetchSize value was specified.
- setFetchSize: The default JDBC fetchSize property that should be applied to all jOOQ queries, for
  which no specific fetchSize value was specified.
- getBatchSize: A property specifying a batch size that should be applied to all automatically
  created BatchedConnection instances.
- setBatchSize: A property specifying a batch size that should be applied to all automatically
  created BatchedConnection instances.
- isDebugInfoOnStackTrace: [#5570] Whether exception stack traces should be enhanced with additional
  debug information.
- setDebugInfoOnStackTrace: [#5570] Whether exception stack traces should be enhanced with
  additional debug information.
- isInListPadding: [#5600] Whether IN lists in IN predicates should be padded to powers of
  inListPadBase (default 2).
- setInListPadding: [#5600] Whether IN lists in IN predicates should be padded to powers of
  inListPadBase (default 2).
- getInListPadBase: [#7095] The base to use to calculate the powers of when applying in list
  padding.
- setInListPadBase: [#7095] The base to use to calculate the powers of when applying in list
  padding.
- getDelimiter: [#5826] The delimiter character to be used to delimit statements in batches.
- setDelimiter: [#5826] The delimiter character to be used to delimit statements in batches.
- isEmulateOnDuplicateKeyUpdateOnPrimaryKeyOnly: [#6462] Use only the primary key to emulate MySQL's
  INSERT .. ON DUPLICATE KEY UPDATE statement. In MySQL, the statement considers all unique keys for
  duplicates to apply an update rather than an insert. Earlier versions of jOOQ considered only the
  PRIMARY KEY. This flag can be turned on to maintain backwards compatibility.
- setEmulateOnDuplicateKeyUpdateOnPrimaryKeyOnly: [#6462] Use only the primary key to emulate
  MySQL's INSERT .. ON DUPLICATE KEY UPDATE statement. In MySQL, the statement considers all unique
  keys for duplicates to apply an update rather than an insert. Earlier versions of jOOQ considered
  only the PRIMARY KEY. This flag can be turned on to maintain backwards compatibility.
- getEmulateMultiset: [#3884] How MULTISET support should be emulated.
- setEmulateMultiset: [#3884] How MULTISET support should be emulated.
- isEmulateNestedRecordProjectionsUsingMultisetEmulation: [#13598] Whether nested record projections
  at the top level should be emulated using the MULTISET emulation rather than the flattening
  emulation, if supported by the dialect.
- setEmulateNestedRecordProjectionsUsingMultisetEmulation: [#13598] Whether nested record
  projections at the top level should be emulated using the MULTISET emulation rather than the
  flattening emulation, if supported by the dialect.
- isEmulateComputedColumns: [#13418] Whether computed columns should be emulated in the client. This
  can be useful if a schema was generated using a dialect that supports computed columns, but it is
  deployed on an RDBMS that does not.
- setEmulateComputedColumns: [#13418] Whether computed columns should be emulated in the client.
  This can be useful if a schema was generated using a dialect that supports computed columns, but
  it is deployed on an RDBMS that does not.
- isComputedOnClientVirtual: Whether VIRTUAL client side computed columns should be applied to
  queries. This feature is available only in commercial distributions.
- setComputedOnClientVirtual: Whether VIRTUAL client side computed columns should be applied to
  queries. This feature is available only in commercial distributions.
- isComputedOnClientStored: Whether STORED client side computed columns should be applied to queries
  (including audit columns). This feature is available only in commercial distributions.
- setComputedOnClientStored: Whether STORED client side computed columns should be applied to
  queries (including audit columns). This feature is available only in commercial distributions.
- getExecuteUpdateWithoutWhere: [#6771] Specifies whether UPDATE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- setExecuteUpdateWithoutWhere: [#6771] Specifies whether UPDATE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- getExecuteDeleteWithoutWhere: [#6771] Specifies whether DELETE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- setExecuteDeleteWithoutWhere: [#6771] Specifies whether DELETE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- getInterpreterDialect: [#7337] The dialect that should be used to interpret SQL DDL statements.
  SQLDialect.DEFAULT means that jOOQ interprets the SQL itself. Any other dialect (if supported)
  will be interpreted on an actual JDBC connection.
- setInterpreterDialect: [#7337] The dialect that should be used to interpret SQL DDL statements.
  SQLDialect.DEFAULT means that jOOQ interprets the SQL itself. Any other dialect (if supported)
  will be interpreted on an actual JDBC connection.
- getInterpreterNameLookupCaseSensitivity: [#9633] The case sensitivity of identifiers used when
  interpreting SQL DDL statements.
- setInterpreterNameLookupCaseSensitivity: [#9633] The case sensitivity of identifiers used when
  interpreting SQL DDL statements.
- getInterpreterLocale: The Locale to be used with any interpreter locale dependent logic,
  defaulting to getLocale().
- setInterpreterLocale: The Locale to be used with any interpreter locale dependent logic,
  defaulting to getLocale().
- isInterpreterDelayForeignKeyDeclarations: Using this flag, the interpreter will be able to delay
  the addition of foreign key declarations until the end of the interpretation run.
- setInterpreterDelayForeignKeyDeclarations: Using this flag, the interpreter will be able to delay
  the addition of foreign key declarations until the end of the interpretation run.
- isMetaIncludeSystemIndexes: The Meta implementation that is backed by DatabaseMetaData does not
  produce system generated indexes on constraints, by default.
- setMetaIncludeSystemIndexes: The Meta implementation that is backed by DatabaseMetaData does not
  produce system generated indexes on constraints, by default.
- isMetaIncludeSystemSequences: The Meta implementation that is backed by DatabaseMetaData does not
  produce system generated sequences, by default.
- setMetaIncludeSystemSequences: The Meta implementation that is backed by DatabaseMetaData does not
  produce system generated sequences, by default.
- getMigrationHistorySchema: The database schema where the migration history is located.
- setMigrationHistorySchema: The database schema where the migration history is located.
- isMigrationHistorySchemaCreateSchemaIfNotExists: Whether getMigrationHistorySchema() should be
  created if it doesn't exist.
- setMigrationHistorySchemaCreateSchemaIfNotExists: Whether getMigrationHistorySchema() should be
  created if it doesn't exist.
- getMigrationDefaultSchema: The default schema whose unqualified objects that are included in the
  migration.
- setMigrationDefaultSchema: The default schema whose unqualified objects that are included in the
  migration.
- isMigrationSchemataCreateSchemaIfNotExists: Whether getMigrationSchemata() should be created if
  they don't exist.
- setMigrationSchemataCreateSchemaIfNotExists: Whether getMigrationSchemata() should be created if
  they don't exist.
- getMigrationDefaultContentType: The default ContentType that is used when loading migrations.
- setMigrationDefaultContentType: The default ContentType that is used when loading migrations.
- isMigrationAllowUndo: Whether migrations are allowed to be executed in inverse order.This is a
  potentially destructive feature, which should not be turned on in production. It is useful mostly
  to quickly switch between branches in a development environment. This feature is available only in
  commercial distributions.
- setMigrationAllowUndo: Whether migrations are allowed to be executed in inverse order.This is a
  potentially destructive feature, which should not be turned on in production. It is useful mostly
  to quickly switch between branches in a development environment. This feature is available only in
  commercial distributions.
- isMigrationAllowInvalidCommits: Whether migrations to invalid commits (Commit.valid()) are
  allowed.This is a potentially destructive feature, which should not be turned on in production. It
  is useful mostly to quickly test uncommited or inconsistent changes in development.
- setMigrationAllowInvalidCommits: Whether migrations to invalid commits (Commit.valid()) are
  allowed.This is a potentially destructive feature, which should not be turned on in production. It
  is useful mostly to quickly test uncommited or inconsistent changes in development.
- isMigrationRevertUntracked: Whether migrations revert any untracked changes in the schemas that
  are being migrated.This is a potentially destructive feature, which should not be turned on in
  production. It is useful mostly to quickly revert any elements created in a development
  environment. This feature is available only in commercial distributions.
- setMigrationRevertUntracked: Whether migrations revert any untracked changes in the schemas that
  are being migrated.This is a potentially destructive feature, which should not be turned on in
  production. It is useful mostly to quickly revert any elements created in a development
  environment. This feature is available only in commercial distributions.
- isMigrationAutoBaseline: Whether to automatically existing schemas that are not yet managed by
  jOOQ Migrations.
- setMigrationAutoBaseline: Whether to automatically existing schemas that are not yet managed by
  jOOQ Migrations.
- isMigrationAutoVerification: Whether a migration automatically runs a verification first.
- setMigrationAutoVerification: Whether a migration automatically runs a verification first.
- isMigrationIgnoreDefaultTimestampPrecisionDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between TIMESTAMP and TIMESTAMP(6), if 6 is
  the default precision for timestamps on the configured dialect.
- setMigrationIgnoreDefaultTimestampPrecisionDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between TIMESTAMP and TIMESTAMP(6), if 6 is
  the default precision for timestamps on the configured dialect.
- isMigrationIgnoreUnnamedConstraintDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between (possibly synthetically) name
  constraints and unnamed constraints, if the structure of the constraint is the same.
- setMigrationIgnoreUnnamedConstraintDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between (possibly synthetically) name
  constraints and unnamed constraints, if the structure of the constraint is the same.
- isMigrationIgnoreImplicitPrimaryKeyNotNullConstraints: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the presence or absence of implicit NOT NULL constraints on
  PRIMARY KEY columns if the constraint is really implicit for a given dialect. This flag allows for
  overriding this behaviour.
- setMigrationIgnoreImplicitPrimaryKeyNotNullConstraints: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the presence or absence of implicit NOT NULL constraints on
  PRIMARY KEY columns if the constraint is really implicit for a given dialect. This flag allows for
  overriding this behaviour.
- getLocale: The Locale to be used with any locale dependent logic if there is not a more specific
  locale available. More specific locales include e.g. getRenderLocale(), getParseLocale(), or
  getInterpreterLocale().
- setLocale: The Locale to be used with any locale dependent logic if there is not a more specific
  locale available. More specific locales include e.g. getRenderLocale(), getParseLocale(), or
  getInterpreterLocale().
- getParseDialect: [#7337] The input dialect that should be chosen to disambiguate ambiguous SQL
  syntax.
- setParseDialect: [#7337] The input dialect that should be chosen to disambiguate ambiguous SQL
  syntax.
- getParseLocale: The Locale to be used with any parser locale dependent logic, defaulting to
  getLocale().
- setParseLocale: The Locale to be used with any parser locale dependent logic, defaulting to
  getLocale().
- getParseDateFormat: The date format to use when parsing functions whose behaviour depends on some
  session date format, such as NLS_DATE_FORMAT in Oracle
- setParseDateFormat: The date format to use when parsing functions whose behaviour depends on some
  session date format, such as NLS_DATE_FORMAT in Oracle
- getParseTimestampFormat: The timestamp format to use when parsing functions whose behaviour
  depends on some session date format, such as NLS_TIMESTAMP_FORMAT in Oracle
- setParseTimestampFormat: The timestamp format to use when parsing functions whose behaviour
  depends on some session date format, such as NLS_TIMESTAMP_FORMAT in Oracle
- getParseNamedParamPrefix: The prefix to use for named parameters in parsed SQL. Named parameter
  syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name when parsing SQL. "Named
  indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- setParseNamedParamPrefix: The prefix to use for named parameters in parsed SQL. Named parameter
  syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name when parsing SQL. "Named
  indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- getParseNameCase: [#7337] The default name case for parsed identifiers.
- setParseNameCase: [#7337] The default name case for parsed identifiers.
- getParseWithMetaLookups: [#7163] Whether the parser should perform meta lookups in the
  Configuration's MetaProvider.
- setParseWithMetaLookups: [#7163] Whether the parser should perform meta lookups in the
  Configuration's MetaProvider.
- getParseAppendMissingTableReferences: Transform the parsed SQL to append missing table references
  to the query's FROM or USING clause, if applicable. Teradata (and possibly others) allow for
  referencing tables that are not listed in the FROM clause, such as SELECT t.* FROM t WHERE t.i =
  u.i. This transformation is executed in the parser, to produce SELECT t.* FROM t, u WHERE t.i =
  u.i, instead. By default, it is active when the input dialect supports this syntax. This feature
  is available in the commercial distribution only.
- setParseAppendMissingTableReferences: Transform the parsed SQL to append missing table references
  to the query's FROM or USING clause, if applicable. Teradata (and possibly others) allow for
  referencing tables that are not listed in the FROM clause, such as SELECT t.* FROM t WHERE t.i =
  u.i. This transformation is executed in the parser, to produce SELECT t.* FROM t, u WHERE t.i =
  u.i, instead. By default, it is active when the input dialect supports this syntax. This feature
  is available in the commercial distribution only.
- isParseSetCommands: [#9780] Whether commands of the type SET key = value should be parsed rather
  than ignored.
- setParseSetCommands: [#9780] Whether commands of the type SET key = value should be parsed rather
  than ignored.
- getParseUnsupportedSyntax: [#5917] Whether the parser should accept unsupported (but known)
  syntax.
- setParseUnsupportedSyntax: [#5917] Whether the parser should accept unsupported (but known)
  syntax.
- getParseUnknownFunctions: [#7344] Whether the parser should accept unknown functions.
- setParseUnknownFunctions: [#7344] Whether the parser should accept unknown functions.
- isParseIgnoreCommercialOnlyFeatures: [#13109] Whether the parser of the jOOQ Open Source Edition
  should ignore commercial only features, rather than failing.
- setParseIgnoreCommercialOnlyFeatures: [#13109] Whether the parser of the jOOQ Open Source Edition
  should ignore commercial only features, rather than failing.
- isParseIgnoreComments: [#8325] Whether the parser should ignore content between ignore comment
  tokens.
- setParseIgnoreComments: [#8325] Whether the parser should ignore content between ignore comment
  tokens.
- getParseIgnoreCommentStart: [#8325] The ignore comment start token
- setParseIgnoreCommentStart: [#8325] The ignore comment start token
- getParseIgnoreCommentStop: [#8325] The ignore comment stop token
- setParseIgnoreCommentStop: [#8325] The ignore comment stop token
- isParseRetainCommentsBetweenQueries: [#12538] Whether the parser should retain comments and
  whitespace between queries when parsing multiple queries through Parser.parse(String). jOOQ's
  query object model doesn't have a way to represent comments or other whitespace, and as such, the
  parser simply skips them by default. However, it may be desirable to retain comments before or in
  between top level queries, when parsing multiple such queries in a script. Comments inside of
  queries (including procedural statements) are still not supported.
- setParseRetainCommentsBetweenQueries: [#12538] Whether the parser should retain comments and
  whitespace between queries when parsing multiple queries through Parser.parse(String). jOOQ's
  query object model doesn't have a way to represent comments or other whitespace, and as such, the
  parser simply skips them by default. However, it may be desirable to retain comments before or in
  between top level queries, when parsing multiple such queries in a script. Comments inside of
  queries (including procedural statements) are still not supported.
- isParseMetaDefaultExpressions: [#8469] Whether to parse default expressions retrieved from
  DatabaseMetaData.
- setParseMetaDefaultExpressions: [#8469] Whether to parse default expressions retrieved from
  DatabaseMetaData.
- isParseMetaViewSources: [#8469] Whether to parse view sources retrieved from DatabaseMetaData.
- setParseMetaViewSources: [#8469] Whether to parse view sources retrieved from DatabaseMetaData.
- getReadonlyTableRecordInsert: [#9864] The behaviour when trying to insert into readonly columns
  using TableRecord.insert().
- setReadonlyTableRecordInsert: [#9864] The behaviour when trying to insert into readonly columns
  using TableRecord.insert().
- getReadonlyUpdatableRecordUpdate: [#9864] The behaviour when trying to update a readonly column
  using UpdatableRecord.update().
- setReadonlyUpdatableRecordUpdate: [#9864] The behaviour when trying to update a readonly column
  using UpdatableRecord.update().
- getReadonlyInsert: [#9864] The behaviour when trying to insert into readonly columns using Insert
  statements, or the insert clause of a Merge statement.
- setReadonlyInsert: [#9864] The behaviour when trying to insert into readonly columns using Insert
  statements, or the insert clause of a Merge statement.
- getReadonlyUpdate: [#9864] The behaviour when trying to update a readonly column using Update
  statements, or the update clause of a Merge statement.
- setReadonlyUpdate: [#9864] The behaviour when trying to update a readonly column using Update
  statements, or the update clause of a Merge statement.
- isApplyWorkaroundFor7962: [#7963] Apply workaround for ORA-04043 when inserting into Oracle tables
  with qualified, quoted identifiers, and fetching generated keys
- setApplyWorkaroundFor7962: [#7963] Apply workaround for ORA-04043 when inserting into Oracle
  tables with qualified, quoted identifiers, and fetching generated keys
- getWarnOnStaticTypeRegistryAccess: [#15286] The warning level when the deprecated static type
  registry was accessed by legacy code.
- setWarnOnStaticTypeRegistryAccess: [#15286] The warning level when the deprecated static type
  registry was accessed by legacy code.
- getInterpreterSearchPath:
- setInterpreterSearchPath:
- getMigrationSchemata:
- setMigrationSchemata:
- getParseSearchPath:
- setParseSearchPath:
- withForceIntegerTypesOnZeroScaleDecimals: Historically, zero-scale decimal types are generated as
  their most appropriate, corresponding integer type (e.g. NUMBER(2, 0) and less: Byte). The same
  behaviour is replicated in the Meta API. This flag allows for turning off this feature.
- withRenderCatalog: Whether any catalog name should be rendered at all. Use this for single-catalog
  environments, or when all objects are made available using synonyms
- withRenderSchema: Whether any schema name should be rendered at all. Setting this to false also
  implicitly sets "renderCatalog" to false. Use this for single-schema environments, or when all
  objects are made available using synonyms
- withRenderTable: Whether any table name qualification should be rendered at all on columns.
  Setting when tables aren't rendered, then implicitly, schemas and catalogs aren't rendered either.
  The following values are available: RenderTable.ALWAYS: The default, which should always be
  preferred. Columns are always qualified with their tables, where possible.
  RenderTable.WHEN_MULTIPLE_TABLES: The simplest option to reduce generated query verbosity,
  avoiding table qualification only in queries with a single table in the FROM clause.
  RenderTable.WHEN_AMBIGUOUS_COLUMNS: A much more expensive to compute option that checks the FROM
  clause for ambiguous column names, in case of which columns are qualified. RenderTable.NEVER:
  Always turn off table qualification. Use this when verbosity of rendered SQL is a problem.
- withRenderMapping: Configure render mapping for runtime schema / table rewriting in generated SQL.
- withRenderQuotedNames: Whether rendered schema, table, column names, etc should be quoted. This
  only affects names created through DSL.name(String) methods (including those that are implicitly
  created through this method), not DSL.quotedName(String) or DSL.unquotedName(String), whose
  behaviour cannot be overridden. This setting does not affect any plain SQL usage.
- withRenderNameCase: Whether the case of Name references should be modified in any way. Names are
  modified irrespective of the getRenderQuotedNames() setting. This setting does not affect any
  plain SQL usage.
- withRenderNameStyle: Whether rendered schema, table, column names, etc should be quoted in
  rendered SQL, or transformed in any other way. This is set to "QUOTED" by default for backwards-
  compatibility.
- withRenderNamedParamPrefix: The prefix to use for named parameters in generated SQL. Named
  parameter syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name, when generating SQL.
  "Named indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- withRenderKeywordCase: Whether the case of Keyword references should be modified in any way.
- withRenderKeywordStyle: Whether the case of Keyword references should be modified in any way.
- withRenderLocale: The Locale to be used with any render locale dependent logic (as e.g.
  transforming names to lower / uppper case), defaulting to getLocale().
- withRenderFormatted: Whether rendered SQL should be pretty-printed.
- withRenderFormatting: All sorts of formatting flags / settings.
- withRenderNullifEmptyStringForBindValues: Whether to wrap String typed bind values with NULLIF(?,
  '') for Oracle compatibility. This feature is available in the commercial distribution only.
- withRenderAutoAliasedDerivedTableExpressions: Whether to auto-alias expressions in derived tables.
  This feature is available in the commercial distribution only.
- withRenderOptionalAssociativityParentheses: Whether to render optional parentheses to make
  associativity explicit, e.g. ((a + b) + c) instead of (a + b + c).
- withRenderOptionalAsKeywordForTableAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect. This is ignored if the keyword is not supported
  (e.g. in Oracle)
- withRenderOptionalAsKeywordForFieldAliases: Whether to render the optional AS keyword in table
  aliases, if it is optional in the output dialect.
- withRenderOptionalInnerKeyword: Whether to render the optional INNER keyword in INNER JOIN, if it
  is optional in the output dialect.
- withRenderOptionalOuterKeyword: Whether to render the optional OUTER keyword in OUTER JOIN, if it
  is optional in the output dialect.
- withRenderImplicitWindowRange: Whether to render an explicit window RANGE clause when an implicit
  clause is applied.
- withRenderScalarSubqueriesForStoredFunctions: Whether stored function calls should be wrapped in
  scalar subqueries. Oracle 11g (and potentially, other databases too) implements scalar subquery
  caching. With this flag set to true, users can automatically profit from this feature in all SQL
  statements.
- withRenderImplicitJoinType: The join type to be generated by implicit joins for to-one paths in
  Select queries. The DEFAULT is dependent on the nullability of the foreign key (LEFT_JOIN for
  nullable foreign keys and INNER_JOIN for non-nullable foreign keys). In DML statements, it is
  always SCALAR_SUBQUERY, unless DML joins are supported.
- withRenderImplicitJoinToManyType: The join type to be generated by implicit joins for to-many
  paths in Select queries. The DEFAULT is SCALAR_SUBQUERY if the join path is implicit only, i.e.
  absent from the FROM clause, to prevent accidental cartesian products, or LEFT_JOIN if declared
  explicitly in the FROM clause. In DML statements, it is always SCALAR_SUBQUERY, unless DML joins
  are supported.
- withRenderDefaultNullability: Whether the Nullability.DEFAULT nullablity should be rendered in
  generated DDL, and how it should be rendered.
- withRenderCoalesceToEmptyStringInConcat: Whether string concatenation operands should be coalesced
  to empty strings. Some dialects treat NULL values as empty strings when concatenating strings
  (e.g. Oracle). For compatibility reasons, this flag allows for replicating this behaviour also
  elsewhere. This feature is available in the commercial distribution only.
- withRenderOrderByRownumberForEmulatedPagination: Whether an additional ORDER BY rn clause should
  be rendered on emulated paginated queries. Older databases did not support OFFSET .. FETCH
  pagination, so jOOQ emulates it using derived tables and ROWNUM (Oracle 11g and older) or
  ROW_NUMBER() (e.g. DB2, SQL Server, etc.) filtering. While these subqueries are ordered, the
  ordering is not guaranteed to be stable in the outer most queries. It may be stable (and e.g. in
  Oracle, it mostly is, if queries are not parallel, or joined to other queries, etc.), so the
  excess ORDER BY clause may add some additional performance overhead. This setting forces jOOQ to
  not generate the additional ORDER BY clause. For details, see
  https://github.com/jOOQ/jOOQ/issues/7609.
- withRenderOutputForSQLServerReturningClause: Whether the jOOQ RETURNING clause should map to SQL
  Server's OUTPUT clause. SQL Server supports an OUTPUT clause in most DML statements, whose
  behaviour is almost identical to RETURNING in Firebird, Oracle, PostgreSQL. Users who want to
  prevent jOOQ from rendering this OUTPUT clause can deactivate this flag to revert to jOOQ calling
  java.sql.Statement#getGeneratedKeys() instead, which is only supported for single row inserts.
  This OUTPUT clause does not support fetching trigger generated values. In order to fetch trigger
  generated values, fetchTriggerValuesAfterReturning needs to be enabled as well. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- withRenderGroupConcatMaxLenSessionVariable: Whether the jOOQ GROUP_CONCAT function should be
  overflow-protected by setting the @@group_concat_max_len session variable in MySQL style database
  systems. MySQL truncates GROUP_CONCAT results after a certain length, which may be way too small
  for jOOQ's usage, especially when using the MULTISET emulation. By default, jOOQ sets a session
  variable to the highest possible value prior to executing a query containing GROUP_CONCAT. This
  flag can be used to opt out of this. For details, see https://github.com/jOOQ/jOOQ/issues/12092.
- withRenderParenthesisAroundSetOperationQueries: Whether queries combined with set operators (e.g.
  UNION and UNION ALL) should always be surrounded by a parenthesis pair. By default (i.e. when this
  setting is set to false jOOQ will only render parenthesis pairs around queries combined with set
  operators when required. This is for example the case when set operators are nested, when non-
  associative operators like EXCEPT are used, or when the queries are rendered as derived tables.
  When this setting is set to true the queries combined with set operators will always be surrounded
  by a parenthesis pair. For details, see https://github.com/jOOQ/jOOQ/issues/3676 and
  https://github.com/jOOQ/jOOQ/issues/9751.
- withRenderVariablesInDerivedTablesForEmulations: Whether emulations that require repeating
  expressions should render variables for those expressions in derived tables. For details, see
  https://github.com/jOOQ/jOOQ/issues/14065.
- withRenderRowConditionForSeekClause: Whether a (a, b) Ungültige Eingabe: "<" (:a, :b) row
  predicate should be rendered for the SEEK clause. Some RDBMS may support (a, b) Ungültige Eingabe:
  "<" (:a, :b) row predicate syntax, which is very convenient for SEEK clause implementations, but
  fail to optimise this predicate as could be expected. This flag allows for expanding the predicate
  to the much more verbose, but equivalent (a Ungültige Eingabe: "<" :a) OR (a = :a AND b Ungültige
  Eingabe: "<" :b). Dialects without native support for row predicates aren't affected by this flag.
- withRenderRedundantConditionForSeekClause: Whether a redundant (a Ungültige Eingabe: "<"= :a)
  predicate should be rendered for a (a, b) Ungültige Eingabe: "<" (:a, :b) predicate for the SEEK
  clause. Some RDBMS may not be able to properly optimise (a, b) Ungültige Eingabe: "<" ('a', 'b')
  or (a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<" 'b'), and choose an
  appropriate index. By adding an additional redundant predicate, jOOQ may help the optimiser, e.g.
  (a Ungültige Eingabe: "<"= :a) AND (a, b) Ungültige Eingabe: "<" ('a', 'b') or (a Ungültige
  Eingabe: "<"= :a) AND ((a Ungültige Eingabe: "<" 'a') OR (a = 'a' AND b Ungültige Eingabe: "<"
  'b'))
- withRenderPlainSQLTemplatesAsRaw: Whether plain SQL templates (SQL) are rendered as raw string
  content.
- withRenderDollarQuotedStringToken: The token to place between the $$ signs of a PostgreSQL dollar
  quoted string generated by jOOQ.
- withNamePathSeparator Name: The character(s) to be used as a separator in paths encoded in a
  Ungültige Referenz Name A few hierarchical mapping features work with paths encoded in names
  (specifically field aliases), such as the reflective mapping of nested values when aliasing fields
  as: SELECT a.first_name AS "book.author.firstName" a.last_name AS "book.author.lastName" FROM ...
  Not all dialects support "." in identifiers. This setting allows for specifying an alternative
  String to use as separator, e.g. "__".
- withBindOffsetDateTimeType: Whether the java.time (JSR 310) type OffsetDateTime should be bound
  natively to JDBC. Historically, jOOQ encoded the java.time types as strings to offer better
  compatibility with older JDBC drivers. By now, most drivers should support the java.time types.
  Using them may produce better performance both on the server and on the client side. This flag
  allows for reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types
  natively. For details, see https://github.com/jOOQ/jOOQ/issues/9902.
- withBindOffsetTimeType: Whether the java.time (JSR 310) type OffsetTime should be bound natively
  to JDBC. Historically, jOOQ encoded the java.time types as strings to offer better compatibility
  with older JDBC drivers. By now, most drivers should support the java.time types. Using them may
  produce better performance both on the server and on the client side. This flag allows for
  reverting to pre-jOOQ 3.14 behaviour, where the default is to bind these types natively. For
  details, see https://github.com/jOOQ/jOOQ/issues/9902.
- withFetchTrimmedCharValues: Whether right trim fetched CHAR typed strings from JDBC ResultSet. By
  default, jOOQ's internal String data type Binding fetched strings as returned by JDBC. With this
  flag enabled, jOOQ will always right-trim CHAR typed strings, which can be useful in database
  products that will often use this historic fixed length string type, especially in dictionary
  views.
- withFetchTriggerValuesAfterSQLServerOutput: Fetch trigger values after SQL Server OUTPUT clause.
  SQL Server OUTPUT statements do not support fetching trigger generated values. This is a
  limitation of the renderOutputForSQLServerReturningClause. An additional MERGE statement can run a
  second query if (and only if) the primary key has been included in the OUTPUT clause. For details,
  see https://github.com/jOOQ/jOOQ/issues/4498.
- withFetchTriggerValuesAfterReturning: Fetch trigger values after a RETURNING clause in dialects
  that don't have native support for this. SQL Server OUTPUT clauses do not support fetching trigger
  generated values. Neither do SQLite RETURNING clauses. An additional MERGE statement can run a
  second query if (and only if) the primary key has been included in the OUTPUT clause. Trigger meta
  data is only available in jOOQ's commercial editions. If setting this flag to WHEN_NEEDED in the
  jOOQ Open Source Edition, jOOQ will assume triggers are present. For details, see
  https://github.com/jOOQ/jOOQ/issues/4498.
- withFetchIntermediateResult: Whether to fetch data into intermediate Result instances. By default,
  a ResultQuery produces no intermediate Result instances if they are not explicitly requested by
  the caller, e.g. by calling ResultQuery.fetch(), or in the presence of ExecuteListener instances,
  which may require access to ExecuteContext.result(). This default behaviour helps avoid
  unnecessary allocations of possibly large data structures. Using this flag, fetching of
  intermediate results can be turned off even when execute listeners are present, or turned on even
  if they're absent.
- withDiagnosticsDuplicateStatements: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsDuplicateStatementsUsingTransformPatterns: Whether to run the
  DiagnosticsListener.duplicateStatements(org.jooq.DiagnosticsContext) diagnostic with the
  transformPatterns feature activated. When transforming patterns, many more complex, duplicate SQL
  statements can be recognised than if simply parsing and re-rendering the statement. This flag
  turns on all transformation patterns, independently of their individual settings. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default. This feature is available in the commercial distribution
  only.
- withDiagnosticsMissingWasNullCall: Whether to run the
  DiagnosticsListener.missingWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsRepeatedStatements: Whether to run the
  DiagnosticsListener.repeatedStatements(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsConsecutiveAggregation
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#consecutiveAggregation(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- withDiagnosticsConcatenationInPredicate
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#concatenationInPredicate(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- withDiagnosticsPossiblyWrongExpression
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext): Whether to run
  the Ungültige Referenz
  org.jooq.DiagnosticsListener#possiblyWrongExpression(org.jooq.DiagnosticsContext) diagnostic.
  Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once
  configured, this diagnostic is turned on by default. This feature is available in the commercial
  distribution only.
- withDiagnosticsTooManyColumnsFetched: Whether to run the
  DiagnosticsListener.tooManyColumnsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsTooManyRowsFetched: Whether to run the
  DiagnosticsListener.tooManyRowsFetched(org.jooq.DiagnosticsContext) diagnostic. Diagnostics are
  turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsUnnecessaryWasNullCall: Whether to run the
  DiagnosticsListener.unnecessaryWasNullCall(org.jooq.DiagnosticsContext) diagnostic. Diagnostics
  are turned off if no Configuration.diagnosticsListenerProviders() are configured. Once configured,
  this diagnostic is turned on by default.
- withDiagnosticsPatterns: Whether to run the various pattern transformation diagnostics.
  transformPatterns allows for applying numerous pattern transformations, which can be turned on
  separately when running diagnostics. This flag overrides the transformPatterns flag in the
  diagnostics context. Individual pattern flags still allow to enable / disable the pattern for
  diagnostics. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- withDiagnosticsTrivialCondition
  org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#trivialCondition(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- withDiagnosticsNullCondition
  org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext): Whether to run the
  Ungültige Referenz org.jooq.DiagnosticsListener#nullConditoin(org.jooq.DiagnosticsContext)
  diagnostic. Diagnostics are turned off if no Configuration.diagnosticsListenerProviders() are
  configured. Once configured, this diagnostic is turned on by default. This feature is available in
  the commercial distribution only.
- withTransformPatterns: Transform various syntax patterns to better versions, if possible. This
  flag enables the pattern transformation feature, which consists of several sub-flags that are all
  prefixed with "transformPatterns", e.g. transformPatternsTrim. While the sub-flags default to
  being enabled, and can be disabled on an individual basis, the global feature itself is disabled
  by default. This feature is available in the commercial distribution only.
- withTransformPatternsLogging: Activate debug logging of the transformPatterns feature.
- withTransformPatternsUnnecessaryDistinct: Transform SELECT DISTINCT a, b FROM t GROUP BY a, b to
  SELECT a, b FROM t GROUP BY a, b. The GROUP BY clause already removes duplicates, so if the
  DISTINCT clause contains at least all the columns from GROUP BY then it can be removed. To enable
  this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsUnnecessaryScalarSubquery: Transform SELECT (SELECT 1) to SELECT 1. Scalar
  subqueries that don't have any content other than a SELECT clause are unnecessary and can be
  removed. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- withTransformPatternsUnnecessaryInnerJoin: Transform SELECT * FROM t INNER JOIN u ON TRUE to
  SELECT * FROM t CROSS JOIN u. Some INNER JOIN expressions can be proven to be unnecessary. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsUnnecessaryGroupByExpressions: Transform SELECT a, b FROM t GROUP BY a, a, b
  to SELECT a, b FROM t GROUP BY a, b. Duplicate GROUP BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsUnnecessaryOrderByExpressions: Transform SELECT a, b FROM t ORDER BY a, a, b
  to SELECT a, b FROM t ORDER BY a, b. Duplicate ORDER BY expressions can be removed. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsUnnecessaryExistsSubqueryClauses: Transform [ NOT ] EXISTS (SELECT DISTINCT
  a, b FROM t ORDER BY c LIMIT d) to [ NOT ] EXISTS (SELECT 1 FROM t). In EXISTS subqueries, quite a
  few SELECT clauses are meaningless, and can thus be removed. These include: SELECT (any projection
  can be ignored) DISTINCT ORDER BY LIMIT (except LIMIT 0, in case of which
  transformPatternsTrivialPredicates applies). To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- withTransformPatternsCountConstant: Transform COUNT(1) or any other COUNT(const) to COUNT(*).
  There is no benefit to counting a constant expression. In fact, in some RDBMS, it might even be
  slightly slower, at least in benchmarks. To enable this feature, transformPatterns must be enabled
  as well. This feature is available in the commercial distribution only.
- withTransformPatternsTrim: Transform LTRIM(RTRIM(x)) or RTRIM(LTRIM(x)) to TRIM(x). Historically,
  a few dialects did not implement TRIM(x) or TRIM(BOTH FROM x), so users worked around this by
  wrapping LTRIM() and RTRIM() with each other. Maintaining this is usually undesirable, so this
  transformation helps remove the unwanted wrapping. To enable this feature, transformPatterns must
  be enabled as well. This feature is available in the commercial distribution only.
- withTransformPatternsNotAnd: Transform NOT(p AND q) to NOT(p) OR NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- withTransformPatternsNotOr: Transform NOT(p OR q) to NOT(p) AND NOT(q). This transformation
  normalises a predicate using De Morgan's rules. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- withTransformPatternsNotNot: Transform NOT(NOT(x)) to x. This transformation removes a redundant
  logic negation. To enable this feature, transformPatterns must be enabled as well. This feature is
  available in the commercial distribution only.
- withTransformPatternsNotComparison: Transform NOT (a != b) to a = b, and similar comparisons. This
  transformation removes a redundant logical negation from the DISTINCT predicate. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsNotNotDistinct: Transform NOT (a IS NOT DISTINCT FROM b) to a IS DISTINCT
  FROM b. This transformation removes a redundant logical negation from the DISTINCT predicate. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsDistinctFromNull: Transform a IS [ NOT ] DISTINCT FROM NULL to a IS [ NOT ]
  NULL. This simplifies the much more verbose DISTINCT predicate. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsNormaliseAssociativeOps: Transform (a + b) + (c + d) to ((a + b) + c) + d.
  This transformation turns trees into lists, which greatly simplifies other tree traversal
  transformations. Some of those other transformations currently rely on this flag to be active. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsNormaliseInListSingleElementToComparison: Transform x IN (a) to x = a and x
  NOT IN (a) to x != a. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsNormaliseFieldCompareValue TableField: Transform 1 = a to a = 1. This
  transformation inverses Ungültige Referenz TableField [op] Ungültige Referenz
  org.jooq.impl.QOM.Val comparisons, if they're not in that order. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsNormaliseCoalesceToNvl: Transform 2 argument COALESCE(a, b) to NVL(a, b). To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsOrEqToIn: Transform x = c1 OR x = c2 to x IN (c1, c2). This transformation
  simplifies verbose OR predicates into simpler IN predicates. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsAndNeToNotIn: Transform x != c1 AND x != c2 to x NOT IN (c1, c2). This
  transformation simplifies verbose AND predicates into simpler NOT IN predicates. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsMergeOrComparison: Transform x = a OR x > a to x >= a. This transformation
  merges multiple OR connected comparisons to a single comparison using a simpler operator. To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsMergeAndComparison: Transform x >= a AND x Ungültige Eingabe: "<"= a to x =
  a. This transformation merges multiple AND connected comparisons to a single comparison using a
  simpler operator. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- withTransformPatternsMergeInLists: Transform x IN (a, b, c) AND x IN (b, c, d) to x IN (b, c).
  This transformation merges multiple OR connected comparisons to a single comparison using a
  simpler operator. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- withTransformPatternsMergeRangePredicates: Transform x >= a AND x Ungültige Eingabe: "<"= b to x
  BETWEEN a AND b. This transformation merges multiple AND connected range predicates to a single
  comparison using BETWEEN. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsMergeBetweenSymmetricPredicates: Transform x BETWEEN a AND b OR x BETWEEN b
  AND a to x BETWEEN SYMMETRIC a AND b. This transformation merges multiple OR connected BETWEEN
  predicates to a single comparison using BETWEEN SYMMETRIC. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsCaseSearchedToCaseSimple: Transform a searched CASE WHEN x = .. WHEN x = ..
  to a simple CASE x WHEN … WHEN … expression. When a searched CASE expression always compares the
  same column to a value, then it can be simplified, possibly unlocking further transformations that
  are available only to the simple CASE expression. This feature is available in the commercial
  distribution only.
- withTransformPatternsCaseElseNull: Transform CASE … ELSE NULL removing the ELSE clause. CASE WHEN
  x THEN y ELSE NULL END is equivalent to CASE WHEN x THEN y END. This feature is available in the
  commercial distribution only.
- withTransformPatternsUnreachableCaseClauses: Transform CASE by removing unreachable clauses. Case
  clauses can be proven to be unreachable, and thus removed: CASE WHEN p THEN 1 WHEN TRUE THEN 2
  WHEN q … ELSE … END is equivalent to CASE WHEN p THEN 1 ELSE 2 END CASE WHEN p THEN 1 WHEN FALSE
  THEN 2 WHEN q .. ELSE .. END is equivalent to CASE WHEN p THEN 1 WHEN q … ELSE … END This feature
  is available in the commercial distribution only.
- withTransformPatternsUnreachableDecodeClauses: Transform DECODE by removing unreachable clauses.
  DECODE clauses can be proven to be unreachable, and thus removed: DECODE(a, b, 1, c, 2, b, 3) is
  equivalent to DECODE(a, b, 1, c, 2) DECODE(a, b, 1, c, 2, b, 3, 4) is equivalent to DECODE(a, b,
  1, c, 2, 4) This feature is available in the commercial distribution only.
- withTransformPatternsCaseDistinctToDecode: Transform CASE WHEN a IS NOT DISTINCT FROM b … to an
  equivalent DECODE function. When all WHEN clauses of a CASE expression use the DISTINCT predicate,
  then the CASE expression can be transformed into a DECODE function call: CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 END is equivalent to DECODE(a, b, 1) CASE WHEN a IS NOT DISTINCT FROM b
  THEN 1 ELSE 2 END is equivalent to DECODE(a, b, 1, 2) CASE WHEN a IS NOT DISTINCT FROM b THEN 1
  WHEN a IS NOT DISTINCT FROM c THEN 2 END is equivalent to DECODE(a, b, 1, c, 2) CASE WHEN a IS NOT
  DISTINCT FROM b THEN 1 WHEN a IS NOT DISTINCT FROM c THEN 2 ELSE 3 END is equivalent to DECODE(a,
  b, 1, c, 2, 3) This feature is available in the commercial distribution only.
- withTransformPatternsCaseMergeWhenWhen: Transform CASE WHEN a THEN x WHEN b THEN x END to CASE
  WHEN a OR b THEN x END. Two consecutive WHEN clauses can be merged, if their respective THEN
  clause is identical. This feature is available in the commercial distribution only.
- withTransformPatternsCaseMergeWhenElse: Transform CASE WHEN a THEN x WHEN b THEN y ELSE y END to
  CASE WHEN a THEN x ELSE y END. The ultimate WHEN clause can be merged with the ELSE, if their
  respective result is identical. If the WHEN clause is the only WHEN clause, then the entire CASE
  expression can be replaced by the ELSE clause content. This feature is available in the commercial
  distribution only.
- withTransformPatternsCaseToCaseAbbreviation: Transform CASE expressions to their respective
  abbreviations. Some CASE expressions have a shorter abbreviated form, such as COALESCE() or
  NULLIF(). This feature is available in the commercial distribution only.
- withTransformPatternsSimplifyCaseAbbreviation: Transform complex predicates into simpler CASE
  abbreviations. Some predicates can be simplified into case abbreviations, such as, for example a
  IS NULL OR COALESCE(a = b, FALSE) to NULLIF(a, b) IS NULL a IS NOT NULL AND COALESCE(a != b, TRUE)
  to NULLIF(a, b) IS NOT NULL This feature is available in the commercial distribution only.
- withTransformPatternsFlattenCaseAbbreviation: Flatten nested CASE abbreviations such as NVL or
  CASE. Nested CASE abbreviations can be flattened, as such: NVL(NVL(a, b), c) to COALESCE(a, b, c)
  COALESCE(a, ..., COALESCE(b, ..., c), ..., d) to COALESCE(a, …, b, …, c, ..., d) This feature is
  available in the commercial distribution only.
- withTransformPatternsFlattenDecode: Flatten nested DECODE functions. Nested DECODE functions can
  be flattened, as such: DECODE(a, b, c, DECODE(a, d, e)) to DECODE(a, b, c, d, e) This feature is
  available in the commercial distribution only.
- withTransformPatternsFlattenCase: Transform CASE … ELSE CASE … by flattening the nested CASE. CASE
  WHEN a THEN b ELSE CASE WHEN c THEN d END END is equivalent to CASE WHEN a THEN b WHEN c THEN d
  END. This feature is available in the commercial distribution only.
- withTransformPatternsTrivialCaseAbbreviation: Transform trivial case abbreviations like NVL(NULL,
  a) to a. This transformation removes any trivial case abbreviations, such as NVL(), COALESCE(),
  NULLIF(), etc. This feature is available in the commercial distribution only.
- withTransformPatternsTrivialPredicates: Transform trivial predicates like 1 = 1 to TRUE. This
  transformation removes any trivial predicates. This feature is available in the commercial
  distribution only.
- withTransformPatternsTrivialBitwiseOperations: Transform trivial bitwise comparisons like
  BIT_OR(a, 0) to a. This transformation removes any trivial predicates. This feature is available
  in the commercial distribution only.
- withTransformPatternsBitSet: Transform bitwise operations to an equivalent BIT_SET(a, b) or
  BIT_SET(a, b, c) expression. This feature is available in the commercial distribution only.
- withTransformPatternsBitGet: Transform bitwise operations to an equivalent BIT_GET(a, b)
  expression. This feature is available in the commercial distribution only.
- withTransformPatternsScalarSubqueryCountAsteriskGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(*) …) > 0 to equivalent EXISTS (SELECT 1 …). Scalar
  subqueries that count rows and whose count is compared to 0 can be transformed into equivalent,
  but likely cheaper to execute EXISTS queries. This feature is available in the commercial
  distribution only.
- withTransformPatternsScalarSubqueryCountExpressionGtZero: Transform predicates comparing scalar
  subqueries with a count (SELECT COUNT(expr) …) > 0 to equivalent EXISTS (SELECT 1 … WHERE expr IS
  NOT NULL). Scalar subqueries that count non-null expressions and whose count is compared to 0 can
  be transformed into equivalent, but likely cheaper to execute EXISTS queries. This feature is
  available in the commercial distribution only.
- withTransformPatternsEmptyScalarSubquery: Transform empty scalar subqueries like (SELECT 1 WHERE
  FALSE) to NULL. Scalar subqueries that are guaranteed to produce no results can be replaced by a
  NULL value. This feature is available in the commercial distribution only.
- withTransformPatternsNegNeg: Transform -(-(x)) to x This transformation removes a redundant
  arithmetic negation. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsBitNotBitNot: Transform ~(~(x)) to x. This transformation removes a redundant
  bitwise negation. To enable this feature, transformPatterns must be enabled as well. This feature
  is available in the commercial distribution only.
- withTransformPatternsBitNotBitNand: Transform ~(bitnand(x, y)) to bitand(x, y) and ~(bitand(x, y)
  to bitnand(x, y). This transformation removes a redundant bitwise negation. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsBitNotBitNor: Transform ~(bitnor(x, y)) to bitor(x, y) and ~(bitor(x, y) to
  bitnor(x, y). This transformation removes a redundant bitwise negation. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsBitNotBitXNor: Transform ~(bitxnor(x, y)) to bitxor(x, y) and ~(bitxor(x, y)
  to bitxnor(x, y). This transformation removes a redundant bitwise negation. To enable this
  feature, transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsNullOnNullInput: Any {org.jooq.impl.QOM.UReturnsNullOnNullInput} function or
  expression with NULL arguments can be replaced by NULL. There are many built-in SQL functions and
  operators with a RETURNS NULL ON NULL INPUT property, e.g. ABS(NULL) MOD(NULL, 1) NULL + 1 To
  enable this feature, transformPatterns must be enabled as well. This feature is available in the
  commercial distribution only.
- withTransformPatternsIdempotentFunctionRepetition: Transform all repetitions of idempotent
  functions, such as UPPER(UPPER(s)) to UPPER(s). Idempotent functions that are covered so far,
  include: LTRIM(LTRIM(s)) to LTRIM(s) LTRIM(TRIM(s)) to TRIM(s) RTRIM(RTRIM(s)) to RTRIM(s)
  RTRIM(TRIM(s)) to TRIM(s) TRIM(LTRIM(s)) to TRIM(s) TRIM(RTRIM(s)) to TRIM(s) UPPER(UPPER(s)) to
  UPPER(s) LOWER(LOWER(s)) to LOWER(s) To enable this feature, transformPatterns must be enabled as
  well. This feature is available in the commercial distribution only.
- withTransformPatternsArithmeticComparisons: Transform a + 1 = 2 to a = 2 - 1, and other
  transformations. It is usually best to compare single columns with constants or expressions to
  encourage index usage. While function based indexes are possible in some RDBMS, ordinary indexes
  are more reusable and should be preferred. To enable this feature, transformPatterns must be
  enabled as well. This feature is available in the commercial distribution only.
- withTransformPatternsArithmeticExpressions: Transform 1 / y * x to x / y, and other
  transformations. This transformation simplifies arithmetic expressions. To enable this feature,
  transformPatterns must be enabled as well. This feature is available in the commercial
  distribution only.
- withTransformPatternsTrigonometricFunctions: Transform SIN(x) / COS(x) to TAN(x), and other
  transformations. This transformation turns expanded trignonometric function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsLogarithmicFunctions: Transform LN(value) / LN(base) to LOG(base, value), and
  other transformations. This transformation turns expanded logarithmic function definitions into
  their shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsHyperbolicFunctions: Transform (EXP(x) - EXP(-x)) / 2 to SINH(x), and other
  transformations. This transformation turns expanded hyperbolic function definitions into their
  shorter equivalents. To enable this feature, transformPatterns must be enabled as well. This
  feature is available in the commercial distribution only.
- withTransformPatternsInverseHyperbolicFunctions: Transform LN(x + SQRT(SQUARE(x) + 1)) to
  ASINH(x), and other transformations. This transformation turns expanded inverse hyperbolic
  function definitions into their shorter equivalents. To enable this feature, transformPatterns
  must be enabled as well. This feature is available in the commercial distribution only.
- withTransformInlineBindValuesForFieldComparisons: Transform QOM.CompareCondition and a few other
  types of condition to inline their bind values, in case they match Historically, prior to ANSI
  join syntax, joins were implemented by listing tables in the FROM clause and providing join
  predicates in the WHERE clause, possibly using vendor specific operators like (+) (Oracle, DB2) or
  *= (SQL Server) for outer join support. For backwards compatibility with older RDBMS versions,
  ANSI joins in jOOQ code may be converted to equivalent table lists in generated SQL using this
  flag. This flag has a limited implementation that supports inner joins (in most cases) and outer
  joins (only for simple comparison predicates). This feature is available in the commercial
  distribution only.
- withTransformAnsiJoinToTableLists: Transform ANSI join to table lists if possible. Historically,
  prior to ANSI join syntax, joins were implemented by listing tables in the FROM clause and
  providing join predicates in the WHERE clause, possibly using vendor specific operators like (+)
  (Oracle, DB2) or *= (SQL Server) for outer join support. For backwards compatibility with older
  RDBMS versions, ANSI joins in jOOQ code may be converted to equivalent table lists in generated
  SQL using this flag. This flag has a limited implementation that supports inner joins (in most
  cases) and outer joins (only for simple comparison predicates). This feature is available in the
  commercial distribution only.
- withTransformInConditionSubqueryWithLimitToDerivedTable: Transform a subquery from an IN condition
  with LIMIT to an equivalent derived table. This transformation works around a known MySQL
  limitation "ERROR 1235 (42000): This version of MySQL doesn't yet support 'LIMIT Ungültige
  Eingabe: "&" IN/ALL/ANY/SOME subquery'" This feature is available in the commercial distribution
  only.
- withTransformQualify: Transform the QUALIFY clause to an equivalent derived table to filter on
  window functions. This feature is available in the commercial distribution only.
- withTransformTableListsToAnsiJoin: Transform table lists to ANSI join if possible. (Very)
  historically, prior to ANSI join syntax, joins were implemented by listing tables in the FROM
  clause and providing join predicates in the WHERE clause, possibly using vendor specific operators
  like (+) (Oracle, DB2) or *= (SQL Server) for outer join support. Migrating such join syntax is
  tedious. The jOOQ parser can parse the old syntax and this flag enables the transformation to ANSI
  join syntax. This feature is available in the commercial distribution only.
- withTransformRownum: Transform ROWNUM expressions to corresponding LIMIT clauses or ROW_NUMBER()
  expressions. In Oracle 11g and less, ROWNUM filtering was the most popular way to paginate. This
  pseudo column is not supported in other RDBMS, and should be replaced in Oracle 12c by the FETCH
  clause or ROW_NUMBER() OVER () filtering. This transformation allows for replacing such a filter
  by equivalent SQL, if possible. This feature is available in the commercial distribution only.
- withTransformUnneededArithmeticExpressions: Transform arithmetic expressions on literals and bind
  variables. Arithmetic expressions may be implemented by the user, or arise from emulations from
  within jOOQ. Expressions on literals and bind variables could be evaluated in the client prior to
  generating SQL. This feature is available in the commercial distribution only.
- withTransformGroupByColumnIndex: Transform GROUP BY [column index] clauses by substituting the
  column index. Not all dialects support grouping by column index, which is a convenient but also a
  bit confusing feature of some dialects. jOOQ can transform the syntax into an equivalent syntax
  where the referenced SELECT expression is duplicated into the GROUP BY clause. This feature is
  available in the commercial distribution only.
- withTransformInlineCTE: Transform Common Table Expressions (CTE) by inlining their WITH clause
  definition to wherever they're referenced. Non-recursive CTE are just syntax sugar for inline
  views (derived tables). When they're not supported natively, jOOQ can simply inline their
  definition to wherever they're referenced. This feature is available in the commercial
  distribution only.
- withBackslashEscaping: Whether string literals should be escaped with backslash.
- withParamType: Specify how bind variables are to be rendered. Possibilities include: - question
  marks - named parameters - named or inlined parameters - inlined parameters This value is
  overridden by statementType == STATIC_STATEMENT, in case of which, this defaults to INLINED
- withParamCastMode: Whether rendered bind values should be cast to their respective type.
- withStatementType: The type of statement that is to be executed.
- withInlineThreshold org.jooq.SQLDialect#ACCESS: The maximum number of allowed bind variables
  before inlining all values where 0 uses the dialect defaults: Ungültige Referenz
  org.jooq.SQLDialect#ACCESS : 768 Ungültige Referenz org.jooq.SQLDialect#ASE : 2000 Ungültige
  Referenz org.jooq.SQLDialect#DATABRICKS : 256 Ungültige Referenz org.jooq.SQLDialect#INGRES : 1024
  Ungültige Referenz org.jooq.SQLDialect#ORACLE : 32767 SQLDialect.POSTGRES : 32767
  SQLDialect.SQLITE : 999 Ungültige Referenz org.jooq.SQLDialect#SQLSERVER : 2100 Ungültige Referenz
  org.jooq.SQLDialect#TERADATA : 2536
- withTransactionListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered TransactionListeners.
- withTransactionListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered TransactionListeners.
- withMigrationListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered MigrationListeners.
- withMigrationListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered MigrationListeners.
- withVisitListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered VisitListeners.
- withVisitListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  VisitListeners.
- withRecordListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered RecordListeners.
- withRecordListenerEndInvocationOrder: The order of invocation for [action]end() methods registered
  RecordListeners.
- withExecuteListenerStartInvocationOrder: The order of invocation for [action]start() methods
  registered ExecuteListeners.
- withExecuteListenerEndInvocationOrder: The order of invocation for [action]end() methods
  registered ExecuteListeners.
- withExecuteLogging: When set to true, this will add jOOQ's default LoggerListener for debug
  logging. This is meant for use in development only.
- withExecuteLoggingSQLExceptions: [#14420] Whether constraint violations and other SQLException
  should produce additional log information about the column name and data causing the problem.
  Unlike executeLogging, this is meant for use in production as well as development. This feature is
  available only in commercial distributions.
- withDiagnosticsLogging: When set to true, this will add jOOQ's default logging
  DiagnosticsListeners.
- withDiagnosticsConnection: Whether to activate the DiagnosticsConnection, explicit by DEFAULT,
  implicit if ON, or turned OFF entirely.
- withUpdateRecordVersion: Whether store(), insert(), and update() methods should update the record
  version prior to the operation, for use with executeWithOptimisticLocking.
- withUpdateRecordTimestamp: Whether store(), insert(), and update() methods should update the
  record timestamp prior to the operation, for use with executeWithOptimisticLocking.
- withExecuteWithOptimisticLocking: Whether store() and delete() methods should be executed with
  optimistic locking.
- withExecuteWithOptimisticLockingExcludeUnversioned: Whether store() and delete() methods should be
  executed with optimistic locking also on "unversioned" tables, i.e. on tables that do not have a
  version and/or timestamp column. This flag has no effect when "executeWithOptimisticLocking" is
  turned off.
- withAttachRecords: Whether fetched records should be attached to the fetching configuration.
- withInsertUnchangedRecords: Whether TableRecord.insert() calls should be executed if the record is
  unchanged. This also affects the INSERT part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- withUpdateUnchangedRecords: Whether UpdatableRecord.update() calls should be executed if the
  record is unchanged. This also affects the UPDATE part of UpdatableRecord.store() and
  UpdatableRecord.merge() calls.
- withRecordDirtyTracking: Whether UpdatableRecord.store() and related calls should be based on
  Record.touched() or Record.modified() semantics. This also affects copying records into explicit
  statements.
- withUpdatablePrimaryKeys: Whether primary key values are deemed to be "updatable" in jOOQ. Setting
  this to "true" will allow for updating primary key values through UpdatableRecord.store() and
  UpdatableRecord.update().
- withReflectionCaching: Whether reflection information should be cached in the configuration.
- withCacheRecordMappers: Whether record mappers should be cached in the configuration.
- withCacheParsingConnection: Whether parsing connection translations should be cached in the
  configuration.
- withCacheParsingConnectionLRUCacheSize: The default value of the ParsingConnection cache's LRU
  cache size.
- withCacheRecordMappersLRUCacheSize: The default value of the RecordMapper cache's LRU cache size.
- withReflectionCacheLRUCacheSize: The default value of the reflection cache's LRU cache size.
- withCachePreparedStatementInLoader: Whether JDBC PreparedStatement instances should be cached in
  loader API.
- withThrowExceptions: A strategy defining how exceptions from the database / JDBC driver should be
  propagated
- withFetchWarnings: Whether warnings should be fetched after each query execution.
- withFetchServerOutputSize: Whether server output should be fetched after each query execution.
- withReturnIdentityOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  the identity column.
- withReturnDefaultOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.defaulted().
- withReturnComputedOnUpdatableRecord: Whether calls to store(), insert() and update() should return
  values for columns that are DataType.computed().
- withReturnAllOnUpdatableRecord: Whether calls to store(), insert() and update() should return all
  columns, not just identity columns. Do note that only few databases support this feature. It is
  supported only in case the INSERT's or UPDATE's RETURNING clause is fully supported, also for non-
  IDENTITY columns.
- withReturnRecordToPojo: Whether calls to store(), insert(), update(), and delete() that are called
  on an UpdatableRecord that is created from a POJO (e.g. in a DAO) should return all Record values
  to the POJO, including IDENTITY values, and if returnAllOnUpdatableRecord is active, also other
  values.
- withMapJPAAnnotations: Whether JPA annotations should be considered by the DefaultRecordMapper,
  assuming the jOOQ-jpa-extensions is on the classpath.
- withMapRecordComponentParameterNames: Whether constructor parameter names obtained from the Record
  component names should be considered by the DefaultRecordMapper.
- withMapConstructorPropertiesParameterNames: Whether constructor parameter names obtained from the
  ConstructorPropertiesProvider SPI (default implementation in the jOOQ-beans-extensions module)
  should be considered by the DefaultRecordMapper.
- withMapConstructorParameterNames: Whether constructor parameter names obtained via reflection in
  Java 8+ should be considered by the DefaultRecordMapper. This flag has no effect in Java 6 or 7.
- withMapConstructorParameterNamesInKotlin: Whether constructor parameter names obtained via
  reflection in Kotlin should be considered by the DefaultRecordMapper. This flag has no effect in
  Java.
- withQueryPoolable: The default JDBC poolable property that should be applied to all jOOQ queries,
  for which no specific poolable flag was specified.
- withQueryTimeout: The default JDBC queryTimeout property that should be applied to all jOOQ
  queries, for which no specific queryTimeout was specified.
- withMaxRows: The default JDBC maxRows property that should be applied to all jOOQ queries, for
  which no specific maxRows value was specified.
- withFetchSize: The default JDBC fetchSize property that should be applied to all jOOQ queries, for
  which no specific fetchSize value was specified.
- withBatchSize: A property specifying a batch size that should be applied to all automatically
  created BatchedConnection instances.
- withDebugInfoOnStackTrace: [#5570] Whether exception stack traces should be enhanced with
  additional debug information.
- withInListPadding: [#5600] Whether IN lists in IN predicates should be padded to powers of
  inListPadBase (default 2).
- withInListPadBase: [#7095] The base to use to calculate the powers of when applying in list
  padding.
- withDelimiter: [#5826] The delimiter character to be used to delimit statements in batches.
- withEmulateOnDuplicateKeyUpdateOnPrimaryKeyOnly: [#6462] Use only the primary key to emulate
  MySQL's INSERT .. ON DUPLICATE KEY UPDATE statement. In MySQL, the statement considers all unique
  keys for duplicates to apply an update rather than an insert. Earlier versions of jOOQ considered
  only the PRIMARY KEY. This flag can be turned on to maintain backwards compatibility.
- withEmulateMultiset: [#3884] How MULTISET support should be emulated.
- withEmulateNestedRecordProjectionsUsingMultisetEmulation: [#13598] Whether nested record
  projections at the top level should be emulated using the MULTISET emulation rather than the
  flattening emulation, if supported by the dialect.
- withEmulateComputedColumns: [#13418] Whether computed columns should be emulated in the client.
  This can be useful if a schema was generated using a dialect that supports computed columns, but
  it is deployed on an RDBMS that does not.
- withComputedOnClientVirtual: Whether VIRTUAL client side computed columns should be applied to
  queries. This feature is available only in commercial distributions.
- withComputedOnClientStored: Whether STORED client side computed columns should be applied to
  queries (including audit columns). This feature is available only in commercial distributions.
- withExecuteUpdateWithoutWhere: [#6771] Specifies whether UPDATE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- withExecuteDeleteWithoutWhere: [#6771] Specifies whether DELETE statements are allowed to be
  executed lacking a WHERE clause. This has no effect on rendering the statements SQL string.
- withInterpreterDialect: [#7337] The dialect that should be used to interpret SQL DDL statements.
  SQLDialect.DEFAULT means that jOOQ interprets the SQL itself. Any other dialect (if supported)
  will be interpreted on an actual JDBC connection.
- withInterpreterNameLookupCaseSensitivity: [#9633] The case sensitivity of identifiers used when
  interpreting SQL DDL statements.
- withInterpreterLocale: The Locale to be used with any interpreter locale dependent logic,
  defaulting to getLocale().
- withInterpreterDelayForeignKeyDeclarations: Using this flag, the interpreter will be able to delay
  the addition of foreign key declarations until the end of the interpretation run.
- withMetaIncludeSystemIndexes: The Meta implementation that is backed by DatabaseMetaData does not
  produce system generated indexes on constraints, by default.
- withMetaIncludeSystemSequences: The Meta implementation that is backed by DatabaseMetaData does
  not produce system generated sequences, by default.
- withMigrationHistorySchema: The database schema where the migration history is located.
- withMigrationHistorySchemaCreateSchemaIfNotExists: Whether getMigrationHistorySchema() should be
  created if it doesn't exist.
- withMigrationDefaultSchema: The default schema whose unqualified objects that are included in the
  migration.
- withMigrationSchemataCreateSchemaIfNotExists: Whether getMigrationSchemata() should be created if
  they don't exist.
- withMigrationDefaultContentType: The default ContentType that is used when loading migrations.
- withMigrationAllowUndo: Whether migrations are allowed to be executed in inverse order.This is a
  potentially destructive feature, which should not be turned on in production. It is useful mostly
  to quickly switch between branches in a development environment. This feature is available only in
  commercial distributions.
- withMigrationAllowInvalidCommits: Whether migrations to invalid commits (Commit.valid()) are
  allowed.This is a potentially destructive feature, which should not be turned on in production. It
  is useful mostly to quickly test uncommited or inconsistent changes in development.
- withMigrationRevertUntracked: Whether migrations revert any untracked changes in the schemas that
  are being migrated.This is a potentially destructive feature, which should not be turned on in
  production. It is useful mostly to quickly revert any elements created in a development
  environment. This feature is available only in commercial distributions.
- withMigrationAutoBaseline: Whether to automatically existing schemas that are not yet managed by
  jOOQ Migrations.
- withMigrationAutoVerification: Whether a migration automatically runs a verification first.
- withMigrationIgnoreDefaultTimestampPrecisionDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between TIMESTAMP and TIMESTAMP(6), if 6 is
  the default precision for timestamps on the configured dialect.
- withMigrationIgnoreUnnamedConstraintDiffs: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the difference between (possibly synthetically) name
  constraints and unnamed constraints, if the structure of the constraint is the same.
- withMigrationIgnoreImplicitPrimaryKeyNotNullConstraints: Various migrateTo() methods (e.g.
  Meta.migrateTo(org.jooq.Meta)) ignore the presence or absence of implicit NOT NULL constraints on
  PRIMARY KEY columns if the constraint is really implicit for a given dialect. This flag allows for
  overriding this behaviour.
- withLocale: The Locale to be used with any locale dependent logic if there is not a more specific
  locale available. More specific locales include e.g. getRenderLocale(), getParseLocale(), or
  getInterpreterLocale().
- withParseDialect: [#7337] The input dialect that should be chosen to disambiguate ambiguous SQL
  syntax.
- withParseLocale: The Locale to be used with any parser locale dependent logic, defaulting to
  getLocale().
- withParseDateFormat: The date format to use when parsing functions whose behaviour depends on some
  session date format, such as NLS_DATE_FORMAT in Oracle
- withParseTimestampFormat: The timestamp format to use when parsing functions whose behaviour
  depends on some session date format, such as NLS_TIMESTAMP_FORMAT in Oracle
- withParseNamedParamPrefix: The prefix to use for named parameters in parsed SQL. Named parameter
  syntax defaults to :name (such as supported by Oracle, JPA, Spring), but vendor specific
  parameters may look differently. This flag can be used to determine the prefix to be used by named
  parameters, such as @ for SQL Server's @name or $ for PostgreSQL's $name when parsing SQL. "Named
  indexed" parameters can be obtained in the same way by specifingy ParamType#NAMED and not
  providing a name to parameters, resulting in :1 or @1 or $1, etc.
- withParseNameCase: [#7337] The default name case for parsed identifiers.
- withParseWithMetaLookups: [#7163] Whether the parser should perform meta lookups in the
  Configuration's MetaProvider.
- withParseAppendMissingTableReferences: Transform the parsed SQL to append missing table references
  to the query's FROM or USING clause, if applicable. Teradata (and possibly others) allow for
  referencing tables that are not listed in the FROM clause, such as SELECT t.* FROM t WHERE t.i =
  u.i. This transformation is executed in the parser, to produce SELECT t.* FROM t, u WHERE t.i =
  u.i, instead. By default, it is active when the input dialect supports this syntax. This feature
  is available in the commercial distribution only.
- withParseSetCommands: [#9780] Whether commands of the type SET key = value should be parsed rather
  than ignored.
- withParseUnsupportedSyntax: [#5917] Whether the parser should accept unsupported (but known)
  syntax.
- withParseUnknownFunctions: [#7344] Whether the parser should accept unknown functions.
- withParseIgnoreCommercialOnlyFeatures: [#13109] Whether the parser of the jOOQ Open Source Edition
  should ignore commercial only features, rather than failing.
- withParseIgnoreComments: [#8325] Whether the parser should ignore content between ignore comment
  tokens.
- withParseIgnoreCommentStart: [#8325] The ignore comment start token
- withParseIgnoreCommentStop: [#8325] The ignore comment stop token
- withParseRetainCommentsBetweenQueries: [#12538] Whether the parser should retain comments and
  whitespace between queries when parsing multiple queries through Parser.parse(String). jOOQ's
  query object model doesn't have a way to represent comments or other whitespace, and as such, the
  parser simply skips them by default. However, it may be desirable to retain comments before or in
  between top level queries, when parsing multiple such queries in a script. Comments inside of
  queries (including procedural statements) are still not supported.
- withParseMetaDefaultExpressions: [#8469] Whether to parse default expressions retrieved from
  DatabaseMetaData.
- withParseMetaViewSources: [#8469] Whether to parse view sources retrieved from DatabaseMetaData.
- withReadonlyTableRecordInsert: [#9864] The behaviour when trying to insert into readonly columns
  using TableRecord.insert().
- withReadonlyUpdatableRecordUpdate: [#9864] The behaviour when trying to update a readonly column
  using UpdatableRecord.update().
- withReadonlyInsert: [#9864] The behaviour when trying to insert into readonly columns using Insert
  statements, or the insert clause of a Merge statement.
- withReadonlyUpdate: [#9864] The behaviour when trying to update a readonly column using Update
  statements, or the update clause of a Merge statement.
- withApplyWorkaroundFor7962: [#7963] Apply workaround for ORA-04043 when inserting into Oracle
  tables with qualified, quoted identifiers, and fetching generated keys
- withWarnOnStaticTypeRegistryAccess: [#15286] The warning level when the deprecated static type
  registry was accessed by legacy code.
- withInterpreterSearchPath:
- withMigrationSchemata:
- withParseSearchPath:
- appendTo:
- toString:
- equals:
- hashCode:
- clone:

Settings (class, org.jooq.conf)
This package contains jOOQ's public API.

StatementType (enum, org.jooq.conf)
Java class for StatementType. The following schema fragment specifies the expected content contained
within this class. <simpleType name="StatementType"> <restriction
base="{http://www.w3.org/2001/XMLSchema}string"> <enumeration value="STATIC_STATEMENT"/>
<enumeration value="PREPARED_STATEMENT"/> </restriction> </simpleType>
Methods:
- STATIC_STATEMENT: Execute statements with inlined bind values, avoiding JDBC's PreparedStatements
- PREPARED_STATEMENT: Execute statements with bind values, using JDBC's PreparedStatements
- values: Gibt ein Array mit den Konstanten dieser Enum-Klasse in der Reihenfolge ihrer Deklaration
  zurück.
- valueOf: Gibt die Enum-Konstante dieser Klasse mit dem angegebenen Namen zurück. Die Zeichenfolge
  muss exakt mit einer ID übereinstimmen, mit der eine Enum-Konstante in dieser Klasse deklariert
  wird. (Zusätzliche Leerzeichen sind nicht zulässig.)
- value:
- fromValue:

StatementType (enum, org.jooq.conf)
The type of statement that is to be executed.

CSVParser (class, org.jooq.tools.csv)
A very simple CSV parser released under a commercial-friendly license. This just implements
splitting a single line into fields.
Methods:
- DEFAULT_SEPARATOR: The default separator to use if none is supplied to the constructor.
- INITIAL_READ_SIZE:
- DEFAULT_QUOTE_CHARACTER: The default quote character to use if none is supplied to the
  constructor.
- DEFAULT_ESCAPE_CHARACTER: The default escape character to use if none is supplied to the
  constructor.
- DEFAULT_STRICT_QUOTES: The default strict quote behavior to use if none is supplied to the
  constructor
- DEFAULT_IGNORE_LEADING_WHITESPACE: The default leading whitespace behavior to use if none is
  supplied to the constructor
- NULL_CHARACTER: This is the "null" character - if a value is set to this then it is ignored. I.E.
  if the quote character is set to null then there is no quote character.
- CSVParser: Constructs CSVParser using a comma for the separator.
- isPending: precondition: the current character is an escape
- parseLineMulti:
- parseLine:
- isNextCharacterEscapable: precondition: the current character is an escape
- isAllWhiteSpace: precondition: sb.length() > 0

CSVParser (class, org.jooq.tools.csv)

JDBCUtils (class, org.jooq.tools.jdbc)
JDBC-related utility methods.
Methods:
- dialect: "Guess" the SQLDialect from a Connection instance. This method tries to guess the
  SQLDialect of a connection from the its connection URL as obtained by DatabaseMetaData.getURL().
  If the dialect cannot be guessed from the URL (e.g. when using an JDBC-ODBC bridge), further
  actions may be implemented in the future.
- driver: "Guess" the JDBC driver from a SQLDialect.
- safeClose: Safely close a connection. This method will silently ignore if connection is null, or
  if Connection.close() throws an exception.
- safeFree: Safely free a blob. This method will silently ignore if blob is null, or if Blob.free()
  throws an exception.
- wasNull: Convenient way to check if a JDBC-originated record was null. This is useful to check if
  primitive types obtained from the JDBC API were actually SQL NULL values.
- foreignKeyRule: Translate the DatabaseMetaData.importedKeyCascade and various other flag valuse to
  the jOOQ QOM.ForeignKeyRule representation.

JDBCUtils (class, org.jooq.tools.jdbc)

Mock (class, org.jooq.tools.jdbc)
Various utilities related to MockDataProvider. Disclaimer: The general idea of mocking a JDBC
connection with this jOOQ API is to provide quick workarounds, injection points, etc. using a very
simple JDBC abstraction. It is NOT RECOMMENDED to emulate an entire database (including complex
state transitions, transactions, locking, etc.) using this mock API. Once you have this requirement,
please consider using an actual database instead for integration testing (e.g. using
https://www.testcontainers.org), rather than implementing your test database inside of a
MockDataProvider.
Methods:
- of: Create a new MockDataProvider that always returns a single record for all queries.

Mock (class, org.jooq.tools.jdbc)

MockConfiguration (class, org.jooq.tools.jdbc)
A mock configuration. This Configuration wraps a delegate Configuration and wraps all
ConnectionProvider references in MockConnectionProvider.
Methods:
- MockConfiguration:
- dsl: Beschreibung aus Schnittstelle kopiert: Configuration
- data: Beschreibung aus Schnittstelle kopiert: Configuration
- clock: Beschreibung aus Schnittstelle kopiert: Configuration
- connectionProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- interpreterConnectionProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- systemConnectionProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- connectionFactory: Beschreibung aus Schnittstelle kopiert: Configuration
- metaProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- commitProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- executorProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- cacheProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- transactionProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- annotatedPojoMemberProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- constructorPropertiesProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- recordMapperProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- recordUnmapperProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- recordListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- executeListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- migrationListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- visitListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- transactionListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- diagnosticsListenerProviders: Beschreibung aus Schnittstelle kopiert: Configuration
- unwrapperProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- charsetProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- converterProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- formattingProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- subscriberProvider: Beschreibung aus Schnittstelle kopiert: Configuration
- schemaMapping: Beschreibung aus Schnittstelle kopiert: Configuration
- dialect: Beschreibung aus Schnittstelle kopiert: Configuration
- family: Beschreibung aus Schnittstelle kopiert: Configuration
- settings: Beschreibung aus Schnittstelle kopiert: Configuration
- set: Beschreibung aus Schnittstelle kopiert: Configuration
- derive: Beschreibung aus Schnittstelle kopiert: Configuration
- deriveSettings: Beschreibung aus Schnittstelle kopiert: Configuration

MockConfiguration (class, org.jooq.tools.jdbc)

MockDataProvider (class, org.jooq.tools.jdbc)
A data provider for mock query executions. Supply this data provider to your MockConnection in order
to globally provide data for SQL statements. Disclaimer: The general idea of mocking a JDBC
connection with this jOOQ API is to provide quick workarounds, injection points, etc. using a very
simple JDBC abstraction. It is NOT RECOMMENDED to emulate an entire database (including complex
state transitions, transactions, locking, etc.) using this mock API. Once you have this requirement,
please consider using an actual database instead for integration testing (e.g. using
https://www.testcontainers.org), rather than implementing your test database inside of a
MockDataProvider. See execute(MockExecuteContext) for more details.
Methods:
- execute int multiSize = context.getBatchSQL().length; int singleSize =
  context.getBatchBindings().length; assertEquals(result.length, Math.max(multiSize, singleSize)):
  Execution callback for a JDBC query execution. This callback will be called by MockStatement upon
  the various statement execution methods. These include: Statement.execute(String)
  Statement.execute(String, int) Statement.execute(String, int[]) Statement.execute(String,
  String[]) Statement.executeBatch() Statement.executeQuery(String) Statement.executeUpdate(String)
  Statement.executeUpdate(String, int) Statement.executeUpdate(String, int[])
  Statement.executeUpdate(String, String[]) PreparedStatement.execute()
  PreparedStatement.executeQuery() PreparedStatement.executeUpdate() The various execution modes are
  unified into this simple method. Implementations should adhere to this contract: MockStatement
  does not distinguish between "static" and "prepared" statements. However, a non-empty
  MockExecuteContext.bindings() is a strong indicator for a PreparedStatement. MockStatement does
  not distinguish between "batch" and "single" statements. However... A
  MockExecuteContext.batchSQL() with more than one SQL string is a strong indicator for a "multi-
  batch statement", as understood by jOOQ's DSLContext.batch(Query...). A
  MockExecuteContext.batchBindings() with more than one bind variable array is a strong indicator
  for a "single-batch statement", as understood by jOOQ's DSLContext.batch(Query). It is recommended
  to return as many MockResult objects as batch executions. In other words, you should guarantee
  that: int multiSize = context.getBatchSQL().length; int singleSize =
  context.getBatchBindings().length; assertEquals(result.length, Math.max(multiSize, singleSize))
  This holds true also for non-batch executions (where both sizes are equal to 1) You may also
  return more than one result for non-batch executions. This is useful for procedure calls with
  several result sets. In JDBC, such additional result sets can be obtained with
  Statement.getMoreResults(). In jOOQ, such additional result sets can be obtained with
  ResultQuery.fetchMany() If generated keys (Statement.RETURN_GENERATED_KEYS) are requested from
  this execution, you can also add MockResult.data to your first result, in addition to the affected
  MockResult.rows. The relevant flag is passed from MockStatement to any of these properties:
  MockExecuteContext.autoGeneratedKeys() MockExecuteContext.columnIndexes()
  MockExecuteContext.columnNames() OUT parameters from stored procedures are generated from the
  first MockResult's first Record. If OUT parameters are requested, implementors must ensure the
  presence of such a Record.

MockDataProvider (class, org.jooq.tools.jdbc)
This package contains jOOQ's public API.

JSONParser (class, org.jooq.tools.json)
Parser for JSON text. Please note that JSONParser is NOT thread-safe.
Methods:
- S_INIT:
- S_IN_FINISHED_VALUE:
- S_IN_OBJECT:
- S_IN_ARRAY:
- S_PASSED_PAIR_KEY:
- S_IN_PAIR_VALUE:
- S_END:
- S_IN_ERROR:
- JSONParser:
- reset: Reset the parser to the initial state without resetting the underlying reader.
- getPosition:
- parse:

JSONParser (class, org.jooq.tools.json)